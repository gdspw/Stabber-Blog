---
layout: post
title:  "java基础面试知识点总结"
categories: [java,jvm]
tags:  [Java,IT]
excerpt: 总结记录的一些有关java基础知识的面试题

---

# Java创建Object对象的方法有哪些

·    使用New关键字，调用类的构造函数直接创建

·    使用反射Class类的newInstance方法，newInstance方法调用无参构造器创建对象(反射)，

Class.forName("com.test3.Hello").newInstance();

Class.forName("com.test3.Hello").getConstructor().newInstance();

·    使用clone方法：通过实现Cloneable接口并使用clone方法产生的对象在内存中是不同的两个对象，可以实现对象的创建功能。

·    实现Serializable接口，采用序列化与反序列化方式：ObjectOutputStream.writeObject(obj1);和ObjectInputStream.readObject();

·    使用Unsafe类创建对象，指针方式操作内存空间，不安全不建议使用。

# Java Object对象的创建过程

![clip_image001](http://image.itstabber.com/2020-09-09/clip_image001.png)

l **类检查器**

JVM遇到new指令的时候,首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用,并且检查这个符号引用代码的类是否被加载过、解析过、初始化过。若没有，则必须先进行类加载过程。

l **分配内存** (对象实例**内存布局**：对象头->实例数据->对齐填充)

在类加载检查通过之后,接下来虚拟机将会为新生的对象分配内存. 对象所需要的内存大小在类加载完成之后便会确定,为对象分配内存空间的任务等同于把一块确定大小的内存从java堆中划分出来.分配方式有**指针碰撞****（****Bump the Pointer****）**和**空闲列表****（****Free List****）**两种,选择哪种分配方式由java堆是否规整决定,而java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。

分配内存的方式最终取决于GC收集器的算法是"标记-清除"还是"标记-整理(标记-压缩)"

![img](http://image.itstabber.com/2020-09-09/clip_image002.png)

l **初始化零值**

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 如果使用TLAB（Thread Local Allocation Buffer，本地线程分配缓冲），这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的**实例****字****段**在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

l **设置对象头**（Object Header）

在HotSpot虚拟机中，对象存储的**内存布局**分为3块区域：**对象头**（Header）、**实例数据**（Instance Data）和**对齐填充**（Padding）。对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。初始化零值之后，虚拟机将给对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息需要存放在对象的对象头之中。

l **执行init方法**

在上面的工作都完成之后,以虚拟机的视角来看,对象创建才刚开始,<init>方法还没有被执行,所有的字段值还都为零.所以一般来说,执行new指令之后接着执行方法,把对象按照程序员的意愿进行初始化,这样一个真正的对象才算完全产生出来.

# Java/JVM的内存结构（内存区域、运行时数据区域）

   ![img](http://image.itstabber.com/2020-09-09/clip_image003.png)



1.*方法区（Method Area）：**方法区属于线程共享的内存区域，又称Non-Heap（非堆），主要用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，根据Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError 异常。值得注意的是在方法区中存在一个叫运行时常量池(Runtime Constant Pool）的区域，它主要用于存放编译器生成的各种字面量和符号引用，这些内容将在类加载后存放到运行时常量池中，以便后续使用。

![img](http://image.itstabber.com/2020-09-09/clip_image004.png)

方法区（Method Area）是JVM规范里面的运行时数据区的一个组成部分，主要用来存储class、运行时常量池、字段、方法、代码、JIT代码等。方法区是JVM规范中的一部分，并不是实际的实现，切忌将规范跟实现混为一谈。永久带又叫Perm区，只存在于Hotspot JVM中，并且只存在于jdk7和之前的版本中，jdk8中已经彻底移除了永久带，jdk8中引入了一个新的内存区域叫Meta-space。永久带是实现层面的东西，永久带里面存的东西基本上就是方法区规定的那些东西。**区别:** 方法区是规范层面的东西，规定了这一个区域要存放哪些东西，永久带或者是Meta-space是对方法区的不同实现，是实现层面的东西。

![img](http://image.itstabber.com/2020-09-09/clip_image005.png)

\2.   **Java****堆（Java Heap）：**Java 堆也是属于线程共享的内存区域，它在虚拟机启动时创建，是Java 虚拟机所管理的内存中最大的一块，主要用于存放对象实例，几乎所有的对象实例都在这里分配内存，注意Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做**GC****堆**，如果在堆中没有内存满足实例分配需求，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。

Java虚拟机根据对象存活的周期不同，再把**堆**内存划分为几块，一般分为新生代（Young Generation）、老年代（Old Generationn）和永久代（Permanent Generationn）（对HotSpot虚拟机而言），这就是JVM的内存分代策略。

\3.   **程序计数器（Program Counter Register）：**属于线程私有的数据区域，是一小块内存空间，它可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时，通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。

\4.   **虚拟机栈(Java Virtual Machine Stacks)：**属于线程私有的数据区域，与线程同时创建，总数与线程关联，代表Java方法执行的内存模型。每个方法执行时都会创建一个栈桢来存储方法的的变量表、操作数栈、动态链接方法、返回值、返回地址等信息。每个方法从调用直结束就对于一个栈桢在虚拟机栈中的入栈和出栈过程，如下（图有误，应该为栈桢）：

![img](http://image.itstabber.com/2020-09-09/clip_image006.png)

\5.   **本地方法栈(Native Method Stacks)：**本地方法栈属于线程私有的数据区域，这部分主要与虚拟机用到的 Native 方法相关，一般情况下，我们无需关心此区域。

# java内存模型和优化有做过哪些？

**一.内存模型的相关概念**

大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。

![image](http://image.itstabber.com/2020-09-09/clip_image007.png)





![img](http://image.itstabber.com/2020-09-09/clip_image008.png)



**缓存一致性****问题**：如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现，多个线程访问的变量为共享变量的），那么就可能存在缓存不一致的问题。

并发编程中三个问题：原子性问题，可见性问题，有序性问题。

**原子性：**即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

**可见性：**是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性：**即程序执行的顺序按照代码的先后顺序执行。**指令重排序**，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会（考虑指令之间的数据依赖性）保证程序最终执行结果和代码顺序执行的结果是一致的。指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。

也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。

**二.Java内存模型（JMM）：线程通信，消息传递**

![img](http://image.itstabber.com/2020-09-09/clip_image009.png) ![img](http://image.itstabber.com/2020-09-09/clip_image010.png)

在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（即线程的上下文，类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。

为了保证共享内存的正确性（并发编程中可以满足原子性、可见性及有序性），有一个重要的概念，那就是——Java内存模型。JMM内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。

内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。

# JMM（Java内存模型）内存之间的交互操作与规则

![在这里插入图片描述](http://image.itstabber.com/2020-09-09/clip_image011.png)

一个变量是怎么从主内存拷贝到线程的工作内存中的。在JMM中主要定义了8种操作来完成上述的工作，并且这**8****种操作**都是原子性（即同步）的，不可分割的。它们分别是：

- lock（锁定）：目的是把主内存中的变量标识为线程已经锁定的状态。
- unlock（解锁）：目的是把主内存中已经是锁定状态的变量解锁，解锁后的变量可以被其他线程锁定。
- read（读取）：目的是把变量的值从主内存中传输到线程的工作内存中。
- load（载入）：目的是把主内存中得到的变量值存储到工作内存的变量副本中。
- use（使用）：目的是把工作内存中变量的值传递给执行引擎。
- assign（赋值）：目的是把执行引擎接收到的值赋给工作内存中的变量。
- store（存储）：目的是把工作内存中变量的值传送到主内存中。
- write（写入）：目的是把工作内存中得到的变量的值放入主内存的变量中。

上述就是每种操作的具体功能。在虚拟机执行上述操作时有一些默认的**规定**：

- 不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起了同步但主内存不接受的情况。
- 不允许变量在工作内存中改变了之后不同步到主内存中。
- 不允许线程在没有发生任何改变的情况下把数据从线程的工作内存同步回主内存中。
- 变量只能在主内存中产生，不允许在工作内存中直接使用一个未初始化的变量。
- 变量在同一个时刻只允许一条线程对其进行lock操作。
- 如果对变量执行lock操作时，线程会清空工作内存中此变量的值。
- 若变量事先没有被lock锁定，那不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
- 对变量执行unlock操作之前，必须先把此变量同步回主内存中。

# Java内存模型的三大特征

Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的。

**1.****原子性**：在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。

**2.****可见性**：对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。

**3.****有序性**：在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。

在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。

另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before先行发生原则，是指Java内存模型中定义的两项操作之间的依序关系，如果说操作A先行发生于操作B，其实就是说发生操作B之前。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

下面就来具体介绍下**happens-before原则（先行发生原则）：**摘自《深入理解Java虚拟机》

- **程序次序规则：**一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
- **锁定规则：**一个unLock操作先行发生于后面对同一个锁额lock操作
- **volatile****变量规则：**对一个变量的写操作先行发生于后面对这个变量的读操作
- **传递规则：**如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
- **线程启动规则：**Thread对象的start()方法先行发生于此线程的每个一个动作
- **线程中断规则：**对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
- **线程终结规则：**线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
- **对象终结规则：**一个对象的初始化完成先行发生于他的finalize()方法的开始

另外，还有一个“传递性”。

# GC分哪两种，Minor GC 和Full GC有什么区别？

​    JVM内存区域中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 Java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的。

- 次数上频繁收集      在Young区（**Eden、Survivor0、Survivor1**）。**Minor GC****清理年轻代内存。**
- 次数上较少收集      在Old区。**Major GC****清理老年代内存。**
- **Full GC = Minor GC + Major GC** **+ Perm     gen(****外)****。**Full GC 是清理整个堆空间：包括年轻代和老年代全堆，外加永久代。
- 基本不动Perm区（JDK1.7 永久区）

PS：https://www.cnblogs.com/tuhooo/p/7508503.html

# 什么时候会触发Full GC？

触发Full GC执行的情况有如下四种：

**1****、Old区（老年代）空间不足。**老年代空间只有在新生代对象转入及创建为大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误：java.lang.OutOfMemoryError: Java heap space。为避免以上两种状况引起的FullGC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。

**2. Permanet Generation****空间满。永久代**中存放的为一些class的信息等，当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息：

java.lang.OutOfMemoryError: PermGen space

为避免Perm Gen占满造成Full GC现象，可采用为增大Perm Gen空间或转为使用CMS GC。

**3. CMS GC****时出现promotion failed和concurrent mode failure**

对于采用CMS进行旧生代GC的程序而言，尤其要注意GC日志中是否有promotion failed和concurrent mode failure两种状况，当这两种状况出现时可能会触发Full GC。

promotion（晋升） failed是在进行Minor GC时，survivor space放不下、对象只能放入旧生代，而此时旧生代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入旧生代，而此时旧生代空间不足造成的。

应对措施为：增大survivorspace、旧生代空间或调低触发并发GC的比率，但在JDK 5.0+、6.0+的版本中有可能会由于JDK的bug29导致CMS在remark完毕后很久才触发sweeping动作。对于这种状况，可通过设置-XX:CMSMaxAbortablePrecleanTime=5（单位为ms）来避免。

**4.** **统计得到的Minor GC****晋升****到旧生代的平均大小****大于****旧生代的剩余空间（或者：**当**年老代的剩余空间小于Young GC的平均晋升大小时****）。**

这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。

例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。

当新生代采用**Parallel Scavenge****收集器**（并行清除）时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否大于6MB，如小于，则触发对旧生代的回收。

除了以上4种状况外，手动调用System.gc()显式触发Full GC；Heap dump带GC，默认也是触发Full GC；对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java-Dsun.rmi.dgc.client.gcInterval=3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。

# JVM内存模型，为什么survivor需要有2个。

**减少Full GC发生：**若没有Survivor区，当Eden区满时触发一次Minor GC，就会把Eden区的对象复制到老年代，这样当老年代满了之后又会触发Major GC（可看做Full GC），比较耗时。避免直接放入老年代被装满，进行Major GC且连带Minor GC也就是Full GC，出现老年代频发Full GC而严重影响效率问题。Survivor具有预筛选保证，只有对象超过一定岁数(默认15)才会送往老年代，Survivor区可以减少被送到老年代的对象，进而减少Full GC发生。

**规避内存碎片化：**新生代使用复制回收算法，当Eden区填满后，触发Minor GC进行垃圾回收，幸存的对象会移动到（假设只有一个）Survivor区，这样循环往复。此时，Survivor区被装满了，也会进行Minor GC，将一些对象kill掉，幸存的对象只能保存在原来的位置，这样就会出现大量的内存碎片（被占用内存不连续），严重影响性能。如果有两个Survivor区，便可以保证一个为空，另一个是非空且无碎片保存的。

# 堆（Heap）跟栈（Stack）的区别

堆和栈都是Java用来在RAM中存放数据的地方。

**堆（运行时动态分配，灵活）：**

（1）Java的堆是一个运行时数据区，类的对象从堆中分配空间。这些对象通过**new等指令**建立，通过**垃圾回收器**来销毁。

（2）堆的优势是可以**动态分配**内存空间，需要多少内存空间不必事先告诉编译器，因为它是在运行时动态分配的。但缺点是，由于需要在运行时动态分配内存，所以存取速度较慢。

**栈（先进后出，有序）：**

（1）栈中主要存放一些**基本数据类型的（局部）变量**（byte，short，int，long，float，double，boolean，char）和对象的引用。

（2）栈的优势是，**存取速度比堆快，栈数据可以共享**。但缺点是，存放在栈中的数据占用多少内存空间需要在**编译时（静态分配）**确定下来，缺乏灵活性。

**（1）存放内容不同：**

栈内存：用来存放基本数据类型变量和引用类型变量。

堆内存：用来存放运行时通过new关键字创建的对象。

**（2）生命周期不同：**

栈的生命周期与线程相同，随线程而生，随线程而亡，是线程私有的。

堆的生命周期与JVM相同，JVM启动时创建，JVM停止时销毁，是线程共享的。

**（3）内存回收管理不同：**

栈是线程私有的内存区域，每个方法被执行的时候都会创建一个栈帧，栈帧随着方法的进入和退出在虚拟机栈中做入栈和出栈操作， 实现了自动内存清理。

堆是线程共享的内存区域，没有确定的销毁时间，因此内存回收主要集中于堆中，在堆中分配的内存由垃圾收集器来管理回收。

**（4）存取速度不同：**

栈的存取速度较快，仅次于寄存器，但栈的数据大小与生存期必须是确定的，缺乏灵活性。另外，栈数据可以共享。

String可以用以下两种方式来创建：

```
String str1 = new String("abc");
String str2 = "abc";
```

第一种使用new来创建的对象，它存放在堆中。每调用一次就创建一个新的对象。

第二种是先在栈中创建对象的引用str2，然后查找栈中有没有存放“abc”，如果没有，则将“abc”存放进栈，并将str2指向“abc”，如果已经有“abc”，则直接将str2指向“abc”。

# java栈主要存什么内容，相比堆有什么优势

栈(stack)：是一个先进后出的数据结构，主要存储方法（函数）中的参数，局部变量，基本类型的变量（字节，短，整型，长，浮点，双精度，布尔值，Char）和对象的引用类型（对象句柄）。栈中数据的生存空间一般在当前scopes作用域内（就是由{...}括起来的区域）。 

栈的优势是存取速度比堆要快，仅次于寄存器，栈数据可以共享（多个引用可以指向同一个地址），随函数返回自动清除。但缺点是，存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。

# 栈实现队列，反思路：队列实现栈

栈（Stack）是先入后出，队列（Queue）是先入先出。根据这个思想，可以用一个栈作为入队，另一个栈作为出队。只要把第一个栈的栈顶的元素压入第二个栈就好了，出队的时候输出第二个栈的栈顶，如果第二个栈的空了就需要不断操作从第一个栈的栈顶压入第二个栈，但是如果第一个栈也空了，那就说明所有元素都输出来了。

# Linux内存模型，和java内存模型

 

# String与StringBuffer的区别

**String****：**

1、String是final类，即不能被继承。

2、是对象（引用）类型不是原始类型，String对象为不可变对象，一旦被创建，就不能修改它的值。

3、对已创建好的String对象进行修改操作，每次都必须重新创建新的对象来保存新的值。

**StringBuffer****：**

1、是一个可变字符串类，底层为可变char[]默认capacity=16，只能通过new关键字调构造函数来创建对象；操作方法都是synchronized同步的，线程安全。

2、当对StringBuffer实例化对象进行修改时，不会像String那样重新建立对象，通过它的append方法向其赋值，只对这一个对象操作。

3、字符串连接操作中StringBuffer的效率要明显比String高。

# GC算法，垃圾回收算法的优缺点

**1****、引用计数法**（引用和去引用伴随加法和减法，影响性能；很难处理循环引用。已被淘汰 –> **根搜索算法**）

![image](http://image.itstabber.com/2020-09-09/clip_image012.png)

**根搜索算法：**处理方式就是**可达性分析算法**，设立若干种根对象，从根（GC Roots）的对象作为起始点，开始向下搜索，搜索所走过的路径称为“**引用链**”，当任何一个根对象到某一个对象没有任何引用链相连（就是从GC Roots到这个对象不可达）时，则认为此对象不可用，是可以被回收的。

可以当做GC roots根对象有以下几种：

（1）栈（栈帧中的本地变量表）中引用的对象。

（2）方法区中的静态成员。

（3）方法区中（声明为final）的常量引用的对象（全局变量的值）

（4）本地方法栈中JNI（一般说的Native方法）引用的对象。

**2、** **标记清除法**（Mark-Sweep）

![image](http://image.itstabber.com/2020-09-09/clip_image013.jpg)

**3、** **标记整理法**（Mark-Compact / Tidy）

![img](http://image.itstabber.com/2020-09-09/clip_image014.png)

**4、** **标记清除压缩法**（Mark-Sweep-Compact）

![img](http://image.itstabber.com/2020-09-09/clip_image015.png) 

**5、** **复制算法**（Copying）

![img](http://image.itstabber.com/2020-09-09/clip_image016.png)

在根搜索算法的基础上，现代虚拟机的实现当中，垃圾搜集的算法主要有**三种**，分别是上面提到的：标记清除算法、复制算法、标记整理算法。这三种算法都扩充了根搜索算法。

**它们的区别如下：**（>表示前者要优于后者，=表示两者效果一样）

**（1）效率**（仅对比**时间复杂度**）：复制算法**>**标记整理算法**>**标记清除算法。

**（2）内存整齐度**：复制算法**=**标记整理算法**>**标记清除算法。

**（3）内存利用率**：标记整理算法**=**标记清除算法**>**复制算法。

注1：可以看到标记清除算法是比较落后的算法了，但是后两种算法却是在此基础上建立的。

注2：时间与空间不可兼得。

**6、****分代收集算法**（Generational Collection）

根据对象的存活周期的不同将内存划分为：新生代（短命对象）和老年代（长命对象）。

**少量对象存活，适合复制算法**：在**新生代**中，每次GC时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成GC。

**大量对象存活，适合用标记清理 / 标记整理**：在**老年代**中，因为对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清理”/“标记-整理”算法进行GC。

**注：**老年代的对象中，有一小部分是因为在新生代回收时，老年代**做担保**，进来的对象；绝大部分对象是因为很多次GC都没有被回收掉而进入老年代。

# 垃圾收集器

**1、** **Serial****收集器**

串行回收器（单线程收集器）只使用一个 CPU 和一个收集线程，垃圾回收时暂停其他所有的工作线程，直到收集结束。每次回收时只有一个工作线程，对于并发能力较弱的计算机来说，串行回收器的专注性和独占性往往有更好的表现，对于运行在 Client 模式下的虚拟机是一个好选择。串行回收器可以在新生代和老年代使用，新生代采用复制算法，老年代采用标记整理算法。根据作用的堆空间不同，分为新生代串行回收器和老年代串行回收器。

Serial收集器是最古老的收集器，它的缺点是当Serial收集器想进行垃圾回收的时候，必须暂停用户的所有进程，即stopthe world(服务暂停)。到现在为止，它依然是虚拟机运行在client模式下的默认新生代收集器。

参数控制：-XX:+UseSerialGC 使用串行收集器

**2****、ParNew收集器**

ParNew收集器是一个工作在新生代的垃圾收集器，它只是简单的将串行收集器多线程化，它的回收策略和算法和串行回收器一样。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩。能与 CMS 收集器 [配置 ](http://www.liuhaihua.cn/archives/tag/配置)工作，所以是许多运行在 Server 模式下的首选新生代收集器。

在垃圾收集器的上下文中，先明确两个概念：

**并行（Parallel）：**多条垃圾线程并行工作，用户线程仍然处于等待状态

**并发（Concurrent）：**用户线程和垃圾回收线程同时执行（不一定并行，可能会交替执行）

并行收集器关注吞吐量优先，并发收集器关注响应时间优先。

参数控制：-XX:+UseParNewGC 使用ParNew收集器   -XX:ParallelGCThreads 限制线程数量

**3****、Parallel Scavenge收集器**（并行清除）

Parallel是采用复制算法的多线程新生代垃圾回收器，Parallel收集器更关注系统的吞吐量。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)。

停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能够提升用户的体验；

而高吞吐量则可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。

可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩

参数控制：-XX:MaxGCPauseMillis 设置最大垃圾收集停顿时间   -XX:GCTimeRatio 设置吞吐量的大小(默认是99)  -XX:+UseAdaptiveSeizPolicy 打开自适应模式

**4****、Parallel Old收集器**

Parallel Old收集器是Parallel Scavenge收集器的老年代版本，采用多线程和”标记－整理”算法，也是比较关注吞吐量。在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。

参数控制：-XX:+UseParallelOldGC 使用ParallelOld收集器 -XX:ParallelGCThreads 限制线程数量

**5****、CMS收集器**

**CMS(Concurrent Mark Sweep)****并发****标记请除**，它使用的是标记请除法，工作在老年代，主要关注系统的停顿时间。

CMS并不是独占的回收器，也就是说，CMS回收的过程中应用程序仍然在不停的工作，又会有新的垃圾不断的产生，所以在使用CMS的过程中应该确保应用程序的内存足够可用，CMS不会等到应用程序饱和的时候才去回收垃圾，而是在某一阀值(默认为68)的时候开始回收，也就是说当老年代的空间使用率达到68%的时候回执行CMS。如果内存使用率增长很快，在CMS执行过程中，已经出现了内存不足的情况，此时，CMS回收就会失败，虚拟机将启动老年代串行回收器进行垃圾回收，这会导致应用程序中断，直到垃圾回收完成后才会正常工作，这个过程GC的停顿时间可能较长，所以阀值的设置要根据实际情况设置。

标记清除法的缺点是内存碎片问题，CMS提供提供了一些优化设置，可以设置完成CMS之后进行一次碎片整理，也可以设置进行多少次CMS回收后进行碎片整理

参数控制：-XX:CMSInitatingPermOccupancyFraction 设置阀值 -XX:+UserConcMarkSweepGC 使用cms垃圾清理器  -XX:ConcGCThreads 限制线程数量 -XX:+UseCMSCompactAtFullCollection 设置完成CMS之后进行一次碎片整理 -XX:CMSFullGCsBeforeCompaction 设置进行多少次CMS回收后进行碎片整理

**6****、G1收集器**

**G1(Garbage First)****垃圾收集器**是当今垃圾回收技术最前沿的成果之一。早在JDK7就已加入JVM的收集器大家庭中，成为HotSpot重点发展的垃圾回收技术。同优秀的CMS垃圾回收器一样，G1也是关注最小时延的垃圾回收器，也同样适合大尺寸堆内存的垃圾收集，官方也推荐使用G1来代替选择CMS。G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。

**并行与并发**：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。

**分代收集**：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。

**空间整合**：与CMS的“标记-清理”算法不同，G1从整体看来是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上看是基于“复制”算法实现，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。

**可预测的停顿**：这是G1相对于CMS的另外一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器特征了。

参数控制：-XX:+UseG1GC 使用G1垃圾收集器  -XX:ParallelGCThreads 限制线程数量  -XX:MaxGCPauseMillis 指定最大停顿时间

# GC Root什么算法知道对象要被回收

​    GC Root即根搜索算法、可达性分析算法、分析对象的引用链、解决循环引用的问题。

可达性分析算法的思想：从一个被称为GC Roots的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明此对象不可用。

在Java语言中，可作为GC Roots的对象包括下面几种：

- 虚拟机栈（栈帧中的本地变量表）中引用的对象。
- 方法区中类静态属性引用的对象。
- 方法区中常量引用的对象。
- 本地方法栈中JNI（即一般说的Native方法）引用的对象。

当一个对象不可达GC Roots时，这个对象并不会马上被回收，而是处于一个死缓的阶段，若要被真正的回收需要经历两次标记。如果对象在可达性分析中没有与GC Roots的引用链，那么此时就会被第一次标记并且进行一次筛选，筛选的条件是是否有必要执行finalize()方法。当对象没有覆盖finalize()方法或者已经被虚拟机调用过，那么就认为是没必要的。

如果该对象有必要执行finalize()方法，那么这个对象将会放在一个称为F-Queue的队列中，虚拟机会触发一个finalize()线程去执行，此线程是低优先级的，并且虚拟机不会承诺一直等待它运行完，这还是因为如果finalize()执行缓慢或者发生了死锁，那么就会造成F-Queue队列一直等待，造成了内存回收系统的崩溃。GC对处于F-Queue中的对象进行第二次被标记，这时，该对象将被移除“即将回收”集合，等待回收。

# Java内存调优怎么做的

**监控GC状态 》 分析堆Dump文件（工具） 》 分析JVM内存泄露（原因） 》 调优JVM参数。**

1、 查看应用程序日志，使用JVM提供的内存查看工具（如JConsole和Java VisualVM），分析当前堆内存快照dump文件和GC日志。

2、 分析当前JVM参数设置，根据实际的堆内存各区域划分和GC执行频次和时间分析问题。

3、 找准问题原因和问题代码，结合业务和技术，做出问题代码的改进和优化处理。

4、 或是调整GC收集器类型和策略参数，合理控制堆内存各区域的分配大小比例。

**堆内存各区域比例不良设置会导致什么后果：**

1）新生代设置过小

一是新生代GC次数非常频繁，增大系统消耗；

二是导致大对象直接进入旧生代，占据了旧生代剩余空间，诱发Full GC

2）新生代设置过大（一般说来新生代占整个堆1/3比较合适）

一是新生代设置过大会导致旧生代过小（堆总量一定），从而诱发Full GC；

二是新生代GC耗时大幅度增加

3）Survivor设置过小

导致对象从Eden直接到达旧生代，降低了在新生代的存活时间

4）Survivor设置过大

导致Eden过小，增加了GC频率

另外，通过-XX:MaxTenuringThreshold=n来控制新生代存活时间，尽量让对象在新生代被回收

**JVM****提供两种较为简单的GC策略的设置方式：**

1）吞吐量throughput优先，这个值可由-XX:GCTimeRatio=n来设置。

2）暂停pause时间优先，尽量保证每次GC造成的应用停止时间都在指定的数值范围内完成。这个值可由-XX:MaxGCPauseRatio=n来设置。

**Java****自带分析工具：**jstack(查看线程)、jmap(查看内存)和jstat(性能分析)命令

1、通过 jstat -gc pid interval 监测程序的实时运行情况，包括堆内存信息（每一个分区的内存使用率变化情况）以及垃圾回收信息。

2、通过jcmd pid VM.flags 就可以查看到jvm相关的设置参数

3、通过jstack pid命令查看分析线程堆栈信息，通常会结合 top -Hp pid 或 pidstat -p pid -t 一起查看具体线程的状态，也经常用来排查一些死锁的异常

4、通过jmap -heap 进程id查看堆内存初始化配置信息以及堆内存的使用情况，其中就包括垃圾收集器的设置类型，输出堆内存中的对象信息，包括产生了哪些对象，对象数量多少等。

5、通过 jmap -histo[:live] 进程id | more 查看堆内存中的对象数目、大小统计直方图，如果带上 live 则只统计活对象。

6、还可以通过jmap –dump:format=b,file=/tmp/heap.hprof 进程id命令把堆内存的使用情况 dump 到文件中（一般dump文件都比较大）

7、查看 & 分析 GC 日志

首先，我们需要通过 JVM 参数预先设置 GC 日志，通常有以下几种 JVM 参数设置：

-XX:+PrintGC 输出GC日志

-XX:+PrintGCDetails 输出GC的详细日志

-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）

-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）

-XX:+PrintHeapAtGC 在进行 GC 的前后打印出堆的信息

-Xloggc:../logs/gc.log 日志文件的输出路径

 eg：-XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:/log/heapTest.log

如果GC日志非常大，可以用GCViewer工具打开日志文件，图形化界面查看整体的 GC 性能。也可以用GCeasy工具，并且还可以将日志文件压缩之后，上传到 GCeasy 官网即可看到非常清楚的 GC 日志分析结果。

8、各种JVM参数调优（比例、大小、年龄、阀值、开启与并闭、）

9、Linux系统工具

（1）top命令：实时显示正在执行进程的 CPU 使用率、内存使用率以及系统负载等信息

（2）top Hp pid命令：查看具体线程使用系统资源情况

（3）vmstat 命令：是一款指定采样周期和次数的功能性监测工具，我们可以看到，它不仅可以统计内存的使用情况，还可以观测到 CPU 的使用率、swap 的使用情况。但 vmstat 一般很少用来查看内存的使用情况，而是经常被用来观察进程的上下文切换。

（4）pidstat命令：是 Sysstat 中的一个组件；可以通过yum install sysstat 安装该监控组件。pidstat 命令则是深入到线程级别的监测工具。

# 有台节点内存溢出，怎么定位问题。整个过程

**引起内存溢出的原因有很多种，列举一下常见的有以下几种：**

1、内存中加载的数据量过于庞大，如一次从数据库查询出过多数据到内存中；

2、集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；

3、代码中存在死循环或循环内部产生过多的重复的大型对象实体；

4、使用了第三方软件中的BUG；

5、启动参数内存值设定的过小；

**使用内存查看工具动态查看内存使用情况：**

**1****、检查GC日志**：确定内存溢出报错是哪个内存划分区域，不同区域的溢出处理不同；主要有永久代（元空间）、堆、本地方法栈三个区域会出现溢出。

**2.1****、永久代溢出：**java.lang.OutOfMemoryError: PermGen space

​    其全称是Permanent Generation space,是指内存的永久保存区域, 这块内存主要是存放Class和Meta信息的,Class在被Load时就会被放到PermGen space中, GC(Garbage Collection)不会在主程序运行期对 PermGen space进行清理。如果应用中加载的class与jar文件大小超过-XX:MaxPermSize就有可能会产生PermGen space OOMError。通常-XX:MaxPermSize设为-Xmx的1/8。

**2.2****、方法区溢出：**Exception in thread "main" java.lang.OutOfMemoryError: Metaspace

​    在HotSpot中，从Jdk8开始，方法区的实现由永久代变更为元空间（MetaSpace），元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。随着类的加载，元空间使用量逐渐增加，可视情况设置将JVM参数：-XX:MetaspaceSize、-XX:MaxMetaspaceSize调整大小。

**3****、堆内存溢出：**java.lang.OutOfMemoryError: Java heap space

​    通过JVM自带的分析工具，找到产生heap space内存溢出时，堆内存中是哪个类的对象存活数量过多而导致溢出的问题根源。可以通过jdk/bin/jconsole.exe和jdk/bin/jvisualvm.exe两个可视工具来定位。生产环境还可以在启动JVM时加上参数指定Dump文件路径，或通过jmap来转储堆内存dump文件进行离线分析。

**4****、方法栈溢出：**Exception in thread "main" java.lang.StackOverflowError

**栈溢出的原因**

·    是否有递归调用

·    是否有大量循环或死循环

·    全局变量（常量）是否过多

·    数组、List、map等集合数据是否过大

**内存溢出的解决方案：**

1、检查对数据库查询中，是否有一次获得全部数据的查询。如果一次取十万条记录到内存，就可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。

2、检查代码中是否有死循环或递归调用，优化代码逻辑。

3、检查是否有大循环重复产生新对象实体，优化代码逻辑。

4、检查List、Map等集合对象是否有使用完后，未清除，始终存有对对象的引用而不能被GC回收。

5、调优JVM启动参数

6、强化并建立代码规范，定期执行迭代版本代码的Review

# 常见的JVM调优方法有哪些？可以具体到调整哪个参数，调成什么值？

主要针对年轻代、年老代、持久代；堆栈等大小进行设置；内存溢出分2类：

\1. 年老代溢出，表现为：java.lang.OutOfMemoryError:Javaheapspace

\2. 持久代溢出，表现为：java.lang.OutOfMemoryError:PermGenspace

**1****、新生代和老年代溢出：**java.lang.OutOfMemoryError:java heep space;当98%时间用于垃圾回收时,且可用的Heap size 不足2%的时候将抛出此异常信息；

**解决方法：****手动设置JVM Heap（堆）的大小**

**2****、持久代溢出：**java.lang.OutOfMemoryError: PermGen space

**解决方法：** **通过-XX:PermSize和-XX:MaxPermSize设置永久代大小即可。**

**3****、栈溢出：java.lang.StackOverFlowError:Thread stack space**

栈区远远小于堆区,栈区需要的内存大小1-2m左右；出现栈溢出，即说明单线程运行程序需要的内存太大；

**解决方法：****1****：修改程序。2：通过 -Xss: 来设置每个线程的Stack大小即可。**

 

**JVM****调优参数参考**

1、JVM堆大小设置，通过-Xms -Xmx限定其最小、最大值。为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值。

2、年轻代和年老代默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代。比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把它们设置为同样大小。

3、年轻代和年老代设置多大才算合理

（1）更大的年轻代必然导致更小的年老代，大的年轻代会延长普通GC的周期，但会增加每次GC的时间；小的年老代会导致更频繁的Full GC

（2）更小的年轻代必然导致更大年老代，小的年轻代会导致普通GC很频繁，但每次的GC时间会更短；大的年老代会减少Full GC的频率

如何选择应该依赖应用程序对象生命周期的分布情况： 如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。但很多应用都没有这样明显的特性。

在抉择时应该根据以下两点：

（1）本着Full GC尽量少的原则，让年老代尽量缓存常用对象，JVM默认比例1：2也是这个道理。

（2）通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响Full GC的前提下，根据实际情况加大年轻代，比如可以把比例控制在1：1。但应该给年老代至少预留1/3的增长空间。

4、在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC 。

5、线程堆栈的设置：每个线程默认会开启1M的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般256K就足用。理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。

 

**JVM****服务参数调优实战——大型网站服务器案例**

承受海量访问的动态Web应用

服务器配置：8 CPU, 8G MEM, JDK 1.6.X

参数方案：

-server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX:SurvivorRatio=6 -XX:MaxPermSize=256m -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC

调优说明：

- -Xmx 与 -Xms 相同以避免JVM反复重新申请内存。-Xmx 的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。
- -Xmn1256m 设置年轻代大小为1256MB。此值对系统性能影响较大，Sun官方推荐配置年轻代大小为整个堆的3/8。
- -Xss128k 设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。
- -XX:SurvivorRatio=6 设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个Survivor区与1个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。
- -XX:ParallelGCThreads=8 配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。
- -XX:MaxTenuringThreshold=0 设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率；如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。根据被海量访问的动态Web应用之特点，其内存要么被缓存起来以减少直接访问DB，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。
- -XX:+UseConcMarkSweepGC 设置年老代为并发收集。CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。

# JDK/Java从1.5~1.9各版本的新特性

**JDK Version 1.0****（**于1996-01-23发行**）**

开发代号为Oak（橡树）。

 

**JDK Version 1.1****（**于1997-02-19发行**）**

引入的新特性包括：

·    引入JDBC（Java Database Connectivity）；

·    支持内部类；

·    引入Java Bean；

·    引入RMI（Remote Method Invocation）；

·    引入反射（仅用于内省）。

 

**J2SE Version 1.2****（**于1998-12-08发行**）**

开发代号为Playground（操场）。引入的新特性包括：

·    引入集合（Collection）框架；

·    对字符串常量做内存映射；

·    引入JIT（Just In Time）编译器；

·    引入对打包的Java文件进行数字签名；

·    引入控制授权访问系统资源的策略工具；

·    引入JFC（Java Foundation Classes），包括Swing 1.0、拖放和Java 2D类库；

·    引入Java 插件；

·    在JDBC中引入可滚动结果集、BLOB、CLOB、批量更新和用户自定义类型；

·    在Applet中添加声音支持。

 

**J2SE Version 1.3****（**于2000-05-08发行**）**

开发代号为Kestrel（红隼）。引入的新特性包括：

·    引入Java Sound API；

·    jar文件索引；

·    对Java的各个方面都做了大量优化和增强。

 

**J2SE Version 1.4****（**于2004-02-06发行（首次在JCP下发行）**）**

开发代号为Merlin（隼）。引入的新特性包括:

·    XML处理；

·    Java打印服务；

·    引入Logging API；

·    引入Java Web Start；

·    引入JDBC 3.0 API；

·    引入断言；

·    引入Preferences API；

·    引入链式异常处理；

·    支持IPv6；

·    支持正则表达式；

·    引入Image I/O slot machine API。

 

**Java Version SE 5.0****（**于2004-09-30发行**）**

开发代号为Tiger（老虎）。引入的新特性包括:

·    引入泛型：了解泛型底层的实现，语法糖，伪泛型，类型擦除；

·    增强循环，可以使用迭代方式：for-each：for(int i=0; i<a.length; i++) {… …} 》 for(int i:a){......}；

·    自动装箱与自动拆箱：原始类型与对应的包装类不用显式转换；

·    类型安全的枚举；

·    可变参数：int sum(int ...nums)有任意个参数，把他看作数组；

·    静态引入：static import：Math.sqrt();  》  sqrt();；

·    元数据（注解）；

·    引入Instrumentation。

 

**Java Version SE 6****（**于2006-12-11发行**）**

开发代号为Mustang（野马）。引入的新特性包括：

·    支持脚本语言；

·    引入JDBC 4.0 API；

·    引入Java Compiler API；

·    插入式注解处理：插入式注解处理API(JSR 269)提供一套标准API来处理Annotations；

·    增强的for循环语句：for ( int number : getNumberList())

·    增加对Native PKI(Public Key Infrastructure)、Java GSS(Generic Security Service)、Kerberos和LDAP(Lightweight Directory Access Protocol)的支持；

·    继承Web Services；

·    做了很多优化，监视和管理：对内存泄漏增强了分析以及诊断能力。当遇到java.lang.OutOfMemory异常的时候，可以得到一个完整的堆栈信息，并且当堆已经满了的时候，会产生一个Log文件来记录这个致命错误。另外，JVM还添加了一个选项，允许你在堆满的时候运行脚本。

 

**Java Version SE 7****（**于2011-07-28发行**）**

开发代号是Dolphin（海豚）。引入的新特性包括：

·    模块化特性：Java7也是采用了模块的划分方式来提速，一些不是必须的模块并没有下载和安装，当虚拟机需要的时候，再下载相应的模块，同时对启动速度也有了很大的改善。

·    switch语句块中允许以字符串作为分支条件；

·    在多线程并发与控制方面：轻量级的分离与合并框架，一个支持并发访问的HashMap等等。

·    通过注解增强程序的静态检查。

·    多动态语言支持：Java7的虚拟机对多种动态程序语言增加了支持，比如：Rubby、Python等等；

·    引入Java NIO.2开发包：提供了一些新的API用于文件系统的访问、异步的输入输出操作、Socket通道的配置与绑定、多点数据包的传送等等；

·    执行效率的提高：对对象指针由64位压缩到与32位指针相匹配的技术使得内存和内存带块的消耗得到了很大的降低因而提高了执行效率。

·    提供了新的垃圾回收机制：（G1）来降低垃圾回收的负载和增强垃圾回收的效果。

·    数值类型可以用2进制字符串表示，并且可以在字符串表示中添加下划线；

·    在创建泛型对象时应用类型推断；

·    在一个语句块中捕获多种异常；

·    引入了一个新的异常处理结构来自动管理资源：try-with-resources；

·    null值的自动处理。

·    钻石型语法；

 

**Java SE 8****（**于2014-3-14发布**）**     相关视频：[极客学院Java8新特性视频教程](http://www.php.cn/course/613.html)

从Java 8开始开发代号已经弃用了，所以没有官方的开发代号了。Java SE 8中的新特性：

·    接口的Default方法：Java 8允许我们使用 default关键字给接口添加一个非抽象的方法实现，这个特征又叫做扩展方法。

·    方法与构造函数引用：Java 8 允许你使用 **::** 关键字来传递方法或者构造函数引用，通常用类名”**.**“来引用一个静态方法，我们也可以引用一个对象的方法，代码如下：

converter = something**::**startsWith;

String converted = converter.convert("Java");

System.out.println(converted);

·    Lambda表达式：在Java 8 中没必要使用传统的匿名对象的方式，提供了更简洁的语法：

Collections.sort(names, (String a, String b) -> {

return b.compareTo(a);

});

·    Lambda 作用域：在Lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。

访问局部变量：可以直接在lambda表达式中访问标记了final的外层局部变量。

访问对象字段与静态变量：和本地变量不同的是Lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的。

·    函数式接口：Lambda表达式是如何在Java的类型系统中表示的呢？每一个Lambda表达式都对应一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的Lambda表达式都会被匹配到这个抽象方法。因为默认方法不算抽象方法，所以你也可以给你的函数式接口添加默认方法。

·    访问接口的默认方法：

JDK 1.8 API包含了很多内建的函数式接口，在老Java中常用到的比如Comparator或者Runnable接口，这些接口都增加了@FunctionalInterface注解以便能用在lambda上。

Java 8 API同样还提供了很多全新的函数式接口来让工作更加方便，有一些接口是来自Google Guava库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到Lambda上使用的。

·    Pipelines和Streams

·    Date和Time API

·    Type注解

·    Nashhorn JavaScript引擎

·    并发计数器

·    Parallel操作

·    移除PermGen Error

·    TLS SNI

 

**JDK1.9** **新特性：（2017.9.21发布）**

\1. Java 平台级modularity System模块系统

​    Modularity提供了类似于OSGI框架的功能，模块之间存在相互的依赖关系，可以导出一个公共的API，并且隐藏实现的细节。引入模块系统，是为了解决公共类JAR文件（已经存在、或者重复项）相互依赖关系，真正地对代码进行封装，精简JDK减少内存的开销。

\2. Linking

当你使用具有显式依赖关系的模块和模块化的JDK时，这可以通过Java 9中的新的 jlink 工具实现，创建针对你的应用程序进行优化的最小运行时映像而不需要使用完全加载JDK安装版本。

\3. JShell : 交互式 Java REPL

​    许多语言已经具有交互式编程环境，Java 现在加入了这个俱乐部。您可以从控制台启动 jshell ，并直接启动输入和执行Java代码。jshell 的即时反馈使它成为探索API和尝试语言特性的好工具。

\4. Html5风格的Java帮助文档

​    Javadoc 现在支持在API文档中进行搜索。另外，每个Javadoc页面输出符合兼容HTML5标准，还包含有关JDK模块类或接口来源的信息。

\5. 不可变集合类的工厂方法

通常，您希望在代码中创建一个集合（例如，List 或 Set ），并直接用一些元素填充它。实例化集合，几个“add”调用，使得代码重复。Java 9，添加了几种集合工厂方法：

  Set<Integer> ints = Set.of(1,2,3);  List<String> strings =  List.of("first","second");  

除了更短和更好阅读之外，这些方法也可以避免您选择特定的集合实现。事实上，从工厂方法返回已放入数个元素的集合实现是高度优化的。因为它们是不可变的：在创建后，继续添加元素到这些集合会导致“UnsupportedOperationException”。

\6. 改进的 Stream API

通过这套Stream API可以在集合上建立用于转换的申明管道。在Stream接口中添加了4个新方法：dropWhile, takeWhile, ofNullable，还有个iterate方法的新重载方法，可以让你提供一个 Predicate (判断条件)来指定什么时候结束迭代：

```
Stream.of(1,2,3,2,1).dropWhile(i -> i < 3)``.collect(Collectors.toList()); // [3,2,1]``Stream.of(1,2,3,2,1).takeWhile(i -> i < 3)``.collect(Collectors.toList()); // [1,2]``IntStream.iterate(1, i -> i <100, i -> i + 1)``.forEach(System.out::println);
```

除了对 Stream 本身的扩展，Optional 和 Stream 之间的结合也得到了改进。现在可以通过 Optional 的新方法 ` stream ` 将一个 Optional 对象转换为一个(可能是空的) Stream 对象：

  Stream<Integer>  s = Optional.of(1).stream();  

在组合复杂的 Stream 管道时，将Optional转换为Stream非常有用。

\7. 引入Reactive Streams API：是一个发布订阅型框架，使我们能够非常简单地使用 Java 语言就能实现异步的、可拓展的和并行的应用。Java SE 9引进下面这些API来开发Reactive Streams：

- java.util.concurrent.Flow
- java.util.concurrent.Flow.Publisher
- java.util.concurrent.Flow.Subscriber
- java.util.concurrent.Flow.Processor

\8. 接口中的私有方法

Java 8 为我们带来了接口的默认方法。接口现在也可以包含行为，而不仅仅是方法签名。但是，如果在接口上有几个默认方法，都有一部分代码几乎相同，会发生什么情况？通常，您将重构这些方法，调用一个可复用的私有方法。但默认方法不能是私有的。将复用代码创建为一个默认方法不是一个解决方案，因为该辅助方法会成为公共API的一部分。使用Java 9，您可以向接口添加私有辅助方法来解决此问题：

  public  interface MyInterface {  void  normalInterfaceMethod();  default  void interfaceMethodWithDefault(){  init();  // 差异部分代码  … …  }  default  void anotherDefaultMethod(){  init();  //差异部分代码 … …  }     //  This method is not part of the public API exposed by MyInterface  private void init(){  System.out.println("Initializing");  }  }  

\9. HTTP 2 Client API

Oracle在“java.net.http”包下引入新的 HTTP 2 Client API处理HTTP调用，用于代替老旧的 `HttpURLConnection` API。它将同时支持 HTTP/1.1 和 HTTP/2 协议，也同时支持同步（Blocking Mode）和异步模式，支持 WebSocket API 使用中的异步模式。

  HttpClient  client = HttpClient.newHttpClient();  HttpRequest  req = HttpRequest.newBuilder(URI.create(  "http://www.google.com"  )).header("User-Agent",  "Java").GET().build();     HttpResponse<String>  resp = client.send(req, HttpResponse.BodyHandler.asString());  

除了这个简单的请求/响应模型之外，HttpClient 还提供了新的API来处理HTTP/2的特性，比如流和服务端推送。

\10. 多版本兼容JAR

解决Java旧版本切换新版本，向后兼容不能在库中运用新版Java库所提供的新特性。幸运的是，多版本兼容JAR功能能让你创建仅在特定版本的Java环境中运行库程序时选择使用的class版本。

 

# JDK 1.8 G1垃圾收集算法的改进？

G1（Garbage First）提供的一个工作在新生代基于“复制算法”和老年代基于“标记-整理”算法实现的收集器，在收集结束后可以避免内存碎片问题。

1. 并行与并发：充分利用多CPU来缩短Stop The World的停顿时间；
2. 分代收集：不需要其他收集配合就可以管理整个Java堆，采用不同的方式处理新建的对象、已经存活一段时间和经历过多次GC的对象获取更好的收集效果;
3. 空间整合：与CMS的”标记-清除”算法不同，G1在运行期间不会产生内存空间碎片，有利于应用的长时间运行，且分配大对象时，不会导致由于无法申请到足够大的连续内存而提前触发一次Full GC;
4. 停顿预测：G1中可以建立可预测的停顿时间模型，能让使用者明确指定在M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。

 

1、优化G1性能调优的参数项。开发人员仅仅需要声明以下参数即可：

-XX:+UseG1GC –Xmx16g -XX:MaxGCPauseMillis=200

​    其中-XX:+UseG1GC为开启G1垃圾收集器，-Xmx16g 设计堆内存的最大内存为16G，-XX:MaxGCPauseMillis=200设置GC的最大暂停时间为200ms。如果我们需要调优，在内存大小一定的情况下，我们只需要修改最大暂停时间即可。

 

2、G1将Java整个堆的内存布局划分为多个大小相等的独立区域Region，新生代和老年代不再是物理隔离，都是一部分Region（不需要连续）的集合。取消了新生代，老年代的物理空间划分。这样我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。

 

3、移除了永久代（Permanent Generation）使用本地化的内存存放类的元数据，这个空间叫做元空间（Metaspace）。

 

# Java8新特性如何使用，函数式编程为什么要添加进来

​    **方法引用**(Method Reference)，在Java8中用**“****::****”**双冒号操作符来直接访问类或者实例的已经存在的方法或者构造方法。方法引用提供了一种引用而不执行方法的方式，它需要由兼容的函数式接口构成的目标类型上下文。计算时，方法引用会创建函数式接口的一个实例。我们可以直接通过方法引用来**简写**lambda表达式中已经存在的方法。方法引用分类：

| **类型**     | **语法**           | **对应的****Lambda****表达式**       |
| ------------ | ------------------ | ------------------------------------ |
| 静态方法引用 | 类名::staticMethod | (args) -> 类名.staticMethod(args)    |
| 实例方法引用 | inst::instMethod   | (args) -> inst.instMethod(args)      |
| 对象方法引用 | 类名::instMethod   | (inst,args) -> 类名.instMethod(args) |
| 构建方法引用 | 类名::new          | (args) -> new 类名(args)             |

​    面向对象编程是对数据进行抽象，而[函数式编程](https://www.baidu.com/s?wd=函数式编程&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)是对（某一类共有的）行为进行抽象。Java8新引入函数式编程方式，函数式编程语法能够精简代码，大大的提高了编码效率。在面对大型数据集合时，为了能够更加高效的开发，编写的代码更加易于维护，更加容易运行在多核CPU上，Java在语言层面增加了Lambda表达式。Lambda表达式即匿名函数，它是一段没有函数名的函数体，可以作为参数直接传递给相关调用者。而函数式接口是Java支持函数式编程的基础。

​    **函数式接口**(Functional Interface)**：**是Java8中新定义了一种接口类型，它与其他接口的区别：

\1. 函数式接口中只能有一个抽象方法（但是可以有多个非抽象方法，还不包括与Object的方法重名的方法，在Java9允许接口中定义私有实现方法，封装给Java8允许接口默认方法内部调用）；

\2. 可以有从Object继承过来的抽象方法，因为所有类的最终父类都是Object；

\3. 接口中唯一抽象方法的命名并不重要，因为函数式接口就是对某一行为进行抽象，主要目的就是可以被隐式（匿名）转换为Lambda表达式。

​    一般通过@FunctionalInterface这个注解来表明某个接口是一个函数式接口,虽然这个注解的使用不是强制性的，但是使用它的好处是让此接口的目的更加明确，同时编译器也会对代码进行检查，来确保被该注解标注的接口的使用没有语法错误。

​    此前就有Comparator<T>和Runnable函数式接口，Java8在java.util.function包下又内置了四种核心函数式接口：

| **函数式接口** | **参数类型** | **返回类型** | **用途**                                                     |
| -------------- | ------------ | ------------ | ------------------------------------------------------------ |
| Consumer       | T            | 无           | 消费型接口，对类型T参数操作，无返回结果，包含方法 void accept(T t) |
| Supplier       | 无           | T            | 供给型接口，返回T类型参数，方法时 T get()                    |
| Function       | T            | R            | 函数型接口，对类型T参数操作，返回R类型参数，包含方法 R apply（T t） |
| Predicate      | T            | boolean      | 断言型接口，对类型T进行条件筛选操作，返回boolean，包含方法 boolean test（T t） |

 

# Java9比Java8改进了什么；

**String****底层存储结构更换：**Java8之前 String的底层结构类型都是 char[] ,但是Java9 就替换成 byte[] 这样来讲，更节省了空间和提高了性能。

**接口规范改进：**可私有接口的方法，默认和静态方法更好的共享接口的私有方法。若私有方法为静态该方法属于这个接口，不为静态则只能被该接口的实例调用。

**提供创建不可变集合的静态工厂方法**

List、Set、Map 接口中，提供新的静态工厂方法直接创建不可变的集合实例。

作用：创建不可变集合更方便，一行代码就搞定，节省了开销。

**私有接口方法**

在接口中也允许编写 private 修饰的私有方法了。

作用：增强了接口的功能，提高了可扩展性。

 

# 说一下Java多线程之内存可见性

​    （其实就是java的volatile实现原理，我补充了volatile的禁止指令重排序的原理。这里我扯到了synchronized的JVM底层实现原理，AQS工具包。）

​    首先要明确一点，每个线程都有属于自己的工作内存。除了线程自己拥有的工作内存外，还有公共的物理主内存。如果一个变量在多个线程的工作内存中都存在副本，那么这个变量就是这几个线程的**共享变量**。若其中一个线程对共享变量的修改，能够被其它线程看到，那么就能说明共享变量在线程之间是**可见的**。**为什么会出现共享变量可见性的问题？**这是因为JMM中线程操作内存的两个基本规定：①线程对共享变量的所有操作都必须在自己的工作内存中进行，不能从主内存中读写；②而且不同线程之间无法直接访问其它线程工作内存中的变量，线程间变量值的传递需要通过主内存来完成。

​    Java语言层面支持的可见性实现方式有两种：

n **1****、Synchronized**：不仅能通过互斥锁来实现同步（原子性），而且还能够实现可见性。**线程解锁前对共享变量的修改在下次加锁时对其他线程可见，****JMM****关于synchronized 的两条规定：**

u 线程解锁前，必须把共享变量的最新值刷新到主内存中；

u 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁需要的是同一把锁）

**线程执行互斥代码的过程：**

1、 获得互斥锁

2、 清空工作内存

3、 从主内存拷贝变量的最新副本到工作内存

4、 执行代码

5、 将更改后的共享变量的值刷新到主内存

6、 释放互斥锁

n **2****、volatile**：通过加入内存屏障和禁止指令重排序优化来实现可见性的，**但不保证原子性**。

u 对volatile变量执行**写**操作时，会在写操作后加入一条store屏障指令，这样就会把读写时的数据缓存加载到主内存中；

u 对volatile变量执行**读**操作时，会在读操作前加入一条load屏障指令，这样就会从主内存中加载变量；

​    所以说，volatile变量在每次被线程访问时，都强迫从主内存中重读该变量的值，而当该变量发生变化时，就会强迫线程将最新的值刷新到主内存，这样任何时刻，不同的线程总能看到该变量的最新值。

# 除了volatile还有什么方法保证数据一致性

volatile的使用场景：

l 状态标志(开关模式) 

l 双重检查锁定

l 需要利用顺序性（防止指令重排序）。

除了volatile在多线程情况下能保证数据一致性，还有以下3种方法：

l 使用synchronized关键字

l 使用Lock锁

l 使用Atomic原子类

# 深入剖析volatile关键字

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。

2）禁止进行指令重排序。volatile关键字禁止指令重排序有两层意思：

　　（A）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；

　　（B）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。

volatile 关键字的作用是禁止指令的重排序，强制从公共堆栈（主存）中取得变量的值，而不是从线程私有的数据栈（工作内存）中取变量的值。

先看一段代码，假如线程1先执行，线程2后执行：

// 线程1

boolean stop = false;

while(!stop){

  doSomething();

}

 

// 线程2

stop = true;

 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。

下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。

那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。

但是用volatile修饰之后就变得不一样了：

第一：使用volatile关键字会强制将修改的值立即写入主存；

第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；

第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。

那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。那么线程1读取到的就是最新的正确的值。

从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？

​    不能。读**->**存工作内存**->**操作**->**写工作内存**->**写主存。只能synchronized和Lock锁来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。

**volatile****的原理和实现机制**

前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。

下面这段话摘自《深入理解Java虚拟机》：

“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”

lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；

2）它会强制将对缓存的修改操作立即写入主存；

3）如果是写操作，它会导致其他CPU中对应的缓存行无效。

使用volatile必须具备以下2个条件：

　　1）对变量的写操作不依赖于当前值

　　2）该变量没有包含在具有其他变量的不变式中

列举几个Java中使用volatile的几个场景：1.状态标记量，**2.double check****。**

# 什么是内存屏障？

l **内存屏障**（Memory Barrier）是一种CPU指令。

​    内存屏障也称为内存栅栏或栅栏指令，是一种屏障指令，它使CPU或编译器对屏障指令之前和之后发出的内存操作执行一个排序约束。目前的高级处理器CPU，为了提高内部逻辑元件的利用率以提高运行速度，通常会采用多指令发射、乱序执行等各种措施。现在普遍使用的一些超标量处理器通常能够在 一个指令周期内并发执行多条指令。**可以解决数据一致性问题：**由于编译器的优化和缓存的使用，导致对内存的写入操作不能及时的反应出来，也就是说当完成对内存的写入操作之后，读取出来的可能是旧的内容。为了防止编译器和硬件的不正确优化，使得对存储器的访问顺序（其实就是变量）和书写程序时的访问顺序不一致而提出的一种解决办法。

​    **内存屏障的分类：**

1、 编译器引起的内存屏障

2、 缓存引起的内存屏障

3、 乱序执行引起的内存屏障

**按功能分类有以下四种：**

   **1****、write（或store）内存屏障**

   保证所有该屏障之前的store操作，看起来一定在所有该屏障之后的store操作之前执行。

   **2****、read（或load）内存屏障**

   保证所有该屏障之前的load操作，看起来一定在所有该屏障之后的load操作之前执行。仅保证load指令上的偏序关系，不要求对store指令有什么影响。

   **3****、数据依赖屏障**

   是read屏障的一种较弱形式。在执行两个load指令，第二个依赖于第一个的执行结果（例如：第一个load执行获取某个地址，第二个load指令取该地址的值）时，可能就需要一个数据依赖屏障，来确保第二个load指令在获取目标地址值的时候，第一个load指令已经更新过该地址。仅保证相互依赖的load指令上的偏序关系，不要求对store指令，无关联的load指令以及重叠的load指令有什么影响。

   **4****、通用内存屏障**

   确保所有该屏障之前的load和store操作，看起来一定在所有屏障之后的load和store操作之前执行。它能保证load和store指令上的偏序关系。

   **5****、一对隐式的屏障变种（LOCK和UNLOCK操作）：**

   LOCK操作可以看作是一个单向渗透的屏障。它保证所有在LOCK之后的内存操作看起来一定在LOCK操作后才发生。

   UNLOCK操作也是一个单向渗透屏障。它保证所有UNLOCK操作之前的内存操作看起来一定在UNLOCK操作之前发生。

 

​    实际运用场景：volatile便是基于内存屏障实现的。可以了解一下Dekker算法中的内存屏障。该算法利用volatile变量协调两个线程之间的共享资源访问。

# 什么是内存对齐？

l **内存对齐：**

​    内存地址对齐，是一种在计算机内存中排列数据（表现为变量的地址）、访问数据（表现为CPU读取数据）的一种方式，包含了两种相互独立又相互关联的部分：基本数据对齐和结构体数据对齐 。

​    为什么需要内存对齐？对齐有什么好处？是我们程序员来手动做内存对齐呢？还是编译器在进行自动优化的时候完成这项工作？

​    在现代计算机体系中，每次读写内存中数据，都是按字（word，4个字节，对于X86架构，系统是32位，数据总线和地址总线的宽度都是32位，所以最大的寻址空间为2的32次方 = 4GB，按A[31,30…2,1,0]这样排列，但是请注意为了CPU每次读写 4个字节寻址，A[0]和A[1]两位是不参与寻址计算的。）为一个块（chunks）来操作（而对于X64则是8个字节为一个快）。注意，这里说的 CPU每次读取的规则，并不是变量在内存中地址对齐规则。既然是这样的，如果变量在内存中存储的时候也按照这样的对齐规则，就可以加快CPU读写内存的速度，当然也就提高了整个程序的性能，并且性能提升是客观，虽然当今的CPU的处理数据速度(是指逻辑运算等,不包括取址)远比内存访问的速度快，程序的执 行速度的瓶颈往往不是CPU的处理速度不够，而是内存访问的延迟，虽然当今CPU中加入了高速缓存用来掩盖内存访问的延迟，但是如果高密集的内存访问，这种延迟是无可避免的，内存地址对齐会给程序带来了很大的性能提升。

  内存地址对齐是计算机语言自动进行的，也即是编译器所做的工作。但这不意味着我们程序员不需要做任何事情，因为如果我们能够遵循某些规则，可以让编译器做得更好，毕竟编译器不是万能的。

**1****、基本数据对齐**

​    在X86，32位系统下基于Microsoft、Borland和GNU的编译器，有如下数据对齐规则：

​    a、一个char（占用1-byte）变量以1-byte对齐。

​    b、一个short（占用2-byte）变量以2-byte对齐。

​    c、一个int（占用4-byte）变量以4-byte对齐。

​    d、一个long（占用4-byte）变量以4-byte对齐。

​    e、一个float（占用4-byte）变量以4-byte对齐。

​    f、一个double（占用8-byte）变量以8-byte对齐。

​    g、一个long double（占用12-byte）变量以4-byte对齐。

​    h、任何pointer（占用4-byte）变量以4-byte对齐。

​    **而在64位系统下，与上面规则对比有如下不同：**

​    a、一个long（占用8-byte）变量以8-byte对齐。

​    b、一个double（占用8-byte）变量以8-byte对齐。

​    c、一个long double（占用16-byte）变量以16-byte对齐。

​    d、任何pointer（占用8-byte）变量以8-byte对齐。

  **2****、结构体数据对齐**

  结构体数据对齐，是指结构体内的各个数据对齐。在结构体中的第一个成员的首地址等于整个结构体的变量的首地址，而后的成员的地址随着它声明的顺序和实际占用的字节数递增。为了总的结构体大小对齐，会在结构体中插入一些没有实际意思的字符来**填充（padding）**结构体。

  在结构体中，成员数据对齐满足以下规则：

  a、结构体中的第一个成员的首地址也即是结构体变量的首地址。

  b、结构体中的每一个成员的首地址相对于结构体的首地址的偏移量（offset）是该成员数据类型大小的整数倍。

  c、结构体的总大小是对齐模数（对齐模数等于#pragma pack(n)所指定的n与结构体中最大数据类型的成员大小的最小值）的整数倍。

# Synchronized锁粒度（使用方法和作用域）

1、修饰**方法**：在范围操作符之后，返回类型声明之前使用。每次只能有一个线程进入该方法，

​    此时线程获得的是**方法锁**。

​    public synchronized void method(){ }

2、修饰**代码块**：每次只能有一个线程进入该代码块，

​       此时线程获得的是（this）**对象锁**。

​    public void method() {synchronized(this) {// dosomething }}

3、修饰**对象**：如果当前线程进入，那么其他线程在该类所有对象上的任何操作都不能进行，

​       此时当前线程获得的是**对象锁**。

​    public void method() {synchronized(objInstance) {// dosomething }}

4、修饰**类**：如果当前线程进入，那么其他线程在该类中所有操作不能进行，包括静态变量和静态方法，

​       此时当前线程获得的是Class**类对象锁**。

   public void method1() {synchronized(MyClass.class){ }}

   public static synchronized void method2(){ }

# Java的synchronized加在静态方法和动态方法的区别？

synchronized修饰静态方法，是对该类对象（XXX.class)加锁，俗称“类锁”。对于静态同步方法，锁是针对这个类的，锁对象是该类的Class对象。静态和非静态方法的锁互不干预。例如：

public static synchronized void method1( ) {  }

public static void method1( ) { synchronized(Xxx.class) {  } }

synchronized修饰非静态方法，是对调用该方法的对象加锁，俗称“对象锁”。静态同步方法和非静态同步方法将永远不会彼此阻塞，因为静态方法锁定在Class对象上，非静态方法锁定在该类的对象上。

public synchronized void method1() {  }

public void method1() { synchronized(this) {  } }

一个线程获得锁，当在一个同步方法中访问另外对象上的同步方法时，会获取这两个对象锁。

# 静态方法跟非静态方法的锁区别

**类锁（又称全局锁，static synchronized）**

​    synchronized修饰静态方法，该锁是对该类Class对象加锁，无论实例出多少个对象，类对象只有一个，那么线程依然共享该锁。和用单例模式声明一个对象来调用非静态方法的情况是一样的，因为永远就只有这一个对象。所以访问同步方法之间一定是互斥的。

​    static synchronized是限制多线程中该类的所有实例同时访问该类所对应的代码块。

**注意：**

1、static synchronized并不是关键字，只是代表给静态方法加锁。

2、锁住的只是static synchronized块，synchronized块锁不住，而不加锁的方法更加锁不住

**对象锁（实例锁，synchronized）**

​    synchronized修饰非静态方法，该锁是对调用该方法的当前实例对象加锁，每个对象有且仅有唯一的1个锁。

​    synchronized是对类的当前实例（当前对象）进行加锁，防止其他线程同时访问该类的该实例的所有synchronized块。

**注意：**

1、指的是“类的当前实例”， 类的两个不同实例就没有这种约束了。

2、锁住的只是synchronized块，static synchronized块锁不住，而不加锁的方法更加锁不住。

**总结:**

·    静态方法的锁属于类, 一个类中所有加锁的静态方法共用该锁

·    非静态方法的锁属于对象, 一个对象中所有加锁的非静态方法共用, 和静态方法的锁不同而互不相干

·    加锁的方法的执行不会影响同一个类/对象中未加锁的方法的执行(因为其他方法没有锁呀)

# 何时需要同步

在多个线程同时并发访问同一个共享资源（全局变量）时，应该使用同步机制（独占方式访问）以保证此资源的数据安全。互斥确保不会同时修改它，即线程安全。要跨线程维护正确的可见性，只要在几个线程之间共享非 final 变量，就必须使用synchronized（或 volatile）以确保一个线程可以看见另一个线程做的更改。为了在线程之间进行可靠的通信，也为了互斥访问，同步是必须的。这归因于java语言规范的内存模型，它规定了：一个线程所做的变化何时以及如何变成对其它线程可见。因为多线程将异步行为引进程序，所以在需要同步时，必须有一种方法强制进行。

Java同步机制有4种实现方式：

**①ThreadLocal:** 线程级别作用域副本，既保证全局变量线程安全，又实现存在当前线程中多次访问全局变量的便利，如JDBC Connection对象，需在线程级别下多个方法多次访问数据库连接。

**②synchronized( )****：**监视器字节码指令monitorenter、monitorexit，重量级锁、悲观锁、内置锁

**③wait()****与notify()**：对象锁

**④volatile****：**内存屏障（Memory Barriers）不允许线程内部缓存（即直接修改内存）和重排序。

**监控器（Monitor）**是一个控制机制，可以认为是一个很小的、只能容纳一个线程的盒子，一旦一个线程进入监控器，其它的线程必须等待，直到那个线程退出监控为止。通过这种方式，一个监控器可以保证共享资源在同一时刻只可被一个线程使用。这种方式称之为同步。

**锁（Lock）**提供了两种主要特性：互斥（mutual exclusion）和可见性（visibility）。**互斥**即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样，一次就只有一个线程能够使用该共享数据。**可见性**要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 —— 如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，造成数据不一致导致计算结果错误。

# 进程与线程的区别

​    **进程：**是并发执行的程序在执行过程中分配和管理资源的基本单位，是一个动态概念，竞争计算机系统资源的基本单位。

​    **线程：**是进程的一个执行单元，是进程内科调度实体，也是处理器调度的基本单位。比进程更小的独立运行的基本单位。线程也被称为轻量级进程。

​    进程是（系统）资源分配最小单位，线程是程序执行的最小单位。关系是进程–>线程–>程序。所以线程是程序执行流的最小单位，而进程是系统进行资源分配和调度的一个独立单位。

**进程与线程的区别：**

·    **地址空间**：同一进程的线程共享本进程的地址空间，而进程之间则是独立的地址空间。

·    **资源拥有**：同一进程内的线程共享本进程的资源如内存、I/O、cpu等，但是进程之间的资源是独立的。线程占用的资源要⽐进程少很多。

·    **执行过程**：每个独立的进程都有一个程序运行的入口、顺序执行序列和程序入口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。

 

# 线程状态，以及相互转化的过程

![img](http://image.itstabber.com/2020-09-09/clip_image017.png)

\1.   **新建(new)**：新创建了一个线程对象，并没有调用start()方法之前。

\2.   **可运行(runnable)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权。

\3.   **运行(running)**：可运行状态(runnable)的线程获得了CPU时间片（timeslice），执行程序代码。

\4.   **阻塞(block)**：阻塞状态是指线程因为某种原因放弃了CPU使用权，也即让出了CPU timeslice，暂时停止运行（线程仍旧是活的）。直到线程进入可运行(runnable)状态，才有机会再次获得CPU timeslice转到运行(running)状态。阻塞的情况分三种：

**(****一). 等待阻塞**：运行(running)的线程执行锁对象的o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。

**(****二). 同步阻塞**：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(**lock** pool)中。

**(****三). 其他阻塞**: 运行(running)的线程执行睡眠Thread.sleep(**long** ms)或合并t.**join**()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时**join**()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

\5.   **死亡(dead)**：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

# 有哪些方式方法可以让线程离开运行状态？

1、调用Thread.sleep()：使当前线程睡眠至少多少毫秒（尽管它可能在指定的时间之前被中断）。

2、调用Thread.yield()：不能保障太多事情，尽管通常它会让当前运行线程回到可运行性状态，使得有相同优先级的线程有机会执行。

3、调用join()方法：保证当前线程停止执行，直到该线程所加入的线程完成为止。然而，如果它加入的线程没有存活，则当前线程不需要停止。

除了以上三种方式外，还有下面几种特殊情况可能使线程离开运行状态：

1、线程的run()方法完成。

2、在持有锁的对象上调用wait()方法（不是在线程上调用）。

3、线程未能获得对象锁（阻塞状态），它正试图运行该对象的同步方法或同步代码。

4、线程调度程序可以决定将当前运行状态移动到可运行状态，以便让另一个线程获得运行机会，而不需要任何理由。

# 锁类型

可重入锁：在执行对象中所有同步方法不用再次获得锁

可中断锁：在等待获取锁过程中可中断

公平锁： 按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利

读写锁：对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写

# 两种锁机制的底层的实现策略

**互斥同步**最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。synchronized采用的便是这种并发策略。

  随着指令集的发展，我们有了另一种选择：基于冲突检测的**乐观并发策略**，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock采用的便是这种并发策略。

  在**乐观并发策略**中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是CAS操作（Compare and Swap）。JDK1.5之后，Java程序才可以使用CAS操作。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState，这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。

  Java 5中引入了注入AutomicInteger、AutomicLong、AutomicReference等特殊的原子性变量类，它们提供的如：compareAndSet（）、incrementAndSet（）和getAndIncrement（）等方法都使用了CAS操作。因此，它们都是由硬件指令来保证的原子方法。

# Lock接口中主要有哪些方法

lock()：获取锁，如果锁被暂用则一直等待

unlock():释放锁

tryLock(): 注意返回类型是boolean，如果获取锁的时候锁被占用就返回false，否则返回true

tryLock(long time, TimeUnit unit)：比起tryLock()就是给了一个时间期限，保证等待参数时间

lockInterruptibly()：用该锁的获得方式，如果线程在获取锁的阶段进入了等待，那么可以中断此线程，先去做别的事

# Java锁Lock——ReentrantLock实现原理及源码分析

​    **Lock****完全用Java写成，在java这个层面是无关JVM实现的。在java.util.concurrent.locks包中有很多Lock的实现类，常用的有ReentrantLock、ReadWriteLock（实现类ReentrantReadWriteLock），其实现都依赖java.util.concurrent.AbstractQueuedSynchronizer类，实现思路都大同小异，因此我们以ReentrantLock作为讲解切入点。**

**ReentrantLock****是Java并发包中提供的一个可重入的互斥锁。ReentrantLock和synchronized在基本用法，行为语义上都是类似的，同样都具有可重入性。只不过相比原生的Synchronized，ReentrantLock增加了一些高级的扩展功能，比如它可以实现公平锁，同时也可以绑定多个Conditon。**

**ReentrantLock****是基于AQS的，AQS是基于CAS+CHL实现，它是Java并发包中众多同步组件的构建基础，它通过一个int类型的状态变量state和一个FIFO队列（CLH队列）来完成共享资源的获取，线程的排队等待等。AQS是个底层框架，采用模板方法模式，它定义了通用的较为复杂的逻辑骨架，比如线程的排队，阻塞，唤醒等，将这些复杂但实质通用的部分抽取出来，这些都是需要构建同步组件的使用者无需关心的，使用者仅需重写一些简单的指定的方法即可（其实就是对于共享变量state的一些简单的获取释放的操作）。**

l **ReentrantLock****的调用过程**

经过观察ReentrantLock把所有Lock接口的操作都委派到一个**Sync****类**上，该类继承了**AbstractQueuedSynchronizer**：

```
static abstract class Sync extends AbstractQueuedSynchronizer
```

Sync又有两个子类：

```
final static class NonfairSync extends Sync
final static class FairSync extends Sync
```

显然是为了支持公平锁和非公平锁而定义，默认情况下为非公平锁。

先理一下Reentrant.lock()方法的调用过程（默认非公平锁）：

![img](http://image.itstabber.com/2020-09-09/clip_image018.png)

这些讨厌的Template模式导致很难直观的看到整个调用过程，其实通过上面调用过程及AbstractQueuedSynchronizer的注释可以发现，AbstractQueuedSynchronizer中抽象了绝大多数Lock的功能，而只把tryAcquire方法延迟到子类中实现。tryAcquire方法的语义在于用具体子类判断请求线程是否可以获得锁，无论成功与否AbstractQueuedSynchronizer都将处理后面的流程。

l **CLH****队列**

AQS内部维护着一个FIFO的队列，即CLH队列。AQS的同步机制就是依靠CLH队列实现的。CLH队列是FIFO的双端双向队列，实现公平锁。线程通过AQS获取锁失败，就会将线程封装成一个Node节点，插入队列尾。当有线程释放锁时，后尝试把队头的next节点占用锁。**CLH****队列结构如下：**

![img](http://image.itstabber.com/2020-09-09/clip_image019.png)

CLH队列由Node对象组成，Node是AQS中的内部类。

l **锁实现（加锁）**

简单说来，AbstractQueuedSynchronizer会把所有的请求线程构成一个CLH队列，当一个线程执行完毕（lock.unlock()）时会激活自己的后继节点，但正在执行的线程并不在队列中，而那些等待执行的线程全部处于阻塞状态，经过调查线程的显式阻塞是通过调用LockSupport.park()完成，而LockSupport.park()则调用sun.misc.Unsafe.park()本地方法，再进一步，HotSpot在Linux中中通过调用pthread_mutex_lock函数把线程交给系统内核进行阻塞。该队列如图：

p(predecessor) 前任，前辈，前身；mutex：n，互斥、互斥锁、互斥体、互斥元、互斥量

![img](http://image.itstabber.com/2020-09-09/clip_image020.png)

与synchronized相同的是，这也是一个虚拟队列，不存在队列实例，仅存在节点之间的前后关系。令人疑惑的是为什么采用CLH队列呢？原生的CLH队列是用于自旋锁，但Doug Lea把其改造为阻塞锁。
 **当有线程竞争锁时，该线程会首先尝试获得锁，这对于那些已经在队列中排队的线程来说显得不公平，这也是非公平锁的由来**，与synchronized实现类似，这样会极大提高吞吐量。

如果已经存在Running线程，则新的竞争线程会被追加到队尾，具体是采用基于CAS（Compare and Swap）的Lock-Free算法，因为线程并发对Tail调用CAS可能会导致其他线程CAS失败，解决办法是**循环CAS直至成功**。AbstractQueuedSynchronizer的实现非常精巧，令人叹为观止，不入细节难以完全领会其精髓，下面详细说明实现过程：

l **1 Sync.nonfairTryAcquire**

nonfairTryAcquire方法将是lock方法间接调用的第一个方法，每次请求锁时都会首先调用该方法。

l **2 AbstractQueuedSynchronizer.addWaiter**

addWaiter方法负责把**当前无法获得锁的线程包装为一个Node添加到队尾**

l **3 AbstractQueuedSynchronizer.acquireQueued**

acquireQueued的主要作用是把已经追加到队列的线程节点（addWaiter方法返回值）进行阻塞，但阻塞前又通过tryAccquire重试是否能获得锁，如果重试成功能则无需阻塞，直接返回。

LockSupport.park最终把线程交给系统（Linux）内核进行阻塞。当然也不是马上把请求不到锁的线程进行阻塞，还要检查该线程的状态。

l **解锁**

​    解锁代码相对简单，主要体现在AbstractQueuedSynchronizer.release和Sync.tryRelease方法。tryRelease与tryAcquire语义相同，把如何释放的逻辑延迟到子类中。tryRelease语义很明确：如果线程多次锁定，则进行多次释放，直至status==0则真正释放锁，所谓释放锁即设置status为0，因为无竞争所以没有使用CAS。release的语义在于：如果可以释放锁，则唤醒队列第一个线程（Head），最后通知系统内核继续该线程，在Linux下是通过pthread_mutex_unlock完成。

p(predecessor) 前任，前辈，前身；mutex：n，互斥、互斥锁、互斥体、互斥元、互斥量

# 说一下悲观锁和乐观锁，synchronized（内置锁、悲观锁）和lock（CAS乐观锁）的区别

​    简答介绍悲观锁和乐观锁的含义，有对具体锁的实现举了例子，比如乐观锁CAS实现，悲观锁synchronized又引入了乐观锁CAS的**ABA问题**（采用版本号，每次更新把版本号加一，那么A－B－A检查变化就会变成1A-2B－3A）。

​    AbstractQueuedSynchronizer通过构造一个基于阻塞的CLH队列容纳所有的阻塞线程，而对该队列的操作均通过Lock-Free（CAS）操作，但对已经获得锁的线程而言，ReentrantLock实现了偏向锁的功能。synchronized的底层也是一个基于CAS操作的等待队列，但JVM实现的更精细，把等待队列分为ContentionList和EntryList，目的是为了降低线程的出列速度；当然也实现了偏向锁，从数据结构来说二者设计没有本质区别。但synchronized还实现了自旋锁，并针对不同的系统和硬件体系进行了优化，而Lock则完全依靠系统阻塞挂起等待线程。

​    当然Lock比synchronized更适合在应用层扩展，可以继承AbstractQueuedSynchronizer定义各种实现，比如实现读写锁（ReadWriteLock），公平或不公平锁；同时，Lock对应的Condition也比wait/notify要方便的多、灵活的多。

# Synchronized和ReentrantLock关系与区别汇总

# synchronized底层实现原理和过程？并与reentrantlock区别？

（1）synchronized是JVM层面的实现的，JVM会确保释放锁，而且synchronized使用简单；而Lock是个普通类，需要在代码中finally中显式释放锁lock.unlock()，但是使用灵活。

（2）synchronized采用的是悲观锁机制，线程获得独占锁，而其他线程只能阻塞来等待释放锁。当竞争激烈时，CPU频繁的上下文切换会降低效率（PS：JDK1.6~1.7对Synchronized做了优化实现）。而Lock是乐观锁机制，每次假设不存在竞争而不上锁，若存在竞争就重试。当竞争激烈时JVM可以花更少的时间来调度线程，把更多时间用在执行线程上，因此性能最佳。

（3）ReentrantLock可以实现定时锁、轮询锁，可以选择放弃等待或者轮询请求。有效防止了死锁。

lock();//用来获取锁，如果锁已被其他线程获取，则进行等待 

tryLock(); //尝试获取锁，若成功返回true，失败（即锁已被其他线程获取）则返回false 

tryLock(long timeout, TimeUnit unit); //在拿不到锁时会等待一定的时间 

//两个线程同时通过lock.lockInterruptibly()想获取某个锁时 

//若线程A获取到了锁，而线程B在等待 

//线程B调用threadB.interrupt()方法能够中断线程B的等待过程 

lockInterruptibly(); 

（4）synchronized是非公平锁。而ReentrantLock可以通过构造函数传入true实现公平锁，即按照申请锁顺序获得锁。

（5）ReentrantLock类有一个重要的函数newCondition()，用于获取Lock上的一个条件，Condition可用于线程间通信。

# 详解synchronized与Lock的区别与使用

[详解synchronized与Lock的区别与使用](https://blog.csdn.net/u012403290/article/details/64910926)

[java中synchronized和lock底层原理](https://blog.csdn.net/SumResort_LChaowei/article/details/72857921)

l **两者的区别：**

![img](http://image.itstabber.com/2020-09-09/clip_image021.png)

​    在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞的是实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。多线程环境下，synchronized的吞吐量下降的非常严重，而ReentrankLock则能基本保持在同一个比较稳定的水平上。

  到了JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。官方也表示，他们也更支持synchronize，在未来的版本中还有优化余地，所以还是提倡在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步。

l **synchronized****的原理**

​    其实synchronized映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。(内存屏障|内存栅栏)在java语言中存在两种内建的synchronized语法：1、synchronized语句；2、synchronized方法。对于synchronized语句当Java源代码被javac编译成bytecode的时候，会在同步块的入口位置和退出位置分别插入MonitorEnter和MonitorExit字节码指令。而synchronized方法则会被翻译成普通的方法调用和返回指令如:InvokeVirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。

l **synchronized****的具体 ：** 

\1. 线程状态及状态转换

  当多个线程同时请求某个对象监视器时，对象监视器会设置几种状态用来区分请求的线程：

Contention List：所有请求锁的线程将被首先放置到该竞争队列

Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List

Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set

OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck

Owner：获得锁的线程称为Owner

!Owner：释放锁的线程

下图反映了个状态转换关系：

![img](http://image.itstabber.com/2020-09-09/clip_image022.png)

　　新请求锁的线程将首先被加入到ConetentionList中，当某个拥有锁的线程（Owner状态）调用unlock之后，如果发现EntryList为空则从ContentionList中移动线程到EntryList，下面说明下ContentionList和EntryList的实现方式：

**1.1 Contention List****虚拟队列**

　　Contention List并不是一个真正的Queue，而只是一个虚拟队列，原因在于ContentionList是由Node及其next指针逻辑构成，并不存在一个Queue的数据结构。ContentionList是一个后进先出（LIFO）的队列，每次新加入Node时都会在队头进行，通过CAS改变第一个节点的的指针为新增节点，同时设置新增节点的next指向后续节点，而取得操作则发生在队尾。显然，该结构其实是个Lock-Free的队列。

因为只有Owner线程才能从队尾取元素，也即线程出列操作无争用，当然也就避免了CAS的ABA问题。

![img](http://image.itstabber.com/2020-09-09/clip_image023.png)

**1.2 EntryList**

EntryList与ContentionList逻辑上同属等待队列，ContentionList会被线程并发访问，为了降低对ContentionList队尾的争用，而建立EntryList。Owner线程在unlock时会从ContentionList中迁移线程到EntryList，并会指定EntryList中的某个线程（一般为Head）为Ready（OnDeck）线程。Owner线程并不是把锁传递给OnDeck线程，只是把竞争锁的权利交给OnDeck，OnDeck线程需要重新竞争锁。这样做虽然牺牲了一定的公平性，但极大的提高了整体吞吐量，在Hotspot中把OnDeck的选择行为称之为“竞争切换”。

OnDeck线程获得锁后即变为owner线程，无法获得锁则会依然留在EntryList中，考虑到公平性，在EntryList中的位置不发生变化（依然在队头）。如果Owner线程被wait方法阻塞，则转移到WaitSet队列；如果在某个时刻被notify/notifyAll唤醒，则再次转移到EntryList。

# 1 . 什么是可重入锁

​    锁的概念就不用多解释了,当某个线程A已经持有了一个锁,当线程B尝试进入被这个锁保护的代码段的时候.就会被阻塞.而锁的操作粒度是”线程”,而不是调用(至于为什么要这样,下面解释).同一个线程再次进入同步代码的时候.可以使用自己已经获取到的锁,这就是可重入锁。java里面内置锁(synchronize)和Lock(ReentrantLock)都是可重入的。

# 2 . 为什么要可重入

​    如果线程A继续再次获得这个锁呢？比如一个方法是synchronized，递归调用自己，那么第一次已经获得了锁，第二次调用的时候还能进入吗？直观上当然需要能进入，这就要求必须是可重入的。可重入锁又叫做递归锁。再举个例子：

public class Widget {

​    public synchronized void doSomething() {

​      ...

​    }

}

public class LoggingWidget extends Widget {

​    public synchronized void doSomething() {

​      System.out.println(toString() + ": calling doSomething");

​      super.doSomething();// 若内置锁是不可重入的，则发生死锁

​    }

}

这个例子是java并发编程实战中的例子，synchronized是父类Widget的内置锁，当执行子类的方法时，先获取了一次Widget的锁，然后在执行super时，就要获取一次，如果不可重入，那么就跪了。

# 3 . 如何实现可重入锁

​    为每个锁关联一个**获取计数器和一个所有者线程，**当计数值为0的时候，这个所就没有被任何线程持有，当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1，如果同一个线程再次获取这个锁，计数值将递增，退出一次同步代码块，计算值递减，当计数值为0时，这个锁就被释放。ReentrantLock源码里面有实现 PS：可重入是指对同一线程而言。

# 4 . 有不可重入锁吗

​    Linux下的pthread_mutex_t锁是默认是非递归的，可以通过设置PTHREAD_MUTEX_RECURSIVE属性，将pthread_mutex_t锁设置为递归锁。如果要自己实现不可重入锁，同可重入锁，这个计数器只能为1或者0，再次进入的时候，发现已经是1了，就进行阻塞，JDK里面没有默认的实现类。

​    recursive：递归的、循环的

# 5 . demo代码展示

5.1 内置锁的可重入

```java
public class Reentrant {

  public void method1() {

​    synchronized (Reentrant.class) {

​      System.out.println("method1 run");

​      method2();

​    }

  }

 

  public void method2() {

​    synchronized (Reentrant.class) {

​      System.out.println("method2 run in method1");

​    }

  }

 

  public static void main(String[] args) {

​    new Reentrant().method1();

  }

}

 // Lock对象可重入

import java.util.concurrent.locks.Lock;

import java.util.concurrent.locks.ReentrantLock;



public class Reentrant2 {

  private Lock lock = new ReentrantLock();

 

  public void method1() {

​    lock.lock();

​    try {

​      System.out.println("method1 run");

​      method2();

​     } finally {

​      lock.unlock();

​    }

  }

 

  public void method2() {

​    lock.lock();

​    try {

​      System.out.println("method2 run in method1");

​    } finally {

​      lock.unlock();

​    }

  }

 

  public static void main(String[] args) {

​    new Reentrant2().method1();

  }

}


```



在同一线程里，method1调用持同样锁的method2，不会等锁。这就是锁的”重入”。

不同线程里锁不可重入。因为不可重入，所以不同线程可以看到T2一定会等到T1释放锁之后。

#  synchronized优化

​    简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）如果每次都调用Mutex Lock那么将严重的影响程序的性能。不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。

在jdk1.6~jdk1.7，对synchronized做了优化，具体优化如下：

**1****、线程自旋和适应性自旋**

​    java线程其实是映射在内核之上的，线程的挂起和恢复会极大的影响开销。并且jdk官方人员发现，很多线程在等待锁的时候，在很短的一段时间就获得了锁，所以它们在线程等待的时候，并不需要把线程挂起，而是让他无目的的循环，一般设置10次。这样就避免了线程切换的开销，极大的提升了性能。
 而适应性自旋，是赋予了自旋一种学习能力，它并不固定自旋10次一下。他可以根据它前面线程的自旋情况，从而调整它的自旋，甚至是不经过自旋而直接挂起。

**2****、锁消除（Lock Elimination）**

​    什么叫锁消除呢？就是把不必要的同步在编译阶段进行移除。通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配（同时还可以减少Heap上的垃圾收集开销）。

​    我自己写的代码我会不知道这里要不要加锁？我加了锁就是表示这边会有同步呀？并不是这样，这里所说的锁消除并不一定指代是你写的代码的锁消除，我打一个比方：

​    在jdk1.5以前，我们的String字符串拼接操作其实底层是StringBuffer来实现的（这个大家可以用我前面介绍的方法，写一个简单的demo，然后查看class文件中的字节码指令就清楚了），而在jdk1.5之后，那么是用StringBuilder来拼接的。我们考虑前面的情况，比如如下代码：

String str1="qwe";

String str2="asd";

String str3=str1+str2;

底层实现会变成这样：

StringBuffer sb = new StringBuffer();

sb.append("qwe");

sb.append("asd");

我们知道，StringBuffer是一个线程安全的类，也就是说两个append方法都会同步，通过指针逃逸分析（就是变量不会外泄），我们发现在这段代码并不存在线程安全问题，这个时候就会把这个同步锁消除。

**3****、锁粗化（Lock Coarsening）**

​    是减少不必要的紧连在一起的lock和unlock操作，将多个连续的锁扩展成一个范围更大的锁。在用synchronized的时候，我们都讲究为了避免大开销，尽量同步代码块要小。那么为什么还要加粗呢？我们继续以上面的字符串拼接为例，我们知道在这一段代码中，每一个append都需要同步一次，那么我可以把锁粗化到第一个append和最后一个append（这里不要去纠结前面的锁消除，我仅打个比方）

**4****、轻量级锁（Lightweight Locking）**

​    这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒。

**5****、偏向锁（Biased Locking）**

​    偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，虽然CAS原子指令相对于重量级锁来说开销比较小，但还是存在非常可观的本地延迟。

**6****、适应性自旋（Adaptive Spinning）**

​    当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁（mutex semaphore）前会进入忙等待（Spinning）然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore（即互斥锁）进入到阻塞状态。

ps：涉及对象头的内存布局，这些数据被称为 Mark Word

​    JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。虚拟机栈中的Lock record和锁对象对应。

​    **轻量级锁**是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。

​    当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 

​    如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 

​    **偏向锁**的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。 当锁对象第一次被线程获得锁时，进入偏向状态，标记为1。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

# 浅析以下两种锁机制的底层的实现策略:

  **互斥同步**最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。synchronized采用的便是这种并发策略。

  随着指令集的发展，我们有了另一种选择：基于冲突检测的**乐观并发策略**，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock采用的便是这种并发策略。

  在**乐观并发策略**中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是CAS操作（Compare and Swap）。JDK1.5之后，Java程序才可以使用CAS操作。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState，这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。

  Java 5中引入了注入AotomicInteger、AotomicLong、AotomicReference等特殊的原子性变量类，它们提供的如：compareAndSet（）、incrementAndSet（）和getAndIncrement（）等方法都使用了CAS操作。因此，它们都是由硬件指令来保证的原子方法。

# ReentrantLock与synchronized用途比较

​    基本语法上，ReentrantLock与synchronized很相似，它们都具备一样的线程重入特性，只是代码写法上有点区别而已，一个表现为API层面的互斥锁（Lock），一个表现为原生语法层面的互斥锁（synchronized）。除此之外ReentrantLock还增加了一些高级功能，主要有以下三项：

  **1****、等待可中断**：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常上的同步块很有帮助。而在等待由synchronized产生的互斥锁时，会一直阻塞，是不能被中断的。

  **2****、可实现公平锁**：多个线程在等待同一个锁时，必须按照申请锁的时间顺序排队等待，而非公平锁则不保证这点，在锁释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁为非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过构造方法ReentrantLock(ture)来使用公平锁。

  **3****、锁可以绑定多个条件**：ReentrantLock对象可以同时绑定多个Condition对象（名曰：条件变量或条件队列），而在synchronized中，锁对象的wait（）和notify（）或notifyAll（）方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无需这么做，只需要多次调用newCondition()方法即可。而且我们还可以通过绑定Condition对象来判断当前线程通知的是哪些线程（即与Condition对象绑定在一起的其他线程）。

# [我们常说的 CAS 自旋锁是什么](https://www.cnblogs.com/fengzheng/p/9018152.html)

​    CAS（Compare and swap），即比较并交换，也是实现我们平时所说的自旋锁或乐观锁的核心操作。它的实现很简单，就是用一个预期的值和内存值进行比较，如果两个值相等，就用预期的值替换内存值，并返回 true。否则，返回 false。

l **使用场景（保证原子操作）：**

CAS 适合简单对象的操作，比如布尔值、整型值等；

CAS 适合冲突较少的情况，如果太多线程在同时自旋，那么长时间循环会导致 CPU 开销很大；

l **ABA****问题**

​    CAS 存在一个问题，就是一个值从 A 变为 B ，又从 B 变回了 A，这种情况下，CAS 会认为值没有发生过变化，但实际上是有变化的。对此，并发包下倒是有 AtomicStampedReference 提供了根据**版本号**判断的实现，可以解决一部分问题。

# 浅析一下ReentrantLock的Condition用法

（1）通过Condition能够更加精细的控制多线程的休眠与唤醒。

（2）对于一个锁，我们可以为多个线程间建立不同的Condition。

**1.** **使用Condition实现一个ArrayBlockingQueue**

我们将实现的MyArrayBlockingQueue类需要包括以下功能：

（1）如果一个线程调用该类的take()获取元素时，若集合为空则使调用线程阻塞。直到有其他线程为集合加入新元素。

（2）如果一个线程调用该类的put()添加新元素时，若集合满了则使调用线程阻塞。直到有其他线程从集合充take出数据。

**1.1** **内部成员以及构造方法**

从下面源码中可以看出，我们使用了泛型，并且默认使用长度为10的数组来维护数据集合。定义了一个锁，并且根据锁的lock.newCondition()创建了两个条件，分别对应集合满和集合空两个条件。

```java
//维护的数据

private final T[] datas;

//数据的个数

private int count;

//插入取出的索引

private int put_index;

private int take_index;

 

//锁

private final Lock lock = new ReentrantLock();

//定义两个条件，分别为“集合满”和“集合空”

private Condition full = lock.newCondition();

private Condition empty = lock.newCondition();

​      

//提供MyArrayBlockingQueue的构造方法，初始化T[]数据

public MyArrayBlockingQueue() {

  this(10);

}

​      

public MyArrayBlockingQueue(int maxSize) {

  this.datas = (T[]) new Object[maxSize];

}
```



**1.2 put/get****方法**

```java
public void put(T data){

  lock.lock();
  try {
​      if(count == datas.length){
​           //此时集合已经满了
​           System.out.println("集合已满，请等待...");
​           //使调用线程挂起
​           full.await();
​      }
​      //不满则添加新元素
​      datas[put_index++] = data;
​      count++;
​                
​      //此时唤醒等待取数据的线程
​      empty.signalAll();
​                
​    } catch (Exception e) {
​      e.printStackTrace();
​      }finally{
​           lock.unlock();
​           }
}

public T take(){
​      lock.lock();
​      try {
​        if(count == 0){
​           //此时集合已经空了
​           System.out.println("集合已空，请等待...");
​           //使调用线程挂起
​           empty.await();
​        }
​               

​        //不空则取出最后一个数据
​        take_index = count - 1;
​        T result = datas[take_index--];
​        count--;
​                
​        //此时唤醒等待写数据的线程
​        full.signalAll();
​                
​        return result;
​                
​       } catch (Exception e) {

​           e.printStackTrace();
​      }finally{

​           lock.unlock();
​      }
​      return null;

}
```



​    put方法中，如果集合满了，就调用await()方法使对应的线程释放锁，并且使调用线程阻塞。直到其他线程调用了take()方法，并调用了full.signalAll()时，该请求线程会被精准唤醒，重新竞争到锁后，代码继续往下执行。

​    若集合不满，则添加新元素，并且通过empty.signalAll()精准唤醒等待取数据的线程。

可以看到在take方法中也是类似的逻辑。这样就灵活并且方便的使用Condition完成了一个简单的线程安全的阻塞队列，一些角标等细节没有处理，毕竟主角是Condition。

**2.** **总结**

在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。Condition的强大之处在于，对于一个锁，我们可以为多个线程间建立不同的Condition。

如果采用Object类中的wait(), notify(), notifyAll()实现的话，当写入数据之后需要唤醒读线程时，不可能通过notify()或notifyAll()明确的指定唤醒读线程，而只能通过notifyAll唤醒所有线程，但是notifyAll无法区分唤醒的线程是读线程，还是写线程。所以，通过Condition能够更加精细的控制多线程的休眠与唤醒。

# CountDownLatch是什么？如何工作（执行过程）？应用场景？

​    [CountDownLatch](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/CountDownLatch.html)是一个计数器闭锁，主要的功能就是通过await()方法来阻塞住当前线程，然后等待计数器countdown()减少到0了，再唤起这些线程继续执行。是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。CountDownLatch的伪代码如下所示：

//Main thread start

//Create CountDownLatch for N threads 

//Create and start N threads

//Main thread wait on latch （待执行的程序先执行，这里通过CountDownLatch的值来判断前面的线程是否执行完毕，如果没有执行完毕会一直卡着）

//N threads completes there tasks are returns

//Main thread resume execution

**执行过程：**

构造器中的计数值（count）实际上就是闭锁需要等待的线程数量。这个值只能被设置一次，而且CountDownLatch没有提供任何机制去重新设置这个计数值。与CountDownLatch的第一次交互是主线程等待其他线程。主线程必须在启动其他线程后立即调用CountDownLatch.await()方法。这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。（重要）其他N个线程必须引用闭锁对象，因为他们需要通知CountDownLatch对象，他们已经完成了各自的任务。这种通知机制是通过 CountDownLatch.countDown()方法来完成的；每调用一次这个方法，在构造函数中初始化的count值就减1。所以当N个线程都调 用了这个方法，count的值等于0，然后主线程就能通过await()方法，恢复执行自己的任务。

**在实时系统中的使用场景**

​    尝试罗列出在java实时系统中CountDownLatch都有哪些使用场景。我所能想到的如下：

\1.   **实现最大的并行性**：有时我们想同时启动多个线程，实现最大程度的并行性。例如，我们想测试一个单例类。如果我们创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，那么我们可以很轻松地完成测试。我们只需调用 一次countDown()方法就可以让所有的等待线程同时恢复执行。

\2.   **开始执行前等待n个线程完成各自任务**：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了。

\3.   **死锁检测：**一个非常方便的使用场景是，你可以使用n个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。

# Semaphore（信号量）

Semaphore与CountDownLatch相似，不同的地方在于Semaphore的值被获取到后是可以释放的，并不像CountDownLatch那样一直减到底。它也被更多地用来限制流量，类似阀门的功能。如果限定某些资源最多有N个线程可以访问，那么超过N个主不允许再有线程来访问，同时当现有线程结束后，就会释放，然后允许新的线程进来。有点类似于锁的lock与unlock过程。可以用Semaphore来实现限流场景。相对来说他也有两个主要的方法：

用于获取权限的acquire(),其底层实现与CountDownLatch.countdown()类似;

用于释放权限的release()，其底层实现与acquire()是一个互逆的过程。

# CyclicBarrier（屏障、关卡）

CyclicBarrier是用来一个关卡来阻挡住所有线程，等所有线程全部执行到关卡处时，再统一执行下一步操作，它里面最重要的方法是await()方法。即每个线程执行完后调用await(),然后在await()里，线程先将计数器减1,如果计数器为0，则执行定义好的操作，然后再继续执行原线程的内容。这个类比之前两个类的一个好处是有点类似于切面编程，可以让我们在同类线程的某个切面切入一块逻辑，并且可以同步所有的线程的执行速度。

# ThreadLocal线程安全原理

**ThreadLocal****提供了线程的本地副本，也就是说每个线程将会拥有一个自己独立的变量副本。它**本身并没有承担存储每个线程中的数据的职责，它是通过操作每个线程内部的一个“副本”-ThreadLocalMap（是ThreadLocal的静态内部类，他是一个设计用来保存thread local 变量的自定义的hash map，key为ThreadLocal<this>本身，所有的操作方法都是私有的，也就是不对外暴露任何操作方法，也就是只能在ThreadLocal中使用）来实现线程之间的隔离，从而保证了线程安全。ThreadLocal操作值的时候是取得当前线程的ThreadLocalMap对象，然后把值设置到了这个对象中，这样对于不同的线程得到的就是不同的ThreadLocalMap，那么向其中保存值或者修改值都只是会影响到当前线程，这样就保证了线程安全。Synchronized（同步访问）关键字也用来解决多线程环境下访问变量的问题，这两者的**区别**在于ThreadLocal是用空间换取时间，synchronized关键字是用时间换空间。

若两个线程同时对一个ThreadLocal变量进行操作，互相之间是没有影响的，换句话说，这很显然并不是用来解决共享变量的一些并发问题，比如多线程的协作。因为ThreadLocal的设计理念就是共享**变私有**，都已经私有了，还谈啥共享？但是共享变私有，如同并发变串行，或许适合解决一些场景的线程安全问题，因为看起来就如同没有共享变量了，不共享即安全，但是他并不是为了解决线程安全问题而存在的。**一个线程中一个，也就是线程隔离，既然是一个线程一个，那么同一个线程中调用的方法也就是共享了，所以说，有时，ThreadLocal会被用来作为参数传递的工具。**因为它能够保障同一个线程中的值是唯一的，那么他就共享于所有的方法中，对于所有的方法来说，相当于一个全局变量了！

**所以可以用来同一个线程内全局参数传递****。****不过要慎用，因为“全局变量”的使用对于维护性、易读性都是挑战，尤其是ThreadLocal这种线程隔离，但是方法共享的“全局变量”。**

# ThreadLocal最根本的使用场景

​    在每个线程希望有一个独有的变量时（这个变量还很可能需要在同一个线程内共享），为了避免每个线程还需要主动地去创建这个对象（如果还需要共享，也一并解决了参数来回传递的问题）。换句话说就是，“如何优雅的解决：线程间隔离与线程内共享的问题”，而不是说用来解决线程安全问题。所以说如果有些场景你需要线程隔离，那么考虑ThreadLocal，而不是你有了什么线程安全问题需要解决，然后求助于ThreadLocal。既然能够线程内共享，自然的确是可以用来线程内全局传参，但是不要滥用，再次注意：

​    ThreadLocal只是具有这样的能力，是你能够做到每个线程一个独有变量，但是如果你set时，不是传递的**new**出来的**新**变量，也就只是理解成“每个线程不同的引用”，对象还是那个对象（有点像参数传递时的值传递，对于对象传递的就是**引用**）。

​    ThreadLocal可以用来优雅的解决线程间隔离的对象，即线程独有的对象，通常都是通过new创建，再借助于ThreadLocal无需在线程中每个方法之前传递参数或重新显式的创建对象，解决方案很优雅。

```
public class DateFormatWrapper {
    private static final SimpleDateFormat SDF = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
    // format(); parse();
}
```

​    经测试发现，SimpleDateFormat 在多线程共享的情况下，不仅可能会出现结果错误的情况，还可能会由于并发访问导致运行异常。当然，我们肯定有解决的办法：

1. 为 DateFormatWrapper 的 format 和 parse 方法加上 synchronized 关键字，坏处就是前面提到的这会加大线程间的竞争和切换而降低效率；
2. 不使用全局的 SimpleDateFormat 对象，而是每次使用 format 和 parse 方法都新建一个 SimpleDateFormat 对象，坏处也很明显，每次调用 format 或者 parse 方法都要新建一个 SimpleDateFormat，这会加大 GC 的负担；
3. 使用 ThreadLocal。ThreadLocal<SimpleDateFormat> 可以为每个线程提供一个独立的 SimpleDateFormat 对象，创建的 SimpleDateFormat 对象个数最多和线程个数相同，相比于 (1)，使用ThreadLocal不存在线程间的竞争；相比于 (2)，使用ThreadLocal创建的 SimpleDateFormat 对象个数也更加合理（不会超过线程的数量）。

我们使用 ThreadLocal 来对 DateFormatWrapper 进行修改，使得每个线程使用单独的 SimpleDateFormat：

```
public class DateFormatWrapper {
 
    private static final ThreadLocal<SimpleDateFormat> SDF = new ThreadLocal<SimpleDateFormat>() {
        @Override
        protected SimpleDateFormat initialValue() {
            return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
        }
    };
 
    public static String format(Date date) {
        return SDF.get().format(date);
    }
 
    public static Date parse(String str) throws ParseException {
        return SDF.get().parse(str);
    }
}
```

如果使用 Java8，则初始化 `ThreadLocal` 对象的代码可以改为：

```
private static final ThreadLocal<SimpleDateFormat> SDF
            = ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"));
```

 

# ThreadLocal什么时候会出现OOM（内存泄漏）的情况？为什么？

​    ThreadLocal很好地解决了线程数据隔离的问题，但是很显然，也引入了另一个空间问题。如果线程数量很多，如果ThreadLocal类型的变量很多，将会占用非常大的空间。而对于ThreadLocal本身来说，他只是作为key，数据并不会存储在它的内部，所以对于ThreadLocal“壳”操作的副本ThreadLocalMap内部的这个Entity的key是弱引用（WeakReference<ThreadLocal<?>>）。

![img](http://image.itstabber.com/2020-09-09/clip_image024.png)

​    如上图所示，实线表示强引用，虚线表示弱引用。对于真实的值是保存在Thread里面的ThreadLocal.ThreadLocalMap threadLocals中的，借助于内部的这个map，通过“壳”ThreadLocal变量的get，可以获取到这个map的真正的值，也就是说，当前线程中持有对真实值value的强引用

而对于ThreadLocal变量本身，如下代码所示，栈中的变量与堆空间中的这个对象，也是强引用的

 static ThreadLocal<String> threadLocal = new ThreadLocal<>();

不过对于Entity来说，key是弱引用。当一系列的执行结束之后，ThreadLocal的强引用也会消亡，也就是堆与栈之间的从ThreadLocal Ref到ThreadLocal的箭头会断开。由于Entity中，对于key是弱引用，所以ThreadLocal变量会被回收（GC时会回收弱引用），而对于线程来说，如果迟迟不结束，那么就会一直存在：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value的强引用，所以value迟迟得不到回收，就会可能导致内存泄漏 。ThreadLocalMap的设计中已经考虑到这种情况，所以ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。一旦将value设置为null之后，就斩断了引用于真实内存之间的引用，就能够真正的释放空间，防止内存泄漏。

![cwKfZ0](http://image.itstabber.com/2020-09-09/cwKfZ0.jpg)

但是这只是一种**被动**的方式，如果这些方法都没有被调用怎么办？

而且现在对于多线程来说，都是使用**线程池**，那个线程很可能是与应用程序共生死的，怎么办？

那你就每次使用完ThreadLocal变量之后，执行remove方法！！！！

从以上分析也看得出来，由于ThreadLocalMap的生命周期跟Thread一样长，所以很可能导致内存泄漏，弱引用是相当于增加了一种防护手段，通过key的弱引用，以及remove方法等内置逻辑，通过合理的处理，减少了内存泄漏的可能，如果不规范，就仍旧会导致内存泄漏。

 

# JAVA多线程之线程间的通信方式

l **①synchronized****同步**

​    这里讲的同步是指多个线程通过synchronized关键字这种方式来实现线程间的通信。由于线程A和线程B持有同一个MyObject类的对象object，尽管这两个线程需要调用不同的方法，但是它们是同步执行的，比如：线程B需要等待线程A执行完了methodA()方法之后，它才能执行methodB()方法。这样，线程A和线程B就实现了 通信。

​    这种方式，本质上就是“**共享内存**”式的通信。多个线程需要访问同一个**共享变量**，谁拿到了**锁**（获得了访问权限），谁就可以执行。在Java 中 volatile，synchronized 以及各种锁机制，均为了解决线程间公共状态的串行访问问题。

l **②while****轮询的方式**

​    在这种方式下，线程A不断地改变条件，线程ThreadB不停地通过while语句检测特定的某个条件是否成立，从而实现了线程间的通信。但是**这种方式会浪费CPU资源**。之所以说它浪费资源，是因为JVM调度器将CPU交给线程B执行时，它没做啥“有用”的工作，只是在不断地测试某个条件是否成立。*就类似于现实生活中，某个人一直看着手机屏幕是否有电话来了，而不是： 在干别的事情，当有电话来时，响铃通知TA电话来了。*关于线程的轮询的影响，[可参考：](http://www.cnblogs.com/hapjin/p/5467984.html)[JAVA多线程之当一个线程在执行死循环时会影响另外一个线程吗？](http://www.cnblogs.com/hapjin/p/5467984.html)

​    这种方式还存在另外一个问题：轮询的条件的可见性问题，关于内存可见性问题，可参考：[JAVA多线程之volatile 与 synchronized 的比较](http://www.cnblogs.com/hapjin/p/5492880.html)中的第一点“**一，volatile关键字的可见性**”。线程都是先把变量读取到本地线程栈空间，然后再去再去修改的本地变量。因此，如果线程B每次都在取本地的条件变量，那么尽管另外一个线程已经改变了轮询的条件，它也察觉不到，这样也会造成**死循环**。

l **③wait/notify****机制 （**必须在synchronized中使用**）**

​    线程A要等待某个条件满足时才执行操作，线程B则不断地改变这个条件。A,B之间如何通信的呢？也就是说，线程A如何知道这个条件已经满足了呢？这里用到了Object类的 wait() 和 notify() 方法。

当条件未满足时，线程A调用wait() 放弃CPU，并进入阻塞状态。（---不像②while轮询那样占用CPU）当条件满足时，线程B调用notify()通知 线程A，所谓通知线程A，就是唤醒线程A，并让它进入可运行状态。这种方式的一个好处就是CPU的利用率提高了。

​    但也有一些缺点：比如，线程B先执行，一下子就到达了A线程满足的条件，并调用了notify()发送了通知，而此时线程A还执行（没有处理等待阻塞状态）；当线程A执行并调用wait()时，那它永远就不可能被唤醒了。因为，线程B已经发了通知了，以后不再发通知了。这说明：**通知过早，会打乱程序的执行逻辑**。

l **④管道通信**

​    就是使用java.io.PipedInputStream 和 java.io.PipedOutputStream进行通信。管道流过程：生产者向管道中输出数据，消费者从管道中读取数据。当然，生产者的管道输出要与消费者的管道输入进行连接。

​    **总结：**分布式系统中说的两种通信机制：**共享内存机制**和**消息通信机制**。感觉前面的①中的synchronized关键字和②中的while轮询“属于”共享内存机制，由于是轮询的条件使用了volatile关键字修饰时，这就表示它们通过判断这个“共享的条件变量“是否改变了，来实现进程间的交流。而**管道通信**，更像消息传递机制，也就是说：通过管道，将一个线程中的消息发送给另一个。

​    当然还有其他类似的通信方式，如：

​       1、使用 `**Thread.join()**`方法，保证代码阻塞，直到子线程执行完毕再继续执行；

​    2、**Lock**锁提供了一个`**Condition**`类来保持协调替代了同步监视器的功能；

​    3、使用**阻塞队列**（`**BlockingQueue**`它最主要作用不是作为容器，而是作为线程同步工具）。

| **BlockingQueue****方法** | **抛出异常** | **不同返回值** | **阻塞线程** | **指定超时时长**   |
| ------------------------- | ------------ | -------------- | ------------ | ------------------ |
| **队尾插入元素**          | add(e)       | offer(e)       | put(e)       | offer(e,time,unit) |
| **队头删除元素**          | remove()     | poll()         | take()       | poll(time,unit)    |
| **获取、不删除元素**      | element()    | peek()         | 无           | 无                 |

 

# wait(10)代表什么？

```
public final native void wait(long timeout) throws InterruptedException;
```

​    表示在持有对象锁的前提下，在其他线程调用此对象的 `notify()` 方法或 `notifyAll()` 方法通知唤醒之前，或者超过指定的时间量（单位：milliseconds毫秒）之前，导致当前线程等待。也就是说，最多会让当前线程进入阻塞状态等待10毫秒。阻塞等待时，会释放互斥锁。

​    **wait****()****方法**的实现细节是将当前线程放入**阻塞线程队列**中，再把当前线程注册为指定对象的监听器，并且释放指定对象的锁；当被notify/notifyAll通知时，重新争取指定对象的锁，并把当前线程从指定对象的监听器中移除，把当前线程从阻塞队列放入**就绪队列**，等待被调度。只有当重新占用互斥锁之后才会进入可运行状态。此方法必须在sychronized代码块中，且锁定的对象要与等待通知来源的对象一致。如果当前线程不是对象锁的持有者，会抛出java.lang.IllegalMonitorStateException 异常”。

​    而**wait****(****long**` **timeout**`**)****方法**阻塞时放入的是**就绪队列**，等待时间到期或被通知就可被调度，其他与wait()方法相同。

# 线程的交互[——wait，notify，notifyAll，synchronized](https://www.cnblogs.com/lixuwu/p/10534787.html){ }

1、wait、notify以及notifyAll都是Object对象的方法，他们必须在被 synchronized 同步方法或同步代码块中调用（同步环境即当前线程拥有对象锁的情况下），否则会报错。

2、调用wait()会使当前线程进入等待状态，并且会释放被同步对象的锁，直到其他线程调用该对象的notify() 方法或 notifyAll() 方法。

3、notify()唤醒在此对象监视器上等待的单个线程。可以唤醒一个因执行wait而处于阻塞状态的线程，使其进入就绪状态，被唤醒的线程会去尝试着获取对象锁，然后执行wait之后的代码。如果发出notify操作时，没有线程处于阻塞状态，那么该命令会忽略。注意执行notify并不会马上释放对象锁，会等到执行完该同步方法或同步代码块后才释放。notify方法可以随机唤醒等待队列中等待同一共享资源的“一个”线程，使其退出等待队列进入可运行状态。

4、notifyAll()唤醒在此对象监视器上等待的所有线程。可以唤醒等待队列中等待同一共享资源的“全部”线程从等待状态退出，进入可运行状态。此时，优先级最高的那个线程优先执行，但也有可能是随机执行，这取决于JVM虚拟机的实现。

**最后说下 wait和sleep的区别，这也是面试经常面到的问题。**

l sleep是Thread类的方法而wait是Object类的方法。

l sleep不会立马释放对象锁，而wait会释放。

 

# 死锁（Java多线程死锁和数据库死锁），工作中怎么解决？

**一、多线程死锁是怎么造成的？**

1. 多线程锁定同一**资源**（共享变量、锁、磁盘、线程池中的线程、网络连接池的连接、数据库引擎锁等）会造成死锁；
2. 线程池中的任务使用当前线程池也可能出现死锁。

```
@Slf4j
public class DeadLock2 {
 
      public static void main(String[] args) {
            ExecutorService pool = Executors.newFixedThreadPool(1);
            pool.submit(() -> {
                try{
                    log.info("First");
                    pool.submit(() -> log.info("second")).get();
                    log.info("third");
                }catch (InterruptedException | ExecutionException e){
                    log.error("Error",e);
                }
            });
            System.out.println("process is over");
      }
}
```

死锁出现了！我们来一步一步分析：

l 打印“First”的任务被提交到只有一个线程的线程池

l 任务开始执行并打印“First”

l 我们向线程池提交了一个内部任务，来打印“Second”

l 内部任务进入等待任务队列。没有可用线程因为唯一的线程正在被占用

l 我们阻塞住并等待内部任务执行结果。不幸的是，我们等待内部任务的同时也在占用着唯一的可用线程

l get() 方法无限等待，无法获取线程

l 死锁

l **死锁预防，避免死锁**

1、尽量避免加多个锁，嵌套死锁

2、以确定的顺序获得锁：加锁顺序

3、超时放弃（加锁限时）：Lock接口提供了`boolean tryLock(long time, TimeUnit unit) throws InterruptedException`方法，该方法可以按照固定时长等待锁，因此线程可以在获取锁超时以后，主动释放之前已经获得的所有的锁。通过这种方式，也可以很有效地避免死锁。

4、工具检测死锁

l **检测工具1：Jstack命令**

jstack是java虚拟机自带的一种堆栈跟踪工具。用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。还可以用于生成java虚拟机当前时刻的线程快照。**线程快照**是当前java虚拟机内每一条线程**正在执行**的**方法堆栈**的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如`线程间死锁`、`死循环`、`请求外部资源导致的长时间等待`等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。

**首先**，我们通过jps确定当前执行任务的进程号:

```
jonny@~$ jps
1370 JConsole
1362 AppMain
1421 Jps
1361 Launcher
```

可以确定任务进程号是1362，**然后**执行jstack命令查看当前进程堆栈信息：

```
jonny@~$ jstack -F 1362
Attaching to process ID 1362, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 23.21-b01
Deadlock Detection:
Found one Java-level deadlock:
=============================
"Thread-1":
  waiting to lock Monitor@0x00007fea1900f6b8 (Object@0x00000007efa684c8, a java/lang/Object),
which is held by "Thread-0"
"Thread-0":
  waiting to lock Monitor@0x00007fea1900ceb0 (Object@0x00000007efa684d8, a java/lang/Object),
  which is held by "Thread-1"
Found a total of 1 deadlock.
```

可以看到，进程的确存在死锁，两个线程分别在等待对方持有的Object对象

l **检测工具2：JConsole工具**

​    Jconsole是JDK自带的监控工具，在JDK/bin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在Java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗。

我们在命令行中敲入jconsole命令，会自动弹出以下对话框，选择进程1362，并点击“链接”新建连接

进入所检测的进程后，选择“线程”选项卡，并点击“检测死锁”。

​    以上例子我都是用synchronized关键词实现的死锁，如果读者用ReentrantLock制造一次死锁，再次使用死锁检测工具，也同样能检测到死锁，不过显示的信息将会更加丰富。

**二、数据库死锁**

**1****、innodb隔离级别、索引与锁：****锁id主键行，锁二级索引对应主键行，没命中索引则锁全表**

**2****、锁与隔离级别的关系**

数据库的事务隔离级别：mysql> select @@tx_isolation;

l 未提交读RU（read uncommitted)

l 已提交读RC（read committed）：能读到已经提交的数据。

l 可重复读RR（repeatable read）：在同一个事务内查询都是事务开始时刻一致的，InnoDB默认级别。

l 串行化（Serializable)

[**详解MySQL****（InnoDB****）是如何处理死锁的**](https://www.cnblogs.com/mxb0611/p/12143494.html)

**一、什么是死锁****：**两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁。

**二、为什么会形成死锁**：MySQL的并发控制有两种方式，一个是 MVCC，一个是两阶段锁协议。

**两阶段锁协议（2PL）**官方定义：

​    两阶段锁协议是指所有事务必须分两个阶段对数据加锁和解锁，在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁；在释放一个封锁之后，事务不再申请和获得任何其他封锁。

对应到 MySQL 上分为两个阶段：

1. 扩展阶段（事务开始后，commit     之前）：获取锁
2. 收缩阶段（commit     之后）：释放锁

就是说呢，只有遵循两段锁协议，才能实现 可串行化调度。

但是两阶段锁协议不要求事务必须一次将所有需要使用的数据加锁，并且在加锁阶段没有顺序要求，所以这种并发控制方式会形成死锁。

**三、MySQL 如何处理死锁？**

MySQL有两种死锁处理方式：

1. 等待，直到超时（innodb_lock_wait_timeout=50s）。
2. 发起死锁检测，主动回滚一条事务，让其他事务继续执行（innodb_deadlock_detect=on）。

由于性能原因，一般都是使用死锁检测来进行处理死锁。

**死锁检测**

死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。

**回滚**

检测到死锁之后，选择插入更新或者删除的行数最少的事务回滚，基于 INFORMATION_SCHEMA.INNODB_TRX 表中的 trx_weight 字段来判断。

**四、如何避免发生死锁**

**收集死锁信息：**

1. 利用命令 SHOW     ENGINE INNODB STATUS查看死锁原因。
2. 调试阶段开启     innodb_print_all_deadlocks，收集所有死锁日志。
3. mysql>show full processlist; 查看当前库里面的线程情况，有sleep的线程事务一直没有commit或者rollback而是卡住了

**减少死锁：**

1. 使用事务，不使用     lock tables 。
2. 保证没有长事务。
3. 操作完之后立即提交事务，特别是在交互式命令行中。
4. 如果在用     (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)，尝试降低隔离级别。
5. 修改多个表或者多个行的时候，将修改的顺序保持一致。
6. 创建索引，可以使创建的锁更少。
7. 最好不要用     (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)。
8. 如果上述都无法解决问题，那么尝试使用 lock tables t1, t2, t3 锁多张表

# [MySQL的innoDB锁机制以及死锁处理](https://www.cnblogs.com/my_life/articles/10219562.html)

InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。行级锁与表级锁本来就有许多不同之处，innodb正常的select ID from table where id=1；不会上任何锁，接下来详细讨论InnoDB的锁问题;

**一：InnoDB行锁的介绍。**

**共享锁（S）**：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁,也就是我读取的行，你不能修改；

**排他锁（X)**：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。也就是我更新的行，不允许其他的事务读取和更新相同的行；

另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种**内部使用的意向锁（Intention Locks）**，这两种意向锁都是**表锁**。

意向共享锁（IS）：

  事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。

意向排他锁（IX）：

  事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加**排他锁（X)**；对于普通SELECT语句，InnoDB不会加任何锁；**事务**可以通过以下语句显示给记录集加共享锁或排他锁。

共享锁（S）：SELECT * FROM table_name WHERE ... **LOCK IN SHARE MODE**；

排他锁（X)：SELECT * FROM table_name WHERE ... **FOR UPDATE**；

InnoDB行锁模式兼容性列表：

 

如果一个**事务**请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。

 

**二：关于innodb锁机制，实现原理：**

InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**

索引分为**主键**索引和**二级索引【也就是非主键索引】**两种，**如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引;如果一条语句操作了二级索引，MySQL会先锁定该二级索引，再锁定相关的主键索引。**

然后innodb行锁分为三种情形：（三种锁级别：页级、表级、行级）

1）Record lock ：对索引项加锁，即锁定一条记录。

2）Gap lock：对索引项之间的‘间隙’、对第一条记录前的间隙或最后一条记录后的间隙加锁，即**锁定一个范围的记录，不包含记录本身**

3）Next-key Lock：锁定一个范围的记录并包含记录本身（上面两者的结合）。

注意：**InnoDB****默认级别是repeatable-read级别，所以下面说的都是在RR级别中的**。

**三：关于innodb锁机制需要注意的是：**

1）InnoDB行锁是通过给索引项加锁实现的，如果没有索引，InnoDB会通过隐藏的聚簇索引来对记录加锁。也就是说：如果不通过索引条件检索数据，那么InnoDB将对表中所有数据加锁，实际效果跟表锁一样。

2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。说白了就是，where id=1 for update 会锁定所有id=1的数据行，如果是where id=1 and name='liuwenhe' for update,这样会把所有 id=1以及所有name='liuwenhe'的行都上排它锁；

3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。

4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL优化器通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，或者隐式转换，或者like百分号在前等等，这种情况下InnoDB将使用表锁，而不是行锁。

因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。

 

**四：查看innodb的相关锁；**

1）查询相关的锁：

**information_schema** **库**中增加了三个关于锁的表：

innodb_trx    ## 当前运行的所有事务 ，还有具体的语句，

innodb_locks   ## 当前出现的锁，只有

innodb_lock_waits ## 锁等待的对应关系

**mysql> show processlist; ##****可以看出来当前库的等待线程情况**

或者

**mysql> show engine innodb status\G ##****也可以要看出相关死锁的问题**

或者：

mysql> select ID,STATE from information_schema.processlist where user='system user';

mysql> select concat('KILL ',id,';') from information_schema.processlist where user='system user';

批量kill多个进程。

mysql>select concat('KILL ',id,';') from information_schema.processlist where user='root' into outfile '/tmp/a.txt';

检查自动提交mysql> select @@autocommit;

设置自动提交mysql> set global autocommit=1;

**五：关于死锁：**

**MyISAM****表锁是deadlock free的**，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的**事务**外，**锁是逐步获得的【一个包含多条sql的事务】**，这就决定了在InnoDB中发生死锁是可能的。

发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数 **innodb_lock_wait_timeout**来解决。

需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。

通常来说，**死锁都是应用设计的问题**，通过调整业务流程、数据库对象设计、**事务大小**，以及访问数据库的SQL语句，绝大部分死锁都可以避免。

下面就通过实例来介绍几种避免死锁的常用方法。

（1）在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。

（2）在程序以批量方式处理数据的时候，如果事先**对数据排序**，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。

（3）在事务中，**如果要更新记录，应该直接申请足够级别的锁，即排他锁**，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。

如果出现死锁，可以用mysql> **show engine innodb status\G**命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

总结：MySQL innodb引擎的锁机制比myisam引擎机制复杂，但是innodb引擎支持更细粒度的锁机制，当然也会带来更多维护的代价；然后innodb的行级别是借助对索引项加锁实现的，值得注意的事如果表没有索引，那么就会上表级别的锁，同时借助行级锁中gap锁来解决部分幻读的问题。只要知道MySQL innodb中的锁的机制原理，那么再解决死锁或者避免死锁就会很容易！

# 线程的调度——休眠Thread.sleep()

线程休眠的目的是使线程让出CPU的最简单的做法之一，线程休眠时候，会将CPU资源交给其他线程，以便能轮换执行，当休眠一定时间后，线程会苏醒，进入准备状态等待执行。线程休眠的方法是Thread.sleep(long millis) 和Thread.sleep(long millis, int nanos) ，均为静态方法，哪个线程调用sleep，就休眠哪个线程。

# 线程的调度——优先级thread.setPriority(1~10)

与线程休眠类似，线程的优先级仍然无法保障线程的执行次序。只不过，优先级高的线程获取CPU资源的概率较大，优先级低的并非没机会执行。线程的优先级用1-10之间的整数表示，数值越大优先级越高，默认的优先级为5。在一个线程中开启另外一个新线程，则新开线程称为该线程的子线程，子线程初始优先级与父线程相同。

# 线程的调度——让步：Thread.yield()

线程的让步含义就是使当前运行着线程让出CPU资源，但是然给谁不知道，仅仅是让出，线程状态回到可运行状态。 线程的让步使用Thread.yield()方法，yield() 为静态方法，功能是暂停当前正在执行的线程对象，并执行其他线程。

# 线程的调度——合并thread.join()

线程的合并让主线程等待子线程运行结束后再继续运行，可以将几个并行线程当作子线程合并到一个主线程上执行，应用场景是当一个线程必须等待另一个线程执行完毕才能执行时可以使用join方法。join为非静态方法，定义如下：

void join()   等待该线程终止。

void join(long millis)  等待该线程终止的时间最长为 millis 毫秒。

void join(long millis, int nanos)  等待该线程终止的时间最长为 millis 毫秒 + nanos 纳秒。

# 线程的调度——守护线程thread.setDaemon(true)

Daemon Thread守护线程与User Thread(用户线程)普通线程写法上基本么啥区别，用个比较通俗的比如，任何一个守护线程都是整个JVM中所有非守护线程的保姆。只要当前JVM实例中尚存在任何一个非守护线程没有结束，守护线程就全部工作；只有当最后一个非守护线程结束时，守护线程随着JVM一同结束工作。因为没有了被守护者，Daemon也就没有工作可做了，也就没有继续运行程序的必要了。

Daemon的作用是为其他线程的运行提供便利服务，守护线程最典型的应用就是，JVM的GC (垃圾回收器)、内存管理等线程都是守护线程。还有就是在做数据库应用时候，使用的数据库连接池，连接池本身也包含着很多后台线程，监控连接个数、超时时间、状态等等。补充说明：

定义：守护线程--也称“服务线程”，在没有用户线程可服务时会自动离开。

优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。

在start()方法被调用之前调用线程对象的方法setDaemon(true)，则可以将其设置为守护线程。setDaemon方法的详细说明：

public final void setDaemon(boolean on) // 将该线程标记为守护线程或用户线程。

这里有几点需要注意： 

(1) thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。

(2) 在Daemon线程中产生的新线程也是Daemon的。 

(3) 不要认为所有的应用都可以分配给Daemon来进行服务，比如读写操作或者计算逻辑。 

因为你不可能知道在所有的User完成之前，Daemon是否已经完成了预期的服务任务。一旦User退出了，可能大量数据还没有来得及读入或写出，计算任务也可能多次运行结果不一样。这对程序是毁灭性的。造成这个结果理由已经说过了：一旦所有User Thread离开了，虚拟机也就退出运行了。

# 核心线程是线程初始化就会创建出来？

Java使用Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。Java可以用四种方式来创建线程，如下所示：

1）继承Thread类创建线程

2）实现Runnable接口创建线程

3）使用Callable和Future创建线程

4）使用线程池例如用Executor框架

# 控制线程顺序执行的方法有哪些？

例如：现有A、B、C、D、E五个线程，现在需要E线程在ABCD四个线程结束之后再执行：

\1. join 让主线程等待子线程运行结束后再继续运行

\2. 利用并发包里的Excutors的newSingleThreadExecutor产生一个单线程的线程池，而这个线程池的底层原理就是一个先进先出（FIFO）的 队列。代码中executor.submit依次添加了123线程，按照FIFO的特性，执行顺序也就是123的执行结果，从而保证了执行顺序。

\3. 使用 CountDownLatch 控制多个线程执行顺序 cutDown()方法和await()方法

# java多线程的异步调用，比如a方法调动b方法的异步返回结果怎么获取的？

#### Future、FutureTask介绍

Future是一个接口，该接口用来返回异步的结果。是一个抽象的概念，它表示一个值，该值可能在某一点变得可用。一个Future要么获得 计算完的结果，要么获得计算失败后的异常。在java.util.concurrent包中，Future接口是Java线程Future模式的实现，可以来进行异步计算。有了Future就可以进行三段式的编程了，1.启动多线程任务2.处理其他事3.收集多线程任务结果。从而实现了非阻塞的任务调用。在途中遇到一个问题，那就是虽然能异步获取结果，但是Future的结果需要通过isDone()来判断是否有结果，或者使用get()函数来阻塞式获取执行结果。这样就不能实时跟踪其他线程的结果状态了，所以直接使用get还是要慎用，最好配合isdone来使用。

FutureTask是一个类，是Future 的一个实现。

# 线程池的工作机制,Java通过Executors工具类创建出来的线程池有什么区别，为什么这样定义？

```
Executors.newCachedThreadPool();     // 创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE
Executors.newSingleThreadExecutor();  // 创建容量为1的缓冲池，可以按提交顺序依次执行
Executors.newFixedThreadPool(int);    // 创建固定容量大小的缓冲池
```

# 线程池有哪些参数，具体含义是什么? 共7个参数

# 创建线程池有哪几个核心参数？ 如何合理配置线程池的大小？

corePoolSize 核心池的线程数，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；

maximumPoolSize线程池最大线程数，它表示在线程池中最多能创建多少个线程；

RejectedExecutionHandler饱和策略：DiscardPolicy，DiscardOldPolicy，CallerRunPolicy，AbortPolicy

keepAliveTime存活时间，表示线程没有任务执行时最多保持多久时间会终止；

TimeUnit 线程活动保持时间keepAliveTime的单位，有7种取值，在TimeUnit类中有7种静态属性；

workQueue阻塞队列 ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous

threadFactory线程工厂，用来创建线程

# 线程池的原理，为什么要创建线程池？创建线程池的方式；

## 线程池原理 

提交一个任务到线程池中，线程池的处理流程如下： 

1、判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。 

2、线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。 

3、判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。

![img](file:////Users/gongdaoshun/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image026.png)

## 为什么要使用线程池

\1.  减少资源消耗,通过重复的使用已创建好的线程，避免了线程的频繁创建和销毁所造成的**消耗**

\2.  提高响应速度,当任务到达时，不需要再去创建，可以直接使用已经创建好的线程就能立即执行任务

\3.  提高线程的管理性,线程池可以统一管理线程的创建，销毁，分配，调优监控

解决的问题：通过固定的几个线程为大量的操作服务,降低线程的频繁创建,销毁线程所需要消耗的时间，从而提高效应效率。

在面向对象编程中，对象创建和销毁是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是对一些很耗资源的对象创建和销毁。如何利用已有对象来服务就是一个需要解决的关键问题，其实这就是一些"池化资源"技术产生的原因。比如大家所熟悉的数据库连接池就是遵循这一思想而产生的，下面将介绍的线程池技术同样符合这一思想。

多线程技术主要解决处理器单元内多个线程执行的问题，它可以显著减少处理器单元的闲置时间，增加处理器单元的吞吐能力。但如果对多线程应用不当，会增加对单个任务的处理时间。可以举一个简单的例子：

假设一台服务器完成一项任务的时间为T

```
 1. T1 创建线程的时间
 2. T2 在线程中执行任务的时间，包括线程间同步所需时间> 
 3. T3 线程销毁的时间
```

显然T ＝ T1＋T2＋T3。注意这是一个极度简化的假设。

可以看出T1，T3是多线程本身附加的开销，用户希望减少T1，T3所用的时间，从而减少T的时间。但一些线程的使用者并没有注意到这一点，所以在应用程序中频繁的创建或销毁线程，这导致T1和T3在T中占有非常大的比例。

线程池技术正是关注如何缩短或调整T1，T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了，线程池不仅调整T1，T3产生的时间，而且它还显著减少了创建线程的数目。

## 创建线程&线程池

java创建线程的三种方式：

```
1. 继承Thread类创建线程类
2. 实现Runnable接口
3. 通过Callable和Future创建线程
```

java创建线程池的四种方式：

```
1. newCachedThreadPool 创建一个可缓存的线程池，如果线程池长度超过处理需求，可灵活回收空闲线程，若无可回收，则新建线程。
2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会唯一的工作线程来执行任务，保证所有任务按照指定顺序（FIFO，LIFO，优先级）执行。
```

## 线程池的好处

通过重复利用已创建的线程，减少在创建和销毁线程上所花的时间以及系统资源的开销。

提高响应速度，当任务到达时，任务可以不需要等到线程创建就可以立即执行。 提高线程的可管理性，使用线程池可以对线程进行统一的分配和监控。

如果不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存。

## 线程池的注意事项：

线程池的大小：多线程应用并非线程越多越好。需要根据系统运行的硬件环境以及应用本身的特点决定线程池的大小。一般来说，如果代码结构合理，线程数与cpu数量相适合即可。如果线程运行时可能出现阻塞现象，可相应增加池的大小、如果有必要可采用自适应算法来动态调整线程池的大小。以提高cpu的有效利用率和系统的整体性能。

并发错误：多线程应用要特别注意并发错误，要从逻辑上保证程序的正确性，注意避免死锁现象的发生。
 线程泄露：这是线程池应用中的一个严重的问题、当任务执行完毕而线程没能返回池中就会发生线程泄露现象。

# 线程的生命周期，什么时候会出现僵死进程；

![img](http://image.itstabber.com/2020-09-09/clip_image027.png)

![img](http://image.itstabber.com/2020-09-09/clip_image028.png)

上图中基本上囊括了Java中多线程各重要知识点。掌握了上图中的各知识点，Java中的多线程也就基本上掌握了。主要包括：

**Java****线程具有七种基本状态**

**新建状态（New）：至今尚未启动的线程的状态。线程刚被创建，但尚未启动****。**如：Thread t = new MyThread();

**就绪状态（Runnable）：**当调用线程对象的start()方法（t.start();），线程即进入就绪状态。正在等待被分配给CPU时间片，也就是说此时线程正在就绪队列中排队等候得到CPU资源。并不是说执行了t.start()此线程立即就会执行；

**运行状态（Running）****：**线程获得CPU资源正在执行任务（执行run()方法），此时除非此线程自动放弃CPU资源或者有优先级更高的线程进入,线程将一直运行到结束或者时间片结束。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；

无限期等待（Waiting）：位于对象等待池中的阻塞状态（Blocked in object’s wait pool）：当线程处于运行状态时，如果执行了某个对象的wait()方法，Java虚拟机就会把线程放到这个对象的等待池中，这涉及到“线程通信”的内容。处于这种状态的线程不会被分配处理器执行时间，它们要等待被其他线程显示唤醒。以下方法会让线程陷入无限期的等待状态：

·    没有设置timeout参数的Object::wait()方法

·    没有设置timeout参数的Thread::join()方法

·    LockSupport::park()方法

**限期等待（Timed Waiting）****：**处于这种状态的线程也不会被分配处理器执行时间，不过无须等待其他线程显示唤醒，在一定时间后它们由系统自动唤醒。以下方法会让线程进入期限等待状态：

·    Thread::sleep()方法

·    设置了timeout参数的Object::wait()方法

·    设置了timeout参数的Thread::join()方法

·    LockSupport::parkNanos()方法

·    LockSupport::parkUntil()方法

**阻塞状态（Blocked）：**处于运行状态中的线程由于某种（当线程处于运行状态时，试图获得某个对象的同步锁时，如果该对象的同步锁已经被其他线程占用，Java虚拟机就会把这个线程放到这个对象的锁池中。这涉及到“线程同步”的内容，【线程在获取synchronized同步锁失败(因为锁被其它线程所占用)】）原因，暂时放弃对CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才有机会再次被CPU调用以进入到运行状态。由于某种原因导致正在运行的线程让出CPU并暂停自己的执行，即进入堵塞状态。阻塞结束后线程进入就绪状态。堵塞的情况分三种：

(一)等待堵塞：执行的线程执行wait()方法，JVM会把该线程放入等待池中。

(二)同步堵塞：执行的线程在获取对象的同步锁时，若该同步锁被别的线程占用。则JVM会把该线程放入锁池中。

(三)其它堵塞：执行的线程执行sleep()或join()方法，或者发出了I/O请求时。JVM会把该线程置为堵塞状态。

当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完成时。线程又一次转入就绪状态。

 “阻塞状态”与“等待状态”的区别：“阻塞状态”在等待着获取一个排它锁，这个事件将在另一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作发生。在程序进入同步区域的时候，线程就会进入阻塞状态。

**死亡状态（Dead）：**线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

# 线程池队列如何设置多长

**1. ThreadPoolExecutor****的重要参数**

·    corePoolSize：核心线程数

o  核心线程会一直存活，及时没有任务需要执行

o  当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理

o  设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭

·    queueCapacity：任务队列容量（阻塞队列）

o  当核心线程数达到最大时，新任务会放在队列中排队等待执行

·    maxPoolSize：最大线程数

o  当线程数>=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务

o  当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常

·    keepAliveTime：线程空闲时间

o  当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize

o  如果allowCoreThreadTimeout=true，则会直到线程数量=0

·    allowCoreThreadTimeout：允许核心线程超时

·    rejectedExecutionHandler：任务拒绝处理器

o  两种情况会拒绝处理任务：

o  当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务

o  当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务

o  线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常

o  ThreadPoolExecutor类有几个内部实现类来处理这类情况：

o  AbortPolicy 丢弃任务，抛运行时异常

o  CallerRunsPolicy 执行任务

o  DiscardPolicy 忽视，什么都不会发生

o  DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务

o  实现RejectedExecutionHandler接口，可自定义处理器

**2. ThreadPoolExecutor****执行顺序：**线程池按以下行为执行任务

\1.   当线程数小于核心线程数时，创建线程。

\2.   当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。

\3.   当线程数大于等于核心线程数，且任务队列已满

1)   若线程数小于最大线程数，创建线程

2)   若线程数等于最大线程数，抛出异常，拒绝任务

**3.** **如何设置参数**

·    默认值

o  corePoolSize=1

o  queueCapacity=Integer.MAX_VALUE

o  maxPoolSize=Integer.MAX_VALUE

o  keepAliveTime=60s

o  allowCoreThreadTimeout=false

o  rejectedExecutionHandler=AbortPolicy()

·    如何来设置

o  需要根据几个值来决定

o  tasks ：每秒的任务数，假设为500~1000

o  taskcost：每个任务花费时间，假设为0.1s

o  responsetime：系统允许容忍的最大响应时间，假设为1s

o  做几个计算

o  corePoolSize = 每秒需要多少个线程处理？ 

o  threadcount = tasks/(1/taskcost) =tasks*taskcout =  (500~1000)*0.1 = 50~100 个线程。corePoolSize设置应该大于50

o  根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可

o  queueCapacity = (coreSizePool/taskcost)*responsetime

o  计算可得 queueCapacity = 80/0.1*1 = 80。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行

o  切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。

o  maxPoolSize = (max(tasks)- queueCapacity)/(1/taskcost)

o  计算可得 maxPoolSize = (1000-80)/10 = 92

o  （最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数

o  rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理

o  keepAliveTime和allowCoreThreadTimeout采用默认通常能满足

·    以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件（呵呵）和优化代码，降低taskcost来处理。

# 类加载过程和双亲委派模型

![img](http://image.itstabber.com/2020-09-09/clip_image029.png)

上图中的加载，验证，准备，初始化，卸载这5个步骤的顺序是固定的，类的加载器也必须按这个顺序开始，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定l在加载阶段，虚拟机需要完成以下三件事情：

·    通过一个类的全限定名来获取定义此类的二进制字节流

·    将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构

·    在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类各种数据的访问入口

但虚拟机规范中并未指明二进制字节流要从哪里获取，应该怎样获取，因此加载阶段是非常灵活的。例如：

·    我们可以从jar，war等格式的文件中获取

·    也可以在运行的时候通过计算生成，最典型的就是动态代理技术

### 加载阶段（Loading）

它是Java将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构（Class对象），这里的数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等；如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。加载阶段是用户参与的阶段，可以自定义类加载器，去实现自己的类加载过程。

### 链接（Linking）

这是核心的步骤，简单说是把原始的类定义信息平滑地转化入JVM运行的过程中。这里可进一步细分为三个步骤：

l  验证(Verification)，是虚拟机安全的重要保障，JVM需要核验字节信息是符合Java虚拟机规范的，否则就被认为是VerifyError，这样就防止了恶意信息或者不合规的信息危害JVM的运行，验证阶段有可能触发更多class的加载。

l  准备（Preparation），创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。

l  解析（Resolution），在这一步会将常量池中的符号引用（symbolic reference）替换为直接引用。在Java虚拟机规范中，详细介绍了类、接口、方法和字段等各个方面的解析。

### 初始化阶段（initialization）

这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。

 

### 系统有哪些类加载器？

![img](http://image.itstabber.com/2020-09-09/clip_image030.png)

如上图所示：

·    Bootstrap ClassLoader：这个类由C/C++实现的是虚拟机的自身的一部分

·    Extension ClassLoader：扩展类加载器，它默认加载<JAVA_HOME>\lib\ext目录下的，也可以加载由java.ext.dirs指定的路径中的所有类库

·    Application ClassLoader：应用程序类加载器，它主要负责加载用户类路径上所指定的类库，这个也是默认的程序中的类加载器。

### 双亲委派模型

简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载Java类型。

  protected Class<?> loadClass(String name,  boolean resolve) throws  ClassNotFoundException {      // 加锁机制      synchronized (getClassLoadingLock(name))  {        // 检查这个类是否被加载过        Class<?>  c = findLoadedClass(name);        if (c  == null) {            long t0 = System.nanoTime();          try {              if (parent != null) {                // 调用父类的ClassLoader来加载                c = parent.loadClass(name, false);              } else {                // 查找最顶层的BootstrapClassLoader                c = findBootstrapClassOrNull(name);              }            } catch (ClassNotFoundException e) {              .....            }             if (c  == null) {              // 如果父类加载器都没找到,就直接调用查找类的方法去查找              long t1 = System.nanoTime();              c = findClass(name);              ......            }        }        if (resolve) {            resolveClass(c);        }        return c;      }    }  

上面的代码很清楚，我们每个`ClassLoader`都会持有一个父类的ClassLoader对象，当调用当前的加载类的方法时候，其实内部会调用`父类的``ClassLoader`来完成加载，如果最顶层的`父类加载器抛出异常`，说明父类无法完成加载请求，此时就由子类来完成，`查找类`，`加载类`的过程了。

# Class文件结构是如何解析的

![img](http://image.itstabber.com/2020-09-09/clip_image031.png)

 

![](http://image.itstabber.com/2020-09-09/clip_image032.png)

   Class文件是一组以**8****位字节**为基础单位的二进制流，各个数据项目严格按照顺序准确地排列在Class文件中，中间没有任何分隔符。当遇到8位字节以上的数据时，就按照高位在前的方式（最高位字节在地址最低位、最低位字节在地址最高位的顺序储存）分割成多个8位字节储存。

   Class文件格式采用一种类似于C语言结构体的伪结构来储存数据的，这种伪结构有两种数据类型：**无符号数**和**表**。

   **无符号数**是基本数据类型，以u1、u2、u4、u8分别代表1个字节、2个字节、4个字节和8个字节的无符号数，可以用来描述数字、索引引用、数量值或者UTF-8编码构成的字符串值。

   **表**是由多个无符号数或其他表作为数据项构成的复合数据类型，所有的表都习惯地以“_info”结尾。**表**的数据结构和树很类似，**无符号数**相当于它的叶子节点，其他的表相当于它的子节点。整个Class文件就本质上也是一个表，具体结构如下：

| **类型**       | **名称**            | **数量**                | **描述**           |
| -------------- | ------------------- | ----------------------- | ------------------ |
| u4             | magic               | 1                       | 魔数(Magic Number) |
| u2             | minor_version       | 1                       | 次版本号           |
| u2             | major_version       | 1                       | 主版本号           |
| u2             | constant_pool_count | 1                       | 常量池容量计数值   |
| cp_info        | constant_pool       | constant_pool_count - 1 | 常量池             |
| u2             | access_flags        | 1                       | 访问标志           |
| u2             | this_class          | 1                       | 类索引             |
| u2             | super_class         | 1                       | 父类索引           |
| u2             | interfaces_count    | 1                       | 接口索引计数值     |
| u2             | interfaces          | interface_count         | 接口索引           |
| u2             | fields_count        | 1                       | 字段计数值         |
| field_info     | fields              | fields_count            | 字段表             |
| u2             | methods_count       | 1                       | 方法计数值         |
| method_info    | fields              | methods_count           | 方法表             |
| u2             | attributes_count    | 1                       | 属性计数值         |
| attribute_info | attributes          | attributes_count        | 属性表             |

   可以发现，无论是**无符号数**还是**表**，当需要描述同一种类型又数量不定的多条数据时，就会用一个前置的计数器加几个连续的数据项的方式，这个时候我们就把这种一系列连续的某种类型的数据叫做这个类型的**集合**。在Class文件中，无论是顺序还是数量，甚至是数据存储的字节序，都必须严格按照上面表格进行设定，哪个字节代表什么含义，长度是多少，先后顺序怎么样，都不允许改变。有个一个专门分析Class文件字节码的工具javap: E:\>javap -verbose YourTest E:\>javap -v YourTest

## 如何解析

​    组成Class文件的各个数据项中，例如魔数、Class文件的版本、访问标志、类索引和父类索引等数据项，它们在每个Class文件中都占用固定数量的字节，在解析时只需要读取相应数量的字节。除此之外，需要**灵活处理**的主要包括4部分：**常量池**、**字段表集合**、**方法表集合和属性表集合**。字段和方法都可以具备自己的属性，Class本身也有相应的属性，因此，在解析字段表集合和方法表集合的同时也包含了属性表集合的解析。

​    **常量池**占据了Class文件很大一部分的数据，用于存储所有的常量信息。其中主要存放两大类常量：**字面量**(Literal)和**符号引用**(Symbolic References)。字面量如文本字符串、声明为final的常量值等。符号引用包括三类常量：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。

   **字段表**(field_info)是用来描述接口或类中声明的变量。包括类级变量（静态变量）和实例级变量（成员变量），但是不包括在方法内部声明的局部变量。

   **方法表**的结构和字段表的是一样的，也是依次包括了访问标志(access_flags)、名称索引(name_index)、描述符索引(descriptor_index)和属性表集合(attributes)。

   **属性表**(attribute_info)在前面的分享中出现了几次，在Class文件、字段表、方法表都可以有自己的属性表集合，用来描述某些场景下特有的信息。属性表不在要求具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以写入自己定义的属性信息，Java虚拟机在运行时会忽略掉它不认识的属性。

# 类加载器的组织结构

类加载器 ClassLoader是具有层次结构的，也就是父子关系。其中，Bootstrap是所有类加载器的父亲。

（1）Bootstrapclass loader： 启动类加载器

当运行Java虚拟机时，这个类加载器被创建，它负责加载虚拟机的核心类库，如java.lang.*等。

（2）Extensionclass loader：标准扩展类加载器

用于加载除了基本 API之外的一些拓展类。

（3）AppClassLoader：加载应用程序和程序员自定义的类。

# 类的加载机制：加载（内存中生成class对象）， 链接（验证 准备 解析）， 初始化

类被加载到虚拟机内存包括加载、链接、初始化几个阶段。其中链接又细化分为验证、准备、解析。

这里需要注意的是，解析阶段在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的运行时绑定。

各个阶段的作用整理如下：

# 加载阶段

加载阶段可以使用系统提供的类加载器(ClassLoader)来完成，也可以由用户自定义的类加载器完成，开发人员可以通过定义类加载器去控制字节流的获取方式。

ps：可以自定义类加载器，从加密和安全两个角度出发来加载特殊的类。具体参考[自定义类加载器](http://www.cnblogs.com/lixuwu/p/8492322.html) 

（1）通过类的全名产生对应类的二进制数据流。

（2）将这些二进制数据流转换为方法区的运行时数据结构。

（3）创建代表这个类的java.lang.Class对象。作为方法区这些数据的访问入口。

# 链接阶段（实现 Java 的动态性的重要一步）

（1）验证：验证阶段的主要目的是确保class文件字节流的正确性，要验证比如class文件格式规范、这个类是否继承了final类、不能把一个父类对象赋值给子类数据类型等等。

（2）准备：准备阶段为方法区中的静态变量分配内存空间。并将其赋值为初始值，所有原始类型的值都为0。如float为0f、 int为0、boolean为0、引用类型为null。

（3）解析：解析阶段把符号引用解析为直接引用。

符号引用是一个字符串，它唯一标识一个类、一个字段、一个方法等目标。

而直接引用对于类变量、类方法指的是指向方法区的指针，然后对于实例方法、实例对象来说就是偏移量，比如一个实例方法，子类中方法表中的偏移量和父类是一致的，这个偏移量可以确定某个方法的位置。

# 初始化

到了初始化阶段，才是真正执行用户定义的程序代码。在初始化阶段就是执行类构造器方法的过程，工作包括赋值类变量、静态语句块的合并。

//定义在静态语句块之后的变量可以赋值，但不能访问

public class Test{

  static{ 

​    i=0;//給变量赋值，可以通过编译

​    System.out.print(i);//这句编译器会提示非法向前引用

  }

  static int i=1;

}

初始化过程会被触发的条件汇总：

（1）使用new关键字实例化对象、访问一个类的静态字段、静态方法的时候。

（2）对类进行反射调用的时候。

（3）当初始化子类时，如果发现其父类还没有进行过初始化，则进行父类的初始化。

 

【关于构造器方法拓展知识】（可以不看）

（1）类构造器<clinit>()方法与类的构造函数不同，它不需要显式调用父类构造，虚拟机会保证在子类<clinit>()方法执行之前，父类的<clinit>()方法已经执行完毕。因此在虚拟机中的第一个执行的<clinit>()方法的类肯定是java.lang.Object。

（2）由于父类的<clinit>()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。

（3）<clinit>()方法不是必须的，如果一个类中没有静态语句，那么编译器可以不为这个类生成<clinit>()方法。

（4）接口中不能使用静态语句块，和类不同的是，执行接口的<clinit>()方法不需要先执行父接口的<clinit>()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的<clinit>()方法。

（5）虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确加锁和同步，可能会导致阻塞。

 

# 类加载的三种方式

（1）由 new 关键字创建一个类的实例。

（2）调用 Class.forName() 方法，通过反射加载类。

（3）调用某个ClassLoader实例的loadClass()方法。

三者的区别汇总如下：

（1）方法1和2都是使用的当前类加载器。方法3是由用户指定的类加载器加载。

（2）方法1是静态加载，2、3是动态加载。

（3）对于两种动态加载，如果程序需要类被初始化，就必须使用Class.forName(name)的方式。

```
Class.forName(className);
//实际上是调用的是：
Class.forName(className, true, this.getClass().getClassLoader());//第二个参为true即默认类需要初始化，初始化会触发目标对象静态块的执行和静态变量的初始化
```

 ClassLoader.loadClass(className);

```
//实际上调用的是:
ClassLoader.loadClass(name, false);//第二个参数即默认得到的class还没有进行链接，意味着不进行初始化等系列操作，即静态代码块不会执行
```

# JVM里的有几种ClassLoader，为什么会有多种？

​    类加载器作用是通过类名来获取二进制字节流。主要分为四种加载器，启动类->扩展类->应用类->自定义类。BootStrap ClassLoader，负责加载<JAVA_HOME>/lib或被-Xbootclasspath指定路径下的类库，开发者不可以直接使用。Extension ClassLoader,负责加载<JAVA_HOME>/lib/ext或被java.ext.dirs系统变量指定的路径中的所有类库，开发者可以直接使用。App ClassLoader，这个类加载器是ClassLoader.getSystemClassLoader()的返回值，负责加载用户类路径上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序没有自定义类加载器，那么系统默认使用这个类加载器。因为他们代表几种不同的信任级别：最可信的级别是java核心API类。然后是安装的拓展类，最后才是在类路径中的类。

\* 多种类加载器待办可以同时加载多个应用程序（一个加载服务，另外的加载器用来服务器内部的部署）。

\* 每种加载器都有对应的层级来加载某些特定（同名）的类，来保证他们之间的安全性。

举例：同一个Tomcat部署多个项目应用，可能使用相同的库，但是不同版本，如果用同一个类加载器去加载，就会造成两个应用类的覆盖。

# 什么是双亲委派机制？介绍一些运作过程，双亲委派模型的好处；

​    双新委派机制：先在启动类加载器找，找不到再到扩展类加载器找，找不到再到应用程序类加载器找，找不到就从自己定义的类；由下到上加载，顶层加载不了再交给下层加载，如果回到底层位置加载 还加载不到，那就会报ClassNotFound错误了。“委托机制” 是指先从父类开始找：这是从安全角度出发，因为怕有人恶意编写类（例如java.lang.String）并且装载到JVM中，那会有多么可怕的后果，但是有了“全盘负责委托机制”，java.lang.String永远是由跟装载器来加载，这就避免了上述事件的发生。双亲委派机制的好处，就是保证类加载的优先级层次顺序，防止核心API库被随意篡改，越基础的类交给越高级的加载器加载。

# 双亲委派模型的工作过程如下：

(1）当前类加载器从自己已经加载的类中查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。

（2）如果没有找到，就去委托父类加载器去加载（如代码c = parent.loadClass(name, false)所示）。父类加载器也会采用同样的策略，查看自己已经加载过的类中是否包含这个类，有就返回，没有就委托父类的父类去加载，一直到启动类加载器。因为如果父加载器为空了，就代表使用启动类加载器作为父加载器去加载。

（3）如果启动类加载器加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用拓展类加载器来尝试加载，继续失败则会使用AppClassLoader来加载，继续失败则会抛出一个异常ClassNotFoundException，然后再调用当前加载器的findClass()方法进行加载。

双亲委派模型的好处：

（1）主要是为了安全性，避免用户自己编写的类动态替换 Java的一些核心类，比如 String。

（2）同时也避免了类的重复加载，因为 JVM中区分不同类，不仅仅是根据类名，相同的 class文件被不同的 ClassLoader加载就是不同的两个类。

# 双亲委派模型，动态代理原理

**(1)****什么是代理？**

代理这种设计模式是通过不直接访问被代理对象的方式，而访问被代理对象的方法。这个就好比 商户---->明星经纪人(代理)---->明星这种模式。我们可以不通过直接与明星对话的情况下，而通过明星经纪人(代理)与其产生间接对话。

**(2)****什么情况下使用代理？**

​      设计模式中有一个设计原则是开闭原则，是说对修改关闭对扩展开放，我们在工作中有时会接手很多前人的代码，里面代码逻辑让人摸不着头脑，这时就很难去下手修改代码，那么这时我们就可以通过代理对类进行增强。Spring的AOP机制就是采用动态代理的机制来实现切面编程。

**(3)****静态代理和动态代理**

​      我们根据加载被代理类的时机不同，将代理分为静态代理和动态代理。如果我们在代码编译时就确定了被代理的类是哪一个，那么就可以直接使用静态代理；如果不能确定，那么可以使用类的动态加载机制，在代码运行期间加载被代理的类这就是动态代理，比如RPC框架和Spring AOP机制。

​      静态代理是实现被代理的接口类，并在代理类中引入了被代理类的对象，在重写接口的方法上进行增强。

​      动态代理的实现代码，涉及到java反射包下的InvocationHandler接口和Proxy类。InvocationHandler这个方法委托接口类只有一个invoke方法，我们在通过代理类调用被代理类的方法时，最终都会委托给这个invoke方法执行，所以我们就可以在这个invoke方法中对被代理类进行增强或做一些其他操作。而Proxy类的public static Object newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h)方法内部通过拼接字节码的方式来创建代理类。

# 什么情况下我们需要破坏双亲委派模型；

### 情况一：JDBC为什么要破坏双亲委派模型

​      因为类加载器受到加载范围的限制，在某些情况下父类加载器无法加载到需要的文件，这时候就需要委托子类加载器去加载class文件。

​      JDBC的Driver接口定义在JDK中，其实现由各个数据库的服务商来提供，比如MySQL驱动包。DriverManager 类中要加载各个实现了Driver接口的类，然后进行管理，但是DriverManager位于 $JAVA_HOME中jre/lib/rt.jar 包，由BootStrap类加载器加载，而其Driver接口的实现类是位于服务商提供的 Jar 包，**根据类加载机制，当被装载的类引用了另外一个类的时候，虚拟机就会使用装载第一个类的类装载器装载被引用的类。**也就是说BootStrap类加载器还要去加载jar包中的Driver接口的实现类。我们知道，BootStrap类加载器默认只负责加载 $JAVA_HOME中jre/lib/rt.jar 里所有的class，所以需要由子类加载器去加载Driver实现，这就破坏了双亲委派模型。

### 情况二：Tomcat为什么要破坏双亲委派模型

**每个****Tomcat****的****webappClassLoader****加载自己的目录下的****class****文件，不会传递给父类加载器。**

事实上，tomcat之所以造了一堆自己的classloader，大致是出于下面三类目的：

·    对于各个 `webapp`中的 `class`和 `lib`，需要相互隔离，不能出现一个应用中加载的类库会影响另一个应用的情况，而对于许多应用，需要有共享的lib以便不浪费资源。

·    与 `jvm`一样的安全性问题。使用单独的 `classloader`去装载 `tomcat`自身的类库，以免其他恶意或无意的破坏；

·    热部署。相信大家一定为 `tomcat`修改文件不用重启就自动重新装载类库而惊叹吧。

# 为什么需要自定义类加载器（自定义类的应用场景）

（1）加密：Java代码可以轻易的被[反编译](https://www.baidu.com/s?wd=反编译&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHcvrjTdrH00T1d9rj6Yuhn3n1b3uWwBn1wb0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EP1R1rjD3njnzPWc1n1RdPW6Y)，如果你需要把自己的代码进行加密以防止反编译，可以先将编译后的代码用某种加密算法加密，类加密后就不能再用Java的ClassLoader去加载类了，这时就需要自定义ClassLoader在加载类的时候先解密类，然后再加载。

（2）从非标准的来源加载代码：如果你的字节码是放在数据库、甚至是在云端，就可以自定义类加载器，从指定的来源加载类。

（3）以上两种情况在实际中的综合运用：比如你的应用需要通过网络来传输 Java 类的字节码，为了安全性，这些字节码经过了加密处理。这个时候你就需要自定义类加载器来从某个网络地址上读取加密后的字节代码，接着进行解密和验证，最后定义出在Java虚拟机中运行的类。

# 自定义类加载器

（1）从上面源码看出，调用loadClass时会先根据委派模型在父加载器中加载，如果加载失败，则会调用当前加载器的findClass来完成加载。（ps：在所有加载器找不到的情况下，就会调用用户自定义的类加载器来加载）

（2）因此我们自定义的类加载器只需要继承ClassLoader，并覆盖findClass方法，下面是一个实际例子，在该例中我们用自定义的类加载器去加载我们事先准备好的class文件。

自定义一个类加载器，需要继承ClassLoader类，并实现findClass方法。其中defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class（只要二进制字节流的内容符合Class文件规范）。

# 集合框架常见的有哪些

**Collection**(单列集合)

   -- List 1. 有序(存取有序) 2. 有索引  3. 可重复

​       \- ArrayList  数组

​       \- LinkedList 链表

​       \- Vector    数组 JDK1.0产物 已经被ArrayList取代，线程安全，效率低下

   -- Set 1. 无序(存取无序) 2. 无索引  3. 不可重复

​      \- HashSet  哈希算法(去重)

​      \- TreeSet   红黑树(去重并排序)

​     \- LinkedHashSet （去重，但是怎么存，就怎么取 ,有以一批量的数据，有重复元素，又不想打乱现有的顺序 ) 

​         

 **Map**(双列集合)

​     \- HashMap  哈希算法(去重)

​     \- TreeMap  红黑树(去重并排序)

​     \- Hashtable Hashtable的命运和Vector雷同！他们都是线程安全的，jdk1.0的产物

​             Hashtable不能存储null键null值；线程安全

​             HashMap可以存储null键null值；线程不安全，HashMap已经全面的取代了Hashtable;

​    \- Properties  可以与IO流技术结合使用

  1.TreeSet如何去重并排序？
   2.HashMap的底层去重和存储原理？
   3.Collections工具类的简单运用？
   4.HashMap与Hashtable的区别？
   5.数组，链表操作元素的原理？
   6.浅谈hash底层算法？
   7.二叉树的原理？

# List 和 Map 区别

List特点：元素有放bai入du顺序，元素可重复zhi

Map特点：元素按键值对存储，无放入顺序

Set特点：元素无放入顺序，元素不可重复（注意：元素虽然无放入顺序，但是元素在set中的位置是有该元素的HashCode决定的，其位置其实是固定的）

# ArrayList 与 Vector 区别；

一. 同步性: Vector是线程安全的，也就是说是同步的，而ArrayList是线程序不安全的，不是同步的 

二. 数据增长: 当需要增长时，Vector默认增长为原来一倍，而ArrayList却是原来的一半

# ArrayList和LinkedList的内部实现

ArrayList是实现了基于动态数组结构，实现了RandomAccess接口，因此对元素的随机访问速度非常快，因为是数组，所以ArrayList在初始化的时候，有初始大小10，插入新元素的时候会判断是否需要扩容，扩容的步长是0.5倍原容量，扩容方式是利用数组的复制，因此有一定的开销，另外，ArrayList在进行元素插入的时候，需要移动插入位置之后的所有元素，位置越靠前，需要位移的元素越多，开销越大，相反，插入位置越靠后的话，开销就越小了，如果在最后面进行插入，那就不需要进行位移。

LinkedList 底层的数据结构是基于双向循环链表，LinkedList有一个内部类作为存放元素的单元（节点），里面有三个属性，中间用来存放元素本身的业务数据以及前后2个单元的引用(位置信息)。另外LinkedList内部还有一个header属性（头节点中不存放数据）用来标识起始位置，LinkedList的第一个单元和最后一个单元都会指向header，因此形成了一个双向的链表结构LinkedList的元素并不需要连续存放，但是每个存放元素的单元比元素本身需要更大的空间，LinkedList对空间的要求比较大，但是扩容的时候不需要进行数组复制，因此没有这一环节的开销但是，LinkedList的随机访问速度惨不忍睹，因为无论你要访问哪一个元素，都需要从header起步正向或反向的进行元素遍历。

​    由此可见，ArrayList适合需要大量进行随机访问或者对靠近集合中尾部的元素进行增删的场景；而LinkedList则适合对靠近集合首部的元素进行增删的场景。

# ArrayList扩容过程，与LinkedList区别

ArrayList 底层会新生成一个数组，在JDK1.7中扩容规则长度为原数组的 1.5 倍（扩容后的大小= 原始大小+原始大小/2），然后将原数组的内容复制到新数组当中，并且后续增加的内容都会放到新数组当中。当新数组无法容纳增加的元素时，重复该过程。扩容数组调用的方法Arrays.copyOf(objArr, objArr.length + 1);

LinkedList的扩容机制：由于它的底层是用双向链表实现的，没有初始化大小，也没有扩容的机制。

# 哈希表（散列表）

​    在讨论哈希表之前，我们先大概了解下其他数据结构在新增，查找等基础操作执行性能：

​    **数组**：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)

　　**线性链表**：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)

　　**二叉树**：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。

　　**哈希表**：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。

　　我们知道，数据结构的物理存储结构只有两种：**顺序****存储结构**和**链式****存储结构**（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中还是这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，**哈希表的主干就是****数组**。

　　比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。

　　　　　　　　**存储位置** **= f(****关键字****)**

其中，这个函数f一般称为**哈希函数**，这个函数的设计好坏会直接影响到哈希表的优劣。

查找操作同理，先通过哈希函数计算出实际存储地址，然后从数组中对应地址取出即可。

​    **哈希冲突**

　　如果两个不同的元素，通过哈希函数得出的实际存储地址相同，即当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的**哈希冲突**，也叫哈希碰撞。哈希函数的设计至关重要，好的哈希函数会尽可能地保证 **计算简单**和**散列地址分布均匀。**但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是**数组****+****链表**的方式。

# HashTable HashMap ConcurrentHashMap的区别、数据结构、线程安全

一. 历史原因:Hashtable是基于陈旧的Dictionary类的，HashMap是Java 1.2引进的Map接口的实现 

二. 同步性:Hashtable是线程安全的，也就是说是同步的（简单粗暴，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把**大锁**，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作**串行化**，在竞争激烈的并发场景中性能就会非常差）；而HashMap是线程序不安全的，不是同步的 

三. 值：只有HashMap可以让你将空值作为一个表的条目的key或value

四. 而JDK1.7的ConcurrentHashMap的主干是个Segment数组，采用的"**分段锁**"思想，在容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。Segment继承了ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在ConcurrentHashMap，一个Segment就是一个子哈希表，Segment里维护了一个HashEntry数组，并发环境下，对于不同Segment的数据进行操作是不用考虑锁竞争的。（就按默认的ConcurrentLeve为16来讲，理论上就允许16个线程并发执行）所以，对于同一个Segment的操作才需考虑线程同步，不同的Segment则无需考虑。Segment类似于HashMap，一个Segment维护着一个HashEntry数组。

# HashMap内部的数据结构是什么？底层是怎么实现的？

// 还可能会延伸考察ConcurrentHashMap与HashMap、HashTable等，考察对技术细节的深入了解程度

Jdk7中hashMap采用数组+链表。Jdk8中hashMap采用数组+链表/红黑树。

​    如果多个hashCode()的值落到同一个桶内的时候，这些值是存储到一个链表中的。最坏的情况下，所有的key都映射到同一个桶中，这样hashmap就退化成了一个链表——查找时间从O(1)到O(n)。 随着HashMap的大小的增长，get()方法的开销也越来越大。由于所有的记录都在同一个桶里的超长链表内，平均查询一条记录就需要遍历一半的列表。

**JDK1.8HashMap****的红黑树是这样解决的**：

​    **如果某个桶中的记录过大的话（当前是TREEIFY_THRESHOLD =** **8****），HashMap会动态的使用一个专门的****TreeNode****实现来替换掉它。这样做的结果会更好，是****O(logn)****，而不是糟糕的****O(n)****。**

但是超过这个阈值后HashMap开始将列表升级成一个二叉树，**使用哈希值作为树的分支变量，如果两个哈希值不等，但指向同一个桶的话，较大的那个会插入到右子树里。如果哈希值相等，HashMap希望key值最好是实现了Comparable接口的，这样它可以按照顺序来进行插入**。

​    /**     * Entry for Tree bins.  Extends LinkedHashMap.Entry (which in turn     * extends Node) so can be  used as extension of either regular or     * linked node.     */    **static** **final** **class** TreeNode<K,V> **extends**  LinkedHashMap.Entry<K,V> {      TreeNode<K,V> parent; // red-black  tree links      TreeNode<K,V> left;      TreeNode<K,V> right;      TreeNode<K,V> prev;  // needed to  unlink next upon deletion      **boolean** red;    }  

# HashMap红黑树的实现原理和应用场景

Java 8之前，HashMap 底层的数据结构是数组+链表实现的， Java 8之后是数组+链表+红黑树实现的，当链表的长度超过8(树化阈值)之后，会转换成红黑树。作用：解决因哈希冲突导致的链表过长，查询效率低的问题。

# JDK1.8中对Hashmap做了哪些改动

- 默认初始化容量=0
- 引入红黑树，优化数据结构
- 将链表头插法改为尾插法，解决1.7中多线程循环链表的bug
- 优化hash算法
- resize计算索引位置的算法改进
- 先插入后扩容

# HashMap和ConcurrentHashMap的内部实现

​    Java8将HashMap原来的数组+链表的结构优化成了数组+链表+红黑树的结构，减少了hash碰撞造成的链表长度过长，时间复杂度过高的问题。Java8也改进了Concurrenthashmap在jdk1.7中是采用Segment + ReentrantLock + HashEntry的分段锁臃肿的方式，采用**transient** **volatile** Node<K,V>[] table; Synchronized + CAS + 数组 + Node链表 + 红黑树来保证并发安全进行实现保存数据，其数据结构已经接近HashMap。

l  红黑树：是一种自平衡二叉查找树，是一种数据结构，典型的用途是实现关联数组，存储有序的数据。将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。

l  红黑树的约束:

Ø  根节点是黑色的，节点可以是红色的或者黑色的。

Ø  叶子节点(特指空节点)是黑色的。

Ø  每个红色节点的子节点都是黑色的。

Ø  任何一个节点到其每一个叶子节点的所有路径上黑色节点数相同。

l  红黑树的特点: 速度特别快，趋近平衡树，查找叶子元素最少和最多次数不多于二倍。

l  红默树的时间复杂度是O(logn)以2为底的对数每次查找范围减少一半，而链表是糟糕的O(n)

![img](http://image.itstabber.com/2020-09-09/clip_image033.png)

​      JDK1.7版本的ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶HashBucket。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。每个Segment守护者一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。相比于对整个Map加锁的设计，分段锁大大的提高了高并发环境下的处理能力。但同时，由于不是对整个Map加锁，导致一些需要扫描整个Map的方法（如size(), containsValue()）需要使用特殊的实现，另外一些方法（如clear()）甚至放弃了对一致性的要求（ConcurrentHashMap是弱一致性的）。

​      \1. 在使用锁来协调多线程间并发访问的模式下，减小对锁的竞争可以有效提高并发性。有两种方式可以减小对锁的竞争：

​           减小请求同一个锁的频率

​           减少持有锁的时间

​      \2. ConcurrentHashMap 的高并发性主要来自于三个方面：

​           使用分离锁减小了请求同一个锁的频率，实现多个线程间的更深层次的共享访问。

​           用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。

​           通过对同一个Volatile变量的写/读访问，协调不同线程间读/写操作的内存可见性。

**总结**

​    其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。

​    1.数据结构：取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。

​    2.保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。

​    3.锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。

​    4.链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8(树化阈值)时，会将链表转化为红黑树进行存储。

​    5.查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。

# 为何HashMap的数组长度一定是2的次幂？

**“****取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是length是2的n次方；）。”** 并且 **采用二进制位操作&，相对于%能够提高运算效率****。**

 

// 我们的数组索引位置的计算是通过对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置：

![](http://image.itstabber.com/2020-09-09/clip_image034.png)

![img](http://image.itstabber.com/2020-09-09/clip_image035.png)

// hash()函数用了很多的异或、移位等运算，对key的hashcode进一步**按位与的散列算法**来保证最终获取存储主数组的index位置尽量分布均匀

// 以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置

​      indexFor()方法h&(length-1);保证获取的index一定在数组范围内。例如，默认容量16，length-1=15，h=18,转换成二进制计算为：

```
        1  0  0  1  0
    &   0  1  1  1  1
        0  0  0  1  0  = 2
```

最终计算出的index=2。有些版本的对于此处的计算会使用取模运算，也能保证index一定在数组范围内，不过位运算对计算机来说，性能更高一些（HashMap中有大量位运算）。

​      key.hashCode();

​      int h = rehash(key); // 元素key的hashCode进行一次再哈希

 在按位与的场景下，只要低4位相同，则总会获取相同的位置下标。rehash就是为了消除这种较高冲突的可能，根据某种算法，打乱低4位，最终得到不同的位置下标。当然，如果两个h一样，那是肯定会分配到相同的位置下标的。

   通过以上得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。

// 如果数组进行扩容，数组长度发生变化，而存储位置 index = h&(length-1),index也可能会发生变化，需要重新计算index

```
void` `resize(``int` `newCapacity){}
```

// transfer()方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中。

```
void` `transfer(Entry[] newTable, ``boolean` `rehash) {}
```

hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。

![img](http://image.itstabber.com/2020-09-09/clip_image036.png)

 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如：

![img](http://image.itstabber.com/2020-09-09/clip_image037.png)

　　我们看到，上面的&运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。

![img](http://image.itstabber.com/2020-09-09/clip_image038.png)

如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。

# Hashmap中resize()过程

JDK1.8版本中扩容相对复杂。在1.7版本中，重新根据hash计算索引位置即可；而在1.8版本中分2种情况，下边用图例来解释。

![img](http://image.itstabber.com/2020-09-09/clip_image039.png)

 

![img](http://image.itstabber.com/2020-09-09/clip_image040.png)

其余还有为什么阈值=8转红黑树，长度<=6 转链表这些问题。基本都是数据科学家根据概率做出的经验值，同时避免数据结构频繁的转换引起的性能开销。

# ConcurrentHashMap怎么做扩容rehash数据重整的

​    现由于添加新元素，进行rehash操作。相对于HashMap的resize，ConcurrentHashMap的rehash原理类似，但是Doug Lea为rehash做了一定的优化，避免让所有的节点都进行复制操作：由于扩容是基于2的幂指来操作，假设扩容前某HashEntry对应到Segment中数组的index为i，数组的容量为capacity，那么扩容后该HashEntry对应到新数组中的index只可能为i或者i+capacity，因此大多数HashEntry节点在扩容前后index可以保持不变。基于此，rehash方法中会定位第一个后续所有节点在扩容后index都保持不变的节点，然后将这个节点之前的所有节点重排即可。

# ConcurrentHashMap怎么count过程，除了最简单的加锁

```java
// 该属性保存着整个哈希表中存储的所有的结点的个数总和，有点类似于 HashMap 的 size 属性
/**

   \* Base counter value, used mainly when there is no contention,

   \* but also as a fallback during table initialization

   \* races. Updated via CAS.

   */

  **private** **transient** **volatile** **long** baseCount;

  /**

   \* Table initialization and resizing control. When negative, the

   \* table is being initialized or resized: -1 for initialization,

   \* else -(1 + the number of active resizing threads). Otherwise,

   \* when table is null, holds the initial table size to use upon

   \* creation, or 0 for default. After initialization, holds the

   \* next element count value upon which to resize the table.

   */

**private** **transient** **volatile** **int** sizeCtl;
```

  

# HashMap链表转红黑树，再回转链表的关键属性条件

```java
   /** 创建HashMap时未指定初始容量情况下的默认容量
     * The default initial capacity - MUST be a power of two.
     */
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    /** HashMap的最大容量
     * The maximum capacity, used if a higher value is implicitly specified
     * by either of the constructors with arguments.
     * MUST be a power of two <= 1<<30.
     */
    static final int MAXIMUM_CAPACITY = 1 << 30;

    /** HashMap默认的装载因子，当HashMap中元素数量超过 容量*装载因子 时，则进行resize()扩容操作
     * The load factor used when none specified in constructor.
     */
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    /** 用来确定何时解决hash冲突的，链表转为红黑树
     * The bin count threshold for using a tree rather than list for a
     * bin.  Bins are converted to trees when adding an element to a
     * bin with at least this many nodes. The value must be greater
     * than 2 and should be at least 8 to mesh with assumptions in
     * tree removal about conversion back to plain bins upon
     * shrinkage.
     */
    static final int TREEIFY_THRESHOLD = 8;

    /** 用来确定何时解决hash冲突的，红黑树转变为链表
     * The bin count threshold for untreeifying a (split) bin during a
     * resize operation. Should be less than TREEIFY_THRESHOLD, and at
     * most 6 to mesh with shrinkage detection under removal.
     */
    static final int UNTREEIFY_THRESHOLD = 6;

/** 当想要将解决hash冲突的链表转变为红黑树时，需要判断下此时数组的容量，
 *  若是由于数组容量太小（小于MIN_TREEIFY_CAPACITY）而导致hash冲突，则不进行链表转为红黑树的操作，而是利用resize()函数对HashMap扩容
     * The smallest table capacity for which bins may be treeified.
     * (Otherwise the table is resized if too many nodes in a bin.)
     * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
     * between resizing and treeification thresholds.
     */
static final int MIN_TREEIFY_CAPACITY = 64;

```



# Hashtable跟HashMap的区别

**1** **产生时间**

Hashtable是Java一开始发布时就提供的键值映射的数据结构，而HashMap产生于JDK1.2。

**2** **继承的父类不同**

HashMap和Hashtable不仅作者不同，而且连父类也是不一样的。HashMap是继承自AbstractMap类，而HashTable是继承自Dictionary类。不过它们都实现了同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口

**3** **对Null key 和Null value的支持不同**

·    Hashtable既不支持Null key也不支持Null value；

·    HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。

**4** **线程安全和效率不同**

 

**5** **遍历方式的内部实现上不同**

HashMap的Iterator迭代器是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。

**6** **初始容量大小和每次扩充容量大小的不同**

Hashtable默认初始大小为11，之后每次扩充容量变为原来的2n+1。HashMap默认初始化大小为16，之后每次扩充容量变为原来的2倍。

# HashMap的get方法的过程

// HashMap::get返回一个数据节点, 如果不存在则返回空;

1. 调用hash()方法获取到key的hash值

2. 调用getNode()方法通过key和hash获取对应的value。不存在则返回null

核心方法是getNode()方法，下面我会先分析一下getNode()方法。

   ```java
public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
}

    final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
            // 先比较hashcode，再比较equals方法
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                do {
                    // 先比较hashcode，再比较equals方法
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }

   ```

![image-20200910105807729](http://image.itstabber.com/2020-09-10/image-20200910105807729.png)

1 通过 hash & (table.length - 1)获取该key对应的数据节点的hash槽;

2 判断首节点是否为空, 为空则直接返回空;

3 再判断首节点key是否和目标值相同，相同则直接返回(首节点不用区分链表还是红黑树);

4 首节点next为空, 则直接返回空;

5 首节点是树形节点, 若是则进入红黑树数的取值流程, 并返回结果;

6 否则进入链表的取值流程, 遍历链表，检索`key`和`hash`与入参相同的节点，若找到则返回该节点，否则返回`null`。

# equals和==区别， 重写equals一定要重写hashcode方法吗？为什么？hashcode方法有什么作用?

  对于基本类型来说，==比较两个基本类型的值是否相等，对于引用类型来说，==比较的是内个引用类型的内存地址。

   Object类中的equals方法和“==”是一样的，没有区别，即俩个对象的比较是比较他们的栈内存中存储的内存地址。而String类，Integer类等等一些类，是重写了equals方法，才使得equals和“==不同”，他们比较的是值是不是相等。所以，当自己创建类时，自动继承了Object的equals方法，要想实现不同的等于比较，必须重写equals方法。

​    equals说明: equals用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object类的，所以适用于所有对象，如果没有对该方法进行覆盖的话，调用的仍然是Object类中的方法，而Object中的equals方法返回的却是==的判断。

   重写equals一般是要重写hashcode方法的，首先equals与hashcode间的关系是这样的：

   1、如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同；

   2、如果两个对象的hashCode相同，它们并不一定相同(即用equals比较返回false)  

   比如说两个字符串的hashcode相同，但是这两个字符串可以是不同的字符串，对象也是同理，自己理解的。

   至于hashcode有什么用？

   为了提高程序的效率才实现了hashcode方法，先进行hashcode的比较，如果不同，那没就不必在进行equals的比较了，这样就大大减少了equals比较的次数，这对比需要比较的数量很大的效率提高是很明显的，一个很好的例子就是在集合中的使用；

# 重写equal为什么一定也要同时重写hashcode？

**1.equals()****的所属以及内部原理（即Object中equals方法的实现原理）**

public boolean equals(Object obj) {  return (this == obj);   }

在Object类中这个方法实际上是判断两个对象是否具有相同的引用，如果有，它们就一定相等。

实际上我们知道所有的对象都拥有标识(内存地址)和状态(数据)，同时“==”比较两个对象的的内存地址，所以说 Object 的 equals() 方法是比较两个对象的内存地址是否相等，即若 object1.equals(object2) 为 true，则表示 object1和 object2实际上是引用同一个对象。

**2.equals()****与‘==’的区别**

默认情况下也就是从超类Object继承而来的equals方法与‘==’是完全等价的，比较的都是对象的内存地址，但我们可以重写equals方法，使其按照我们的需求的方式进行比较，如String类重写了equals方法，使其比较的是字符的序列，而不再是内存地址。

**3.equals()****的重写规则**

· 自反性：对于任何非null的引用值x，x.equals(x)应返回true。

· 对称性：对于任何非null的引用值x与y，当且仅当：y.equals(x)返回true时，x.equals(y)才返回true。

· 传递性：对于任何非null的引用值x、y与z，如果y.equals(x)返回true，y.equals(z)返回true，那么x.equals(z)也应返回true。

· 一致性：对于任何非null的引用值x与y，假设对象上equals比较中的信息没有被修改，则多次调用x.equals(y)始终返回true或者false。

· 非空性：对于任何非空引用值x，x.equal(null)应返回false。

**4.****为什么重写equals()的同时还得重写hashCode()**

​    hashCode的意思就是散列码，也就是哈希码，是由对象导出的一个整型值。在java中，我们可以使用hashCode()来获取对象的哈希码，其值就是对象的存储地址，这个方法在Object类中声明，因此所有的子类都含有该方法。

​      这个问题主要是针对Map接口映射相关的操作，Map接口的类会使用到键对象的哈希码，当我们调用put方法或者get方法对Map容器进行操作时，都是根据键对象的哈希码来计算存储位置的，因此如果我们对哈希码的获取没有相关保证，就会造成哈希冲突，降低Map的访问效率。

​      在Java API文档中关于hashCode方法有以下几点规定：

·    在java应用程序执行期间，如果在equals方法比较中所用的信息没有被修改，那么在同一个对象上多次调用hashCode方法时必须一致地返回相同的整数。如果多次执行同一个应用时，不要求该整数必须相同。

·    如果两个对象通过调用equals方法是相等的，那么这两个对象调用hashCode方法必须返回相同的整数。

·    如果两个对象通过调用equals方法是不相等的，不要求这两个对象调用hashCode方法必须返回不同的整数。但是程序员应该意识到对不同的对象产生不同的hash值可以提供哈希表的性能。

​      通过前面的分析，我们知道在Object类中，hashCode方法是通过Object对象的地址计算出来的，因为Object对象只与自身相等，所以同一个对象的地址总是相等的，计算取得的哈希码也必然相等，对于不同的对象，由于地址不同，所获取的哈希码自然也不会相等。因此到这里我们就明白了，如果一个类重写了equals方法，但没有重写hashCode方法，将会直接违法了第2条规定，这样的话，如果我们通过映射表(Map接口)操作相关对象时，就无法达到我们预期想要的效果。

**5.****重写equals()中getClass与instanceof的区别**

​      在重写equals() 方法时，一般都是推荐使用 getClass 来进行类型判断（除非所有的子类有统一的语义才使用instanceof），不是使用 instanceof。instanceof 的作用是判断其左边对象是否为其右边类的实例，返回 boolean 类型的数据。可以用来判断继承中的子类的实例是否为父类的实现。

**6.****编写一个完美equals()的几点建议**

1）显式参数命名为otherObject，稍后需要将它转换成另一个叫做other的变量（参数名命名，强制转换请参考建议5）

2）检测this与otherObject是否引用同一个对象 ：if(this == otherObject) return true;（存储地址相同，肯定是同个对象，直接返回true）

3) 检测otherObject是否为null，如果为null，返回false。if(otherObject == null) return false;

4) 比较this与otherObject是否属于同一个类 （视需求而选择）

·    如果equals的语义在每个子类中有所改变，就使用getClass检测 ：if(getClass()!=otherObject.getClass()) return false;

·    如果所有的子类都拥有统一的语义，就使用instanceof检测 ：if(!(otherObject instanceof ClassName)) return false;

5) 将otherObject转换为相应类的类型变量：ClassName other = (ClassName) otherObject;

6) 现在开始对所有需要比较的域进行比较 。使用==比较基本类型域，使用equals比较对象域。若所有的域都匹配，就返回true，否则flase。

·    如果在子类中重新定义equals，就要在其中包含调用super.equals(other)

·    当此方法被重写时，通常有必要重写 hashCode 方法，以维护 hashCode 方法的常规协定：相等对象必须具有相等的哈希码。

# hashcode和equals过程？

   在大多数编程实践中，归根结底会落实到数据的存取问题上。Java 以面向对象为核心思想，把数据按照一定的数据结构保存到存储单元（容器类）中，根据不同的数据结构封装提供了丰富的操作数据的API，降低了数据操作的复杂度。其中Map 和 Set 的绝大多数实现类的底层都会用到散列表结构，它们是**不允许重复**的**散列表结构****，**这些容器在存储元素的时必须对元素做出判断：**在当前的容器中有没有和新元素相同的元素？用****equals()** **会有力不从心的时候（**要调用容器中所有对象的 equals() 方法和新元素进行比较，时间复杂度为 O(n)**），而****hashCode()** **小力出奇迹（****两个相同的对象，****hashCode()** **一定相同****：运用** **hashCode()** **判断是否有相同元素的代价，只是一次哈希计算能定位存放的位置，时间复杂度为****O(1)****，若已存在再与新元素调用****1****次****equals****方法****）。**

hashcode和equals二者的关系：

1、如果两个对象equals，Java运行时环境会认为他们的hashcode一定相等。

2、如果两个对象不equals，他们的hashcode有可能相等。

3、如果两个对象hashcode相等，他们不一定equals。

4、如果两个对象hashcode不相等，他们一定不equals。

​    hashcode的作用主要体现在哈希表结构中，如果hashCode()每次都返回相同的数，这种极端冲突会将哈希表退化为链表，那么所有的对象都会被放到同一个bucket中，每次执行查找操作都会遍历链表，这样也就完全失去了哈希的作用。

# final类事务是怎样的

**关键字、修饰符修饰数据、方法、类**

**1.** **最终值**

·    当final修饰基本类型数据时，保证值不能改变

·    当final修饰引用类型数据时，地址值不能改变

·    当final修饰成员变量，保证对象创建完成之前（可以在构造函数中）给值

·    当final修饰静态变量（静态常量）时，保证类加载完成之前给值

**2.** **最终方法**   支持重载，不支持重写

**3.** **最终类**    可以继承别的类，但是不能被别的类继承

​    使用final显示的声明变量是一个非常良好的编码习惯，因为java会对final修饰的变量进行内联，提高代码的性能。可以利用final关键字的同步作用，构建一个线程安全（可在线程之间共享）的类。final能够做出如下保证：当你创建一个对象时，使用final关键字能够使得另一个线程不会访问到处于“部分创建”的对象，否则是会可能发生的。这是因为，当用作对象的一个属性时，final有着如下的语义：

用来保证对象的安全发布（初始化），防止对象引用被其他线程在对象被完全构造完成前拿到并使用。

当构造函数结束时，final类型的值是被保证其他线程访问该对象时，它们的值是可见的。  **另外：**

·    final类型的成员变量的值，包括那些用final引用指向的collections的对象，是读线程安全而无需使用synchronization的；

·    不可变对象（指所有的成员都是final并且成员要么是基本类型，要么指向另一个不可变对象）可以并发访问而无需使用同步机制；

·    通过final引用读取“实际不可变”对象（指成员虽然实际并不是final，然而却从不会改变）也是安全的。然而，从程序设计的角度来看，在此种情况下强化不可变性是明智的（如用Collections.unmodifiableList()封装一个collection）；

·    如果你有一个指向collection，数组或其他可变对象的final引用，如果存在其他线程访问，仍然需要使用同步机制来访问该对象（或使用ConcurrentHashMap）。

·    与Volatile 有相似作用，不过Final主要用于不可变变量（基本数据类型和非基本数据类型），进行安全的发布（初始化）。而Volatile可以用于安全的发布不可变变量，也可以提供可变变量的可见性。

应用场景：

​      1、饿汉单例模式，将静态的最终的单例实例的引用率先存放在静态区中。

​      2、ThreadPoolExecutor、ConcurrentHashMap.Node{Key, hash}

### 安全发布的常用模式

·    在静态初始化函数中初始化一个对象引用

·    将对象的应用保存到volatile类型的域或者AtomicReferance对象中

·    将对象的引用保存到某个正确构造对象的final类型域中

·    将对象的引用保存到一个由锁保护的域中。

# 说说反射的用途及实现，反射是不是很慢，我们在项目中是否要避免使用反射；

​      Java反射是指我们可以于运行时加载、探知、使用编译期间完全未知的classes。换句话说，Java程序可以加载一个运行时才得知名称的class，获悉其完整构造（但不包括methods定义），并生成其对象实体、或对其fields设值、或唤起其methods。这种“看透class”的能力被称为introspection（内省、内观、反省）。

​      反射大概比直接调用慢50~100倍（JDK7以后对反射有优化，大概在5倍到20倍不等了），但是需要你在执行100万遍的时候才会有所感觉。为了更好的使用反射，我们应该在项目启动的时候将反射所需要的相关配置及元数据加载进内存中，在运行阶段都从缓存中取这些元数据进行反射操作。

![img](http://image.itstabber.com/2020-09-09/clip_image042.png)

## Java Reflection反射框架主要提供以下功能

\1. 在运行时判断任意一个对象所属的类；

\2. 在运行时构造任意一个类的对象；

\3. 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）；

\4. 在运行时调用任意一个对象的方法

反射最重要的用途就是开发各种通用框架(Spring，hibernate，mybatis)。学习Spring 的依赖注入和反转控制，可以对反射有更好的理解。

## 反射的实现(反射相关的类一般都在java.lang.relfect包里)

1、获得Class对象：

  Hero.class          // 直接获取某一个类的class

  new Hero().getClass();   // 调用某个对象的getClass()方法

   Class.forName("com.Hero"); // 使用Class类的forName静态方法

2、判断是否为某个类的实例

  (hero **instanceof** Hero) // 用**instanceof**关键字来判断是否为某个类的实例

3、获取构造器信息：

   Constructor con = clazz.getConstructor(形参.class);

  Constructor[] conArray = clazz.getConstructors(); // 所有公有构造方法

  conArray = clazz.getDeclaredConstructors(); // 所有的构造方法(包括：私有、受保护、默认、公有)

4、创建实例：

   Hero.**class**.newInstance(); // 使用Class对象的newInstance()方法创建Class对象对应类的实例。

   Hero hero = con.newInstance(实参); // 先通过Class对象获取指定构造器Constructor，再调用con对象的newInstance()创建实例。

5、获取类的成员变量（字段）信息

​    Hero.**class**.getFields(); // 访问共有的成员变量

​    Hero.**class**.getDeclareFields(); // 得到所有的字段，包括公共，保护，默认（包）和私有变量，但不包括继承的字段。

   Field f1 = hero.getDeclaredField("属性名"); // 获取属性

  f1.set(hero, 实参); // 修改属性，注意这里的hero是对象，不是类对象

6、获取方法

   Method[] methods = Hero.**class**.getDeclaredMethods();

  Method m = hero.getClass().getMethod("setName", String.class);

7、调用方法

  m.setAccessible(true); // 暴力访问(忽略掉访问修饰符)

  m.invoke(hero, "hero2"); // 对hero对象，调用这个方法

8、利用反射创建数组

   Array.newInstance();

9、生成动态代理

  在java的动态代理机制中，有两个重要的类或接口，一个是InvocationHandler(Interface)、另一个则是Proxy(Class)。可以通过使用Proxy.newProxyInstance()方法创建动态代理。newProxyInstance()方法有三个参数：

  1、类加载器（ClassLoader）用来加载动态代理类。

  2、一个要实现的接口的数组。

  3、一个InvocationHandler把所有方法的调用都转到代理上。

由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。

另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。

# 静态代理、动态代理和Cglib代理

一、静态代理

​      1、需要定义接口或者父类

​      2、被代理对象与代理对象一起实现相同的接口或者是继承相同父类

​      3、在代理对象中声明一个该接口或者父类的成员变量

​      4、在代理对象构造时注入该接口或者父类的一个实例，作为被代理对象，赋值给代理对象的成员变量

​      5、代理对象在重写该接口或父类的方法中调用被代理对象相应的方法，做到在不修改目标对象的功能前提下，对目标功能进行扩展和增强。

二、动态代理

​      1、代理对象，不需要实现接口；但是目标对象一定要实现接口，否则不能用动态代理

​      2、代理对象的生成，是利用JDK的API，动态的在内存中构建代理对象

JDK中生成代理对象的API代理类所在包:java.lang.reflect.Proxy.newProxyInstance()方法： 

static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h)

注意该方法是在Proxy类中是静态方法，且接收的三个参数依次为:

·    ClassLoader loader：指定当前目标对象使用类加载器，获取加载器的方法是固定的

·    Class<?>[] interfaces：目标对象实现的接口的类型，使用泛型方式确认类型

·    InvocationHandler h：事件处理，执行目标对象的方法时，会触发事件处理器的方法，会把当前执行目标对象的方法作为参数传入

三、Cglib代理

目标对象只是一个单独的对象，并没有实现任何的接口，这个时候就可以使用以目标对象子类的方式类实现代理，这种方法就叫做：Cglib代理。Cglib代理，也叫作子类代理，它是在内存中构建一个子类对象从而实现对目标对象功能的扩展。

·    Cglib是一个强大的高性能的代码生成包，它可以在运行期扩展java类与实现java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和synaop，为他们提供方法的MethodInterceptor (拦截)。

·    Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类，不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。

**Cglib****子类代理实现方法：**

1、需要引入cglib的jar文件，但是Spring核心包中已经包括了Cglib功能，所以直接在Maven中添加s`pring-core.jar`即可。如果非Maven工程则需要引入cglib.jar和asm.jar；

2、引入功能包后，就可以在内存中动态构建子类（代理类实现MethodInterceptor接口，通过Enhancer工具类给目标对象创建一个代理对象）

3、代理的类不能为final，否则报错

4、目标对象的方法如果为final/static，那么就不会被拦截，即不会执行目标对象额外的业务方法。

# 说说自定义注解的场景及实现；

## 使用场景

·    类属性自动赋值，例如对上下文、传入参数等赋值。@Value

·    验证对象属性完整性，例如，对参数的校验。@NotNull

·    代替配置文件功能，像spring基于注解的配置。@Configuration

·    可以生成文档，例如java 最早提供的注解。常用的有 @param @return 等

·    利用注解针对性做一些前置或者后置的处理。例如：登陆校验、权限拦截、记录日志等，以及各种框架如Spring，Hibernate，Junit

## 实现方法

·    Java自定义注解通过**运行期间靠反射获取注解**，实际开发过程中，如果我们需要获取某个方法的调用日志，可以通过**AOP（动态代理机制）** 对方法添加切面，通过反射获取方法包含的注解，如果包含了日志注解，就进行日志记录。

·    Java反射实际是通过对Class对象进行操作而实现，Class对象为我们提供了一系列方法对类进行操作。

·    在JVM角度上来说，**Class文件**是**一组以8字节为基础单位的二进制流，各个数据项目按照严格的顺序紧凑的排列在一起**，里面包含了类、方法、字段等有关数据，**通过对Class数据流进行相应的处理**，就可以得到相应的字段、方法、注解、类等元数据。

## 注解的作用

·    注解是一种元数据形式。即注解是属于java的一种数据类型，和类、接口、数组、枚举类似。

·    注解用来修饰，类、方法、变量、参数、包。

·    注解不会对所修饰的代码产生直接的影响。

## 自定义注解

·    首先使用 @interface声明注解名称

·    自定义注解还会用到4个元注解：@Retention、@Inherited、@Documented、@Target

·    @Documented –注解是否将包含在JavaDoc中

·    @Retention –什么时候使用该注解

·    @Target –注解用于什么地方

·    @Inherited – 是否允许子类继承该注解

  @Target(ElementType.TYPE) // ElementType枚举：CONSTRUCTOR、FIELD、LOCAL_VARIABLE、METHOD、PACKAGE、PARAMETER、TYPE  @Retention(value = RetentionPolicy.RUNTIME)  public @interface Custom1  {      String[] values();  }  

 

# 跳跃表原理

   跳跃表（SkipList），就是在普通链表的基础上增加了多层索引链表，这样在查找时就可以通过在上下不同层级的索引链表间跳跃，以达到快速查找的目的。跳跃表是一种基于有序链表的扩展，利用类似索引的思想，提取出链表中的部分关键节点作为索引链表层。对于节点数目达到上W个，可以进一步在已经提取出的一层关键节点作为索引之上再提取，提出一层索引的索引。当节点足够多的时候，我们不止能提出两层索引，还可以向更高层次提取，保证每一层是上一层节点数的一半。至于提取的极限，则是同一层只有两个节点的时候，因为一个节点没有比较的意义。这样的多层链表结构就是所谓的跳跃表。如上图结构所示。

蓝色最下层原链表是真正存储数据的数据链表，其中每个Node节点都有三个字段：

·    key：键值对的KEY

·    value：键值对的VALUE

·    next：指向下一个数据节点

1级索引层索引链表是分层级的，而且同时指向它的下层索引节点以及同层级的右侧的索引节点。因此，每个Index节点也有三个字段：

·    node：同一列的Index节点都指向最下层的同一个Node节点，目的是可以随时通过索引节点判断出它对应的数据节点是哪个

·    down：指向下一层的索引节点

·    right：指向同一层的右侧的索引节点

2级索引层上级头部（索引的）索引链表是在普通的索引链表的基础上新增了一个表示当前横向链表层级的字段。因此，每个HeadIndex节点就需要用四个字段来表示：

·    level：当前索引链表的层级，从 1 开始计数

·    node：指向左下角的基础Node节点，这个Node节点只是起到一个标志性作用，因此没有KEY

·    down：指向下一层的头部索引节点

·    right：指向同一层的右侧的索引节点

可以参考`Java8`的`ConcurrentSkipListMap`源码。

## Redis中的有序集合

​      Redis使用跳跃表作为有序集合键的的底层实现，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时Redis就会使用跳跃表来作为有序集合键的底层实现。Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。

**Redis****为什么要使用跳跃表而不是红黑树？**

​      其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。对于按照区间查找数据这个操作，跳表可以做到O(logn)的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。当然，Redis 之所以用跳表来实现有序集合，还有其他原因，比如，跳表更容易代码实现。虽然跳表的实现也不简单，但比起红黑树来说还是好懂、好写多了，而简单就意味着可读性好，不容易出错。还有，跳表更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。我们做业务开发的时候，直接拿来用就可以了，不用费劲自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果你想使用跳表，必须要自己实现。Java创建Object对象的方法有哪些

·    使用New关键字，调用类的构造函数直接创建

·    使用反射Class类的newInstance方法，newInstance方法调用无参构造器创建对象(反射)，

Class.forName("com.test3.Hello").newInstance();

Class.forName("com.test3.Hello").getConstructor().newInstance();

·    使用clone方法：通过实现Cloneable接口并使用clone方法产生的对象在内存中是不同的两个对象，可以实现对象的创建功能。

·    实现Serializable接口，采用序列化与反序列化方式：ObjectOutputStream.writeObject(obj1);和ObjectInputStream.readObject();

·    使用Unsafe类创建对象，指针方式操作内存空间，不安全不建议使用。

# Java Object对象的创建过程

![img](http://image.itstabber.com/2020-09-10/clip_image001.png)

l **类检查器**

JVM遇到new指令的时候,首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用,并且检查这个符号引用代码的类是否被加载过、解析过、初始化过。若没有，则必须先进行类加载过程。

l **分配内存** (对象实例**内存布局**：对象头->实例数据->对齐填充)

在类加载检查通过之后,接下来虚拟机将会为新生的对象分配内存. 对象所需要的内存大小在类加载完成之后便会确定,为对象分配内存空间的任务等同于把一块确定大小的内存从java堆中划分出来.分配方式有**指针碰撞****（****Bump the Pointer****）**和**空闲列表****（****Free List****）**两种,选择哪种分配方式由java堆是否规整决定,而java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。

分配内存的方式最终取决于GC收集器的算法是"标记-清除"还是"标记-整理(标记-压缩)"

![img](http://image.itstabber.com/2020-09-10/clip_image002.png)

l **初始化零值**

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 如果使用TLAB（Thread Local Allocation Buffer，本地线程分配缓冲），这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的**实例****字****段**在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

l **设置对象头**（Object Header）

在HotSpot虚拟机中，对象存储的**内存布局**分为3块区域：**对象头**（Header）、**实例数据**（Instance Data）和**对齐填充**（Padding）。对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。初始化零值之后，虚拟机将给对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息需要存放在对象的对象头之中。

l **执行init方法**

在上面的工作都完成之后,以虚拟机的视角来看,对象创建才刚开始,<init>方法还没有被执行,所有的字段值还都为零.所以一般来说,执行new指令之后接着执行方法,把对象按照程序员的意愿进行初始化,这样一个真正的对象才算完全产生出来.

# Java/JVM的内存结构（内存区域、运行时数据区域）

   ![img](http://image.itstabber.com/2020-09-10/clip_image003.png)

**1. 方法区（Method Area）：**方法区属于线程共享的内存区域，又称Non-Heap（非堆），主要用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，根据Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError 异常。值得注意的是在方法区中存在一个叫运行时常量池(Runtime Constant Pool）的区域，它主要用于存放编译器生成的各种字面量和符号引用，这些内容将在类加载后存放到运行时常量池中，以便后续使用。

![img](http://image.itstabber.com/2020-09-10/clip_image004.png)

方法区（Method Area）是JVM规范里面的运行时数据区的一个组成部分，主要用来存储class、运行时常量池、字段、方法、代码、JIT代码等。方法区是JVM规范中的一部分，并不是实际的实现，切忌将规范跟实现混为一谈。永久带又叫Perm区，只存在于Hotspot JVM中，并且只存在于jdk7和之前的版本中，jdk8中已经彻底移除了永久带，jdk8中引入了一个新的内存区域叫Meta-space。永久带是实现层面的东西，永久带里面存的东西基本上就是方法区规定的那些东西。**区别:** 方法区是规范层面的东西，规定了这一个区域要存放哪些东西，永久带或者是Meta-space是对方法区的不同实现，是实现层面的东西。

![https://oscimg.oschina.net/oscnet/b941a038303f37cfceb7d3b4d3f3d34646d.jpg](http://image.itstabber.com/2020-09-10/clip_image005.png)

\2.   **Java****堆（Java Heap）：**Java 堆也是属于线程共享的内存区域，它在虚拟机启动时创建，是Java 虚拟机所管理的内存中最大的一块，主要用于存放对象实例，几乎所有的对象实例都在这里分配内存，注意Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做**GC****堆**，如果在堆中没有内存满足实例分配需求，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。

Java虚拟机根据对象存活的周期不同，再把**堆**内存划分为几块，一般分为新生代（Young Generation）、老年代（Old Generationn）和永久代（Permanent Generationn）（对HotSpot虚拟机而言），这就是JVM的内存分代策略。

\3.   **程序计数器（Program Counter Register）：**属于线程私有的数据区域，是一小块内存空间，它可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时，通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。

\4.   **虚拟机栈(Java Virtual Machine Stacks)：**属于线程私有的数据区域，与线程同时创建，总数与线程关联，代表Java方法执行的内存模型。每个方法执行时都会创建一个栈桢来存储方法的的变量表、操作数栈、动态链接方法、返回值、返回地址等信息。每个方法从调用直结束就对于一个栈桢在虚拟机栈中的入栈和出栈过程，如下（图有误，应该为栈桢）：

![img](http://image.itstabber.com/2020-09-10/clip_image006.png)

\5.   **本地方法栈(Native Method Stacks)：**本地方法栈属于线程私有的数据区域，这部分主要与虚拟机用到的 Native 方法相关，一般情况下，我们无需关心此区域。

# java内存模型和优化有做过哪些？

**一.内存模型的相关概念**

大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。

![enter image description here](http://image.itstabber.com/2020-09-10/clip_image007.png)![img](http://image.itstabber.com/2020-09-10/clip_image008.png)**缓存一致性****问题**：如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现，多个线程访问的变量为共享变量的），那么就可能存在缓存不一致的问题。

并发编程中三个问题：原子性问题，可见性问题，有序性问题。

**原子性：**即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

**可见性：**是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性：**即程序执行的顺序按照代码的先后顺序执行。**指令重排序**，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会（考虑指令之间的数据依赖性）保证程序最终执行结果和代码顺序执行的结果是一致的。指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。

也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。

**二.Java内存模型（JMM）：线程通信，消息传递**

![img](http://image.itstabber.com/2020-09-10/clip_image009.png) ![img](http://image.itstabber.com/2020-09-10/clip_image010.png)

在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（即线程的上下文，类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。

为了保证共享内存的正确性（并发编程中可以满足原子性、可见性及有序性），有一个重要的概念，那就是——Java内存模型。JMM内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。

内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。

# JMM（Java内存模型）内存之间的交互操作与规则

![在这里插入图片描述](http://image.itstabber.com/2020-09-10/clip_image011.png)

一个变量是怎么从主内存拷贝到线程的工作内存中的。在JMM中主要定义了8种操作来完成上述的工作，并且这**8****种操作**都是原子性（即同步）的，不可分割的。它们分别是：

- lock（锁定）：目的是把主内存中的变量标识为线程已经锁定的状态。
- unlock（解锁）：目的是把主内存中已经是锁定状态的变量解锁，解锁后的变量可以被其他线程锁定。
- read（读取）：目的是把变量的值从主内存中传输到线程的工作内存中。
- load（载入）：目的是把主内存中得到的变量值存储到工作内存的变量副本中。
- use（使用）：目的是把工作内存中变量的值传递给执行引擎。
- assign（赋值）：目的是把执行引擎接收到的值赋给工作内存中的变量。
- store（存储）：目的是把工作内存中变量的值传送到主内存中。
- write（写入）：目的是把工作内存中得到的变量的值放入主内存的变量中。

上述就是每种操作的具体功能。在虚拟机执行上述操作时有一些默认的**规定**：

- 不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起了同步但主内存不接受的情况。
- 不允许变量在工作内存中改变了之后不同步到主内存中。
- 不允许线程在没有发生任何改变的情况下把数据从线程的工作内存同步回主内存中。
- 变量只能在主内存中产生，不允许在工作内存中直接使用一个未初始化的变量。
- 变量在同一个时刻只允许一条线程对其进行lock操作。
- 如果对变量执行lock操作时，线程会清空工作内存中此变量的值。
- 若变量事先没有被lock锁定，那不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
- 对变量执行unlock操作之前，必须先把此变量同步回主内存中。

# Java内存模型的三大特征

Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的。

**1.****原子性**：在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。

**2.****可见性**：对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。

**3.****有序性**：在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。

在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。

另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before先行发生原则，是指Java内存模型中定义的两项操作之间的依序关系，如果说操作A先行发生于操作B，其实就是说发生操作B之前。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

下面就来具体介绍下**happens-before原则（先行发生原则）：**摘自《深入理解Java虚拟机》

- **程序次序规则：**一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
- **锁定规则：**一个unLock操作先行发生于后面对同一个锁额lock操作
- **volatile****变量规则：**对一个变量的写操作先行发生于后面对这个变量的读操作
- **传递规则：**如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
- **线程启动规则：**Thread对象的start()方法先行发生于此线程的每个一个动作
- **线程中断规则：**对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
- **线程终结规则：**线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
- **对象终结规则：**一个对象的初始化完成先行发生于他的finalize()方法的开始

另外，还有一个“传递性”。

# GC分哪两种，Minor GC 和Full GC有什么区别？

​    JVM内存区域中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 Java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的。

- 次数上频繁收集      在Young区（**Eden、Survivor0、Survivor1**）。**Minor GC****清理年轻代内存。**
- 次数上较少收集      在Old区。**Major GC****清理老年代内存。**
- **Full GC = Minor GC + Major GC** **+ Perm     gen(****外)****。**Full GC 是清理整个堆空间：包括年轻代和老年代全堆，外加永久代。
- 基本不动Perm区（JDK1.7 永久区）

PS：https://www.cnblogs.com/tuhooo/p/7508503.html

# 什么时候会触发Full GC？

触发Full GC执行的情况有如下四种：

**1****、Old区（老年代）空间不足。**老年代空间只有在新生代对象转入及创建为大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误：java.lang.OutOfMemoryError: Java heap space。为避免以上两种状况引起的FullGC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。

**2. Permanet Generation****空间满。永久代**中存放的为一些class的信息等，当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息：

java.lang.OutOfMemoryError: PermGen space

为避免Perm Gen占满造成Full GC现象，可采用为增大Perm Gen空间或转为使用CMS GC。

**3. CMS GC****时出现promotion failed和concurrent mode failure**

对于采用CMS进行旧生代GC的程序而言，尤其要注意GC日志中是否有promotion failed和concurrent mode failure两种状况，当这两种状况出现时可能会触发Full GC。

promotion（晋升） failed是在进行Minor GC时，survivor space放不下、对象只能放入旧生代，而此时旧生代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入旧生代，而此时旧生代空间不足造成的。

应对措施为：增大survivorspace、旧生代空间或调低触发并发GC的比率，但在JDK 5.0+、6.0+的版本中有可能会由于JDK的bug29导致CMS在remark完毕后很久才触发sweeping动作。对于这种状况，可通过设置-XX:CMSMaxAbortablePrecleanTime=5（单位为ms）来避免。

**4.** **统计得到的Minor GC****晋升****到旧生代的平均大小****大于****旧生代的剩余空间（或者：**当**年老代的剩余空间小于Young GC的平均晋升大小时****）。**

这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。

例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。

当新生代采用**Parallel Scavenge****收集器**（并行清除）时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否大于6MB，如小于，则触发对旧生代的回收。

除了以上4种状况外，手动调用System.gc()显式触发Full GC；Heap dump带GC，默认也是触发Full GC；对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java-Dsun.rmi.dgc.client.gcInterval=3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。

# JVM内存模型，为什么survivor需要有2个。

**减少Full GC发生：**若没有Survivor区，当Eden区满时触发一次Minor GC，就会把Eden区的对象复制到老年代，这样当老年代满了之后又会触发Major GC（可看做Full GC），比较耗时。避免直接放入老年代被装满，进行Major GC且连带Minor GC也就是Full GC，出现老年代频发Full GC而严重影响效率问题。Survivor具有预筛选保证，只有对象超过一定岁数(默认15)才会送往老年代，Survivor区可以减少被送到老年代的对象，进而减少Full GC发生。

**规避内存碎片化：**新生代使用复制回收算法，当Eden区填满后，触发Minor GC进行垃圾回收，幸存的对象会移动到（假设只有一个）Survivor区，这样循环往复。此时，Survivor区被装满了，也会进行Minor GC，将一些对象kill掉，幸存的对象只能保存在原来的位置，这样就会出现大量的内存碎片（被占用内存不连续），严重影响性能。如果有两个Survivor区，便可以保证一个为空，另一个是非空且无碎片保存的。

# 堆（Heap）跟栈（Stack）的区别

堆和栈都是Java用来在RAM中存放数据的地方。

**堆（运行时动态分配，灵活）：**

（1）Java的堆是一个运行时数据区，类的对象从堆中分配空间。这些对象通过**new等指令**建立，通过**垃圾回收器**来销毁。

（2）堆的优势是可以**动态分配**内存空间，需要多少内存空间不必事先告诉编译器，因为它是在运行时动态分配的。但缺点是，由于需要在运行时动态分配内存，所以存取速度较慢。

**栈（先进后出，有序）：**

（1）栈中主要存放一些**基本数据类型的（局部）变量**（byte，short，int，long，float，double，boolean，char）和对象的引用。

（2）栈的优势是，**存取速度比堆快，栈数据可以共享**。但缺点是，存放在栈中的数据占用多少内存空间需要在**编译时（静态分配）**确定下来，缺乏灵活性。

**（1）存放内容不同：**

栈内存：用来存放基本数据类型变量和引用类型变量。

堆内存：用来存放运行时通过new关键字创建的对象。

**（2）生命周期不同：**

栈的生命周期与线程相同，随线程而生，随线程而亡，是线程私有的。

堆的生命周期与JVM相同，JVM启动时创建，JVM停止时销毁，是线程共享的。

**（3）内存回收管理不同：**

栈是线程私有的内存区域，每个方法被执行的时候都会创建一个栈帧，栈帧随着方法的进入和退出在虚拟机栈中做入栈和出栈操作， 实现了自动内存清理。

堆是线程共享的内存区域，没有确定的销毁时间，因此内存回收主要集中于堆中，在堆中分配的内存由垃圾收集器来管理回收。

**（4）存取速度不同：**

栈的存取速度较快，仅次于寄存器，但栈的数据大小与生存期必须是确定的，缺乏灵活性。另外，栈数据可以共享。

String可以用以下两种方式来创建：

```
String str1 = new String("abc");
String str2 = "abc";
```

第一种使用new来创建的对象，它存放在堆中。每调用一次就创建一个新的对象。

第二种是先在栈中创建对象的引用str2，然后查找栈中有没有存放“abc”，如果没有，则将“abc”存放进栈，并将str2指向“abc”，如果已经有“abc”，则直接将str2指向“abc”。

# java栈主要存什么内容，相比堆有什么优势

栈(stack)：是一个先进后出的数据结构，主要存储方法（函数）中的参数，局部变量，基本类型的变量（字节，短，整型，长，浮点，双精度，布尔值，Char）和对象的引用类型（对象句柄）。栈中数据的生存空间一般在当前scopes作用域内（就是由{...}括起来的区域）。 

栈的优势是存取速度比堆要快，仅次于寄存器，栈数据可以共享（多个引用可以指向同一个地址），随函数返回自动清除。但缺点是，存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。

# 栈实现队列，反思路：队列实现栈

栈（Stack）是先入后出，队列（Queue）是先入先出。根据这个思想，可以用一个栈作为入队，另一个栈作为出队。只要把第一个栈的栈顶的元素压入第二个栈就好了，出队的时候输出第二个栈的栈顶，如果第二个栈的空了就需要不断操作从第一个栈的栈顶压入第二个栈，但是如果第一个栈也空了，那就说明所有元素都输出来了。

# Linux内存模型，和java内存模型

 

# String与StringBuffer的区别

**String****：**

1、String是final类，即不能被继承。

2、是对象（引用）类型不是原始类型，String对象为不可变对象，一旦被创建，就不能修改它的值。

3、对已创建好的String对象进行修改操作，每次都必须重新创建新的对象来保存新的值。

**StringBuffer****：**

1、是一个可变字符串类，底层为可变char[]默认capacity=16，只能通过new关键字调构造函数来创建对象；操作方法都是synchronized同步的，线程安全。

2、当对StringBuffer实例化对象进行修改时，不会像String那样重新建立对象，通过它的append方法向其赋值，只对这一个对象操作。

3、字符串连接操作中StringBuffer的效率要明显比String高。

# GC算法，垃圾回收算法的优缺点

**1****、引用计数法**（引用和去引用伴随加法和减法，影响性能；很难处理循环引用。已被淘汰 –> **根搜索算法**）

![https://img-blog.csdnimg.cn/20190808114151791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODIzODAy,size_16,color_FFFFFF,t_70](http://image.itstabber.com/2020-09-10/clip_image012.png)

**根搜索算法：**处理方式就是**可达性分析算法**，设立若干种根对象，从根（GC Roots）的对象作为起始点，开始向下搜索，搜索所走过的路径称为“**引用链**”，当任何一个根对象到某一个对象没有任何引用链相连（就是从GC Roots到这个对象不可达）时，则认为此对象不可用，是可以被回收的。

可以当做GC roots根对象有以下几种：

（1）栈（栈帧中的本地变量表）中引用的对象。

（2）方法区中的静态成员。

（3）方法区中（声明为final）的常量引用的对象（全局变量的值）

（4）本地方法栈中JNI（一般说的Native方法）引用的对象。

**2、** **标记清除法**（Mark-Sweep）

![https://img-blog.csdnimg.cn/20190808114801136.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODIzODAy,size_16,color_FFFFFF,t_70](http://image.itstabber.com/2020-09-10/clip_image013.jpg)

**3、** **标记整理法**（Mark-Compact / Tidy）

![img](http://image.itstabber.com/2020-09-10/clip_image014.png)

**4、** **标记清除压缩法**（Mark-Sweep-Compact）

![img](http://image.itstabber.com/2020-09-10/clip_image015.png) 

**5、** **复制算法**（Copying）

![img](http://image.itstabber.com/2020-09-10/clip_image016.png)

在根搜索算法的基础上，现代虚拟机的实现当中，垃圾搜集的算法主要有**三种**，分别是上面提到的：标记清除算法、复制算法、标记整理算法。这三种算法都扩充了根搜索算法。

**它们的区别如下：**（>表示前者要优于后者，=表示两者效果一样）

**（1）效率**（仅对比**时间复杂度**）：复制算法**>**标记整理算法**>**标记清除算法。

**（2）内存整齐度**：复制算法**=**标记整理算法**>**标记清除算法。

**（3）内存利用率**：标记整理算法**=**标记清除算法**>**复制算法。

注1：可以看到标记清除算法是比较落后的算法了，但是后两种算法却是在此基础上建立的。

注2：时间与空间不可兼得。

**6、****分代收集算法**（Generational Collection）

根据对象的存活周期的不同将内存划分为：新生代（短命对象）和老年代（长命对象）。

**少量对象存活，适合复制算法**：在**新生代**中，每次GC时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成GC。

**大量对象存活，适合用标记清理 / 标记整理**：在**老年代**中，因为对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清理”/“标记-整理”算法进行GC。

**注：**老年代的对象中，有一小部分是因为在新生代回收时，老年代**做担保**，进来的对象；绝大部分对象是因为很多次GC都没有被回收掉而进入老年代。

# 垃圾收集器

**1、** **Serial****收集器**

串行回收器（单线程收集器）只使用一个 CPU 和一个收集线程，垃圾回收时暂停其他所有的工作线程，直到收集结束。每次回收时只有一个工作线程，对于并发能力较弱的计算机来说，串行回收器的专注性和独占性往往有更好的表现，对于运行在 Client 模式下的虚拟机是一个好选择。串行回收器可以在新生代和老年代使用，新生代采用复制算法，老年代采用标记整理算法。根据作用的堆空间不同，分为新生代串行回收器和老年代串行回收器。

Serial收集器是最古老的收集器，它的缺点是当Serial收集器想进行垃圾回收的时候，必须暂停用户的所有进程，即stopthe world(服务暂停)。到现在为止，它依然是虚拟机运行在client模式下的默认新生代收集器。

参数控制：-XX:+UseSerialGC 使用串行收集器

**2****、ParNew收集器**

ParNew收集器是一个工作在新生代的垃圾收集器，它只是简单的将串行收集器多线程化，它的回收策略和算法和串行回收器一样。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩。能与 CMS 收集器 [配置 ](http://www.liuhaihua.cn/archives/tag/配置)工作，所以是许多运行在 Server 模式下的首选新生代收集器。

在垃圾收集器的上下文中，先明确两个概念：

**并行（Parallel）：**多条垃圾线程并行工作，用户线程仍然处于等待状态

**并发（Concurrent）：**用户线程和垃圾回收线程同时执行（不一定并行，可能会交替执行）

并行收集器关注吞吐量优先，并发收集器关注响应时间优先。

参数控制：-XX:+UseParNewGC 使用ParNew收集器   -XX:ParallelGCThreads 限制线程数量

**3****、Parallel Scavenge收集器**（并行清除）

Parallel是采用复制算法的多线程新生代垃圾回收器，Parallel收集器更关注系统的吞吐量。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)。

停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能够提升用户的体验；

而高吞吐量则可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。

可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩

参数控制：-XX:MaxGCPauseMillis 设置最大垃圾收集停顿时间   -XX:GCTimeRatio 设置吞吐量的大小(默认是99)  -XX:+UseAdaptiveSeizPolicy 打开自适应模式

**4****、Parallel Old收集器**

Parallel Old收集器是Parallel Scavenge收集器的老年代版本，采用多线程和”标记－整理”算法，也是比较关注吞吐量。在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。

参数控制：-XX:+UseParallelOldGC 使用ParallelOld收集器 -XX:ParallelGCThreads 限制线程数量

**5****、CMS收集器**

**CMS(Concurrent Mark Sweep)****并发****标记请除**，它使用的是标记请除法，工作在老年代，主要关注系统的停顿时间。

CMS并不是独占的回收器，也就是说，CMS回收的过程中应用程序仍然在不停的工作，又会有新的垃圾不断的产生，所以在使用CMS的过程中应该确保应用程序的内存足够可用，CMS不会等到应用程序饱和的时候才去回收垃圾，而是在某一阀值(默认为68)的时候开始回收，也就是说当老年代的空间使用率达到68%的时候回执行CMS。如果内存使用率增长很快，在CMS执行过程中，已经出现了内存不足的情况，此时，CMS回收就会失败，虚拟机将启动老年代串行回收器进行垃圾回收，这会导致应用程序中断，直到垃圾回收完成后才会正常工作，这个过程GC的停顿时间可能较长，所以阀值的设置要根据实际情况设置。

标记清除法的缺点是内存碎片问题，CMS提供提供了一些优化设置，可以设置完成CMS之后进行一次碎片整理，也可以设置进行多少次CMS回收后进行碎片整理

参数控制：-XX:CMSInitatingPermOccupancyFraction 设置阀值 -XX:+UserConcMarkSweepGC 使用cms垃圾清理器  -XX:ConcGCThreads 限制线程数量 -XX:+UseCMSCompactAtFullCollection 设置完成CMS之后进行一次碎片整理 -XX:CMSFullGCsBeforeCompaction 设置进行多少次CMS回收后进行碎片整理

**6****、G1收集器**

**G1(Garbage First)****垃圾收集器**是当今垃圾回收技术最前沿的成果之一。早在JDK7就已加入JVM的收集器大家庭中，成为HotSpot重点发展的垃圾回收技术。同优秀的CMS垃圾回收器一样，G1也是关注最小时延的垃圾回收器，也同样适合大尺寸堆内存的垃圾收集，官方也推荐使用G1来代替选择CMS。G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。

**并行与并发**：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。

**分代收集**：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。

**空间整合**：与CMS的“标记-清理”算法不同，G1从整体看来是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上看是基于“复制”算法实现，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。

**可预测的停顿**：这是G1相对于CMS的另外一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器特征了。

参数控制：-XX:+UseG1GC 使用G1垃圾收集器  -XX:ParallelGCThreads 限制线程数量  -XX:MaxGCPauseMillis 指定最大停顿时间

# GC Root什么算法知道对象要被回收

​    GC Root即根搜索算法、可达性分析算法、分析对象的引用链、解决循环引用的问题。

可达性分析算法的思想：从一个被称为GC Roots的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明此对象不可用。

在Java语言中，可作为GC Roots的对象包括下面几种：

- 虚拟机栈（栈帧中的本地变量表）中引用的对象。
- 方法区中类静态属性引用的对象。
- 方法区中常量引用的对象。
- 本地方法栈中JNI（即一般说的Native方法）引用的对象。

当一个对象不可达GC Roots时，这个对象并不会马上被回收，而是处于一个死缓的阶段，若要被真正的回收需要经历两次标记。如果对象在可达性分析中没有与GC Roots的引用链，那么此时就会被第一次标记并且进行一次筛选，筛选的条件是是否有必要执行finalize()方法。当对象没有覆盖finalize()方法或者已经被虚拟机调用过，那么就认为是没必要的。

如果该对象有必要执行finalize()方法，那么这个对象将会放在一个称为F-Queue的队列中，虚拟机会触发一个finalize()线程去执行，此线程是低优先级的，并且虚拟机不会承诺一直等待它运行完，这还是因为如果finalize()执行缓慢或者发生了死锁，那么就会造成F-Queue队列一直等待，造成了内存回收系统的崩溃。GC对处于F-Queue中的对象进行第二次被标记，这时，该对象将被移除“即将回收”集合，等待回收。

# Java内存调优怎么做的

**监控GC状态 》 分析堆Dump文件（工具） 》 分析JVM内存泄露（原因） 》 调优JVM参数。**

1、 查看应用程序日志，使用JVM提供的内存查看工具（如JConsole和Java VisualVM），分析当前堆内存快照dump文件和GC日志。

2、 分析当前JVM参数设置，根据实际的堆内存各区域划分和GC执行频次和时间分析问题。

3、 找准问题原因和问题代码，结合业务和技术，做出问题代码的改进和优化处理。

4、 或是调整GC收集器类型和策略参数，合理控制堆内存各区域的分配大小比例。

**堆内存各区域比例不良设置会导致什么后果：**

1）新生代设置过小

一是新生代GC次数非常频繁，增大系统消耗；

二是导致大对象直接进入旧生代，占据了旧生代剩余空间，诱发Full GC

2）新生代设置过大（一般说来新生代占整个堆1/3比较合适）

一是新生代设置过大会导致旧生代过小（堆总量一定），从而诱发Full GC；

二是新生代GC耗时大幅度增加

3）Survivor设置过小

导致对象从Eden直接到达旧生代，降低了在新生代的存活时间

4）Survivor设置过大

导致Eden过小，增加了GC频率

另外，通过-XX:MaxTenuringThreshold=n来控制新生代存活时间，尽量让对象在新生代被回收

**JVM****提供两种较为简单的GC策略的设置方式：**

1）吞吐量throughput优先，这个值可由-XX:GCTimeRatio=n来设置。

2）暂停pause时间优先，尽量保证每次GC造成的应用停止时间都在指定的数值范围内完成。这个值可由-XX:MaxGCPauseRatio=n来设置。

**Java****自带分析工具：**jstack(查看线程)、jmap(查看内存)和jstat(性能分析)命令

1、通过 jstat -gc pid interval 监测程序的实时运行情况，包括堆内存信息（每一个分区的内存使用率变化情况）以及垃圾回收信息。

2、通过jcmd pid VM.flags 就可以查看到jvm相关的设置参数

3、通过jstack pid命令查看分析线程堆栈信息，通常会结合 top -Hp pid 或 pidstat -p pid -t 一起查看具体线程的状态，也经常用来排查一些死锁的异常

4、通过jmap -heap 进程id查看堆内存初始化配置信息以及堆内存的使用情况，其中就包括垃圾收集器的设置类型，输出堆内存中的对象信息，包括产生了哪些对象，对象数量多少等。

5、通过 jmap -histo[:live] 进程id | more 查看堆内存中的对象数目、大小统计直方图，如果带上 live 则只统计活对象。

6、还可以通过jmap –dump:format=b,file=/tmp/heap.hprof 进程id命令把堆内存的使用情况 dump 到文件中（一般dump文件都比较大）

7、查看 & 分析 GC 日志

首先，我们需要通过 JVM 参数预先设置 GC 日志，通常有以下几种 JVM 参数设置：

-XX:+PrintGC 输出GC日志

-XX:+PrintGCDetails 输出GC的详细日志

-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）

-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）

-XX:+PrintHeapAtGC 在进行 GC 的前后打印出堆的信息

-Xloggc:../logs/gc.log 日志文件的输出路径

 eg：-XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:/log/heapTest.log

如果GC日志非常大，可以用GCViewer工具打开日志文件，图形化界面查看整体的 GC 性能。也可以用GCeasy工具，并且还可以将日志文件压缩之后，上传到 GCeasy 官网即可看到非常清楚的 GC 日志分析结果。

8、各种JVM参数调优（比例、大小、年龄、阀值、开启与并闭、）

9、Linux系统工具

（1）top命令：实时显示正在执行进程的 CPU 使用率、内存使用率以及系统负载等信息

（2）top Hp pid命令：查看具体线程使用系统资源情况

（3）vmstat 命令：是一款指定采样周期和次数的功能性监测工具，我们可以看到，它不仅可以统计内存的使用情况，还可以观测到 CPU 的使用率、swap 的使用情况。但 vmstat 一般很少用来查看内存的使用情况，而是经常被用来观察进程的上下文切换。

（4）pidstat命令：是 Sysstat 中的一个组件；可以通过yum install sysstat 安装该监控组件。pidstat 命令则是深入到线程级别的监测工具。

# 有台节点内存溢出，怎么定位问题。整个过程

**引起内存溢出的原因有很多种，列举一下常见的有以下几种：**

1、内存中加载的数据量过于庞大，如一次从数据库查询出过多数据到内存中；

2、集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；

3、代码中存在死循环或循环内部产生过多的重复的大型对象实体；

4、使用了第三方软件中的BUG；

5、启动参数内存值设定的过小；

**使用内存查看工具动态查看内存使用情况：**

**1****、检查GC日志**：确定内存溢出报错是哪个内存划分区域，不同区域的溢出处理不同；主要有永久代（元空间）、堆、本地方法栈三个区域会出现溢出。

**2.1****、永久代溢出：**java.lang.OutOfMemoryError: PermGen space

​    其全称是Permanent Generation space,是指内存的永久保存区域, 这块内存主要是存放Class和Meta信息的,Class在被Load时就会被放到PermGen space中, GC(Garbage Collection)不会在主程序运行期对 PermGen space进行清理。如果应用中加载的class与jar文件大小超过-XX:MaxPermSize就有可能会产生PermGen space OOMError。通常-XX:MaxPermSize设为-Xmx的1/8。

**2.2****、方法区溢出：**Exception in thread "main" java.lang.OutOfMemoryError: Metaspace

​    在HotSpot中，从Jdk8开始，方法区的实现由永久代变更为元空间（MetaSpace），元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。随着类的加载，元空间使用量逐渐增加，可视情况设置将JVM参数：-XX:MetaspaceSize、-XX:MaxMetaspaceSize调整大小。

**3****、堆内存溢出：**java.lang.OutOfMemoryError: Java heap space

​    通过JVM自带的分析工具，找到产生heap space内存溢出时，堆内存中是哪个类的对象存活数量过多而导致溢出的问题根源。可以通过jdk/bin/jconsole.exe和jdk/bin/jvisualvm.exe两个可视工具来定位。生产环境还可以在启动JVM时加上参数指定Dump文件路径，或通过jmap来转储堆内存dump文件进行离线分析。

**4****、方法栈溢出：**Exception in thread "main" java.lang.StackOverflowError

**栈溢出的原因**

·    是否有递归调用

·    是否有大量循环或死循环

·    全局变量（常量）是否过多

·    数组、List、map等集合数据是否过大

**内存溢出的解决方案：**

1、检查对数据库查询中，是否有一次获得全部数据的查询。如果一次取十万条记录到内存，就可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。

2、检查代码中是否有死循环或递归调用，优化代码逻辑。

3、检查是否有大循环重复产生新对象实体，优化代码逻辑。

4、检查List、Map等集合对象是否有使用完后，未清除，始终存有对对象的引用而不能被GC回收。

5、调优JVM启动参数

6、强化并建立代码规范，定期执行迭代版本代码的Review

# 常见的JVM调优方法有哪些？可以具体到调整哪个参数，调成什么值？

主要针对年轻代、年老代、持久代；堆栈等大小进行设置；内存溢出分2类：

\1. 年老代溢出，表现为：java.lang.OutOfMemoryError:Javaheapspace

\2. 持久代溢出，表现为：java.lang.OutOfMemoryError:PermGenspace

**1****、新生代和老年代溢出：**java.lang.OutOfMemoryError:java heep space;当98%时间用于垃圾回收时,且可用的Heap size 不足2%的时候将抛出此异常信息；

**解决方法：****手动设置JVM Heap（堆）的大小**

**2****、持久代溢出：**java.lang.OutOfMemoryError: PermGen space

**解决方法：** **通过-XX:PermSize和-XX:MaxPermSize设置永久代大小即可。**

**3****、栈溢出：java.lang.StackOverFlowError:Thread stack space**

栈区远远小于堆区,栈区需要的内存大小1-2m左右；出现栈溢出，即说明单线程运行程序需要的内存太大；

**解决方法：****1****：修改程序。2：通过 -Xss: 来设置每个线程的Stack大小即可。**

 

**JVM****调优参数参考**

1、JVM堆大小设置，通过-Xms -Xmx限定其最小、最大值。为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值。

2、年轻代和年老代默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代。比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把它们设置为同样大小。

3、年轻代和年老代设置多大才算合理

（1）更大的年轻代必然导致更小的年老代，大的年轻代会延长普通GC的周期，但会增加每次GC的时间；小的年老代会导致更频繁的Full GC

（2）更小的年轻代必然导致更大年老代，小的年轻代会导致普通GC很频繁，但每次的GC时间会更短；大的年老代会减少Full GC的频率

如何选择应该依赖应用程序对象生命周期的分布情况： 如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。但很多应用都没有这样明显的特性。

在抉择时应该根据以下两点：

（1）本着Full GC尽量少的原则，让年老代尽量缓存常用对象，JVM默认比例1：2也是这个道理。

（2）通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响Full GC的前提下，根据实际情况加大年轻代，比如可以把比例控制在1：1。但应该给年老代至少预留1/3的增长空间。

4、在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC 。

5、线程堆栈的设置：每个线程默认会开启1M的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般256K就足用。理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。

 

**JVM****服务参数调优实战——大型网站服务器案例**

承受海量访问的动态Web应用

服务器配置：8 CPU, 8G MEM, JDK 1.6.X

参数方案：

-server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX:SurvivorRatio=6 -XX:MaxPermSize=256m -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC

调优说明：

- -Xmx 与 -Xms 相同以避免JVM反复重新申请内存。-Xmx 的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。
- -Xmn1256m 设置年轻代大小为1256MB。此值对系统性能影响较大，Sun官方推荐配置年轻代大小为整个堆的3/8。
- -Xss128k 设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。
- -XX:SurvivorRatio=6 设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个Survivor区与1个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。
- -XX:ParallelGCThreads=8 配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。
- -XX:MaxTenuringThreshold=0 设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率；如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。根据被海量访问的动态Web应用之特点，其内存要么被缓存起来以减少直接访问DB，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。
- -XX:+UseConcMarkSweepGC 设置年老代为并发收集。CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。

# JDK/Java从1.5~1.9各版本的新特性

**JDK Version 1.0****（**于1996-01-23发行**）**

开发代号为Oak（橡树）。

 

**JDK Version 1.1****（**于1997-02-19发行**）**

引入的新特性包括：

·    引入JDBC（Java Database Connectivity）；

·    支持内部类；

·    引入Java Bean；

·    引入RMI（Remote Method Invocation）；

·    引入反射（仅用于内省）。

 

**J2SE Version 1.2****（**于1998-12-08发行**）**

开发代号为Playground（操场）。引入的新特性包括：

·    引入集合（Collection）框架；

·    对字符串常量做内存映射；

·    引入JIT（Just In Time）编译器；

·    引入对打包的Java文件进行数字签名；

·    引入控制授权访问系统资源的策略工具；

·    引入JFC（Java Foundation Classes），包括Swing 1.0、拖放和Java 2D类库；

·    引入Java 插件；

·    在JDBC中引入可滚动结果集、BLOB、CLOB、批量更新和用户自定义类型；

·    在Applet中添加声音支持。

 

**J2SE Version 1.3****（**于2000-05-08发行**）**

开发代号为Kestrel（红隼）。引入的新特性包括：

·    引入Java Sound API；

·    jar文件索引；

·    对Java的各个方面都做了大量优化和增强。

 

**J2SE Version 1.4****（**于2004-02-06发行（首次在JCP下发行）**）**

开发代号为Merlin（隼）。引入的新特性包括:

·    XML处理；

·    Java打印服务；

·    引入Logging API；

·    引入Java Web Start；

·    引入JDBC 3.0 API；

·    引入断言；

·    引入Preferences API；

·    引入链式异常处理；

·    支持IPv6；

·    支持正则表达式；

·    引入Image I/O slot machine API。

 

**Java Version SE 5.0****（**于2004-09-30发行**）**

开发代号为Tiger（老虎）。引入的新特性包括:

·    引入泛型：了解泛型底层的实现，语法糖，伪泛型，类型擦除；

·    增强循环，可以使用迭代方式：for-each：for(int i=0; i<a.length; i++) {… …} 》 for(int i:a){......}；

·    自动装箱与自动拆箱：原始类型与对应的包装类不用显式转换；

·    类型安全的枚举；

·    可变参数：int sum(int ...nums)有任意个参数，把他看作数组；

·    静态引入：static import：Math.sqrt();  》  sqrt();；

·    元数据（注解）；

·    引入Instrumentation。

 

**Java Version SE 6****（**于2006-12-11发行**）**

开发代号为Mustang（野马）。引入的新特性包括：

·    支持脚本语言；

·    引入JDBC 4.0 API；

·    引入Java Compiler API；

·    插入式注解处理：插入式注解处理API(JSR 269)提供一套标准API来处理Annotations；

·    增强的for循环语句：for ( int number : getNumberList())

·    增加对Native PKI(Public Key Infrastructure)、Java GSS(Generic Security Service)、Kerberos和LDAP(Lightweight Directory Access Protocol)的支持；

·    继承Web Services；

·    做了很多优化，监视和管理：对内存泄漏增强了分析以及诊断能力。当遇到java.lang.OutOfMemory异常的时候，可以得到一个完整的堆栈信息，并且当堆已经满了的时候，会产生一个Log文件来记录这个致命错误。另外，JVM还添加了一个选项，允许你在堆满的时候运行脚本。

 

**Java Version SE 7****（**于2011-07-28发行**）**

开发代号是Dolphin（海豚）。引入的新特性包括：

·    模块化特性：Java7也是采用了模块的划分方式来提速，一些不是必须的模块并没有下载和安装，当虚拟机需要的时候，再下载相应的模块，同时对启动速度也有了很大的改善。

·    switch语句块中允许以字符串作为分支条件；

·    在多线程并发与控制方面：轻量级的分离与合并框架，一个支持并发访问的HashMap等等。

·    通过注解增强程序的静态检查。

·    多动态语言支持：Java7的虚拟机对多种动态程序语言增加了支持，比如：Rubby、Python等等；

·    引入Java NIO.2开发包：提供了一些新的API用于文件系统的访问、异步的输入输出操作、Socket通道的配置与绑定、多点数据包的传送等等；

·    执行效率的提高：对对象指针由64位压缩到与32位指针相匹配的技术使得内存和内存带块的消耗得到了很大的降低因而提高了执行效率。

·    提供了新的垃圾回收机制：（G1）来降低垃圾回收的负载和增强垃圾回收的效果。

·    数值类型可以用2进制字符串表示，并且可以在字符串表示中添加下划线；

·    在创建泛型对象时应用类型推断；

·    在一个语句块中捕获多种异常；

·    引入了一个新的异常处理结构来自动管理资源：try-with-resources；

·    null值的自动处理。

·    钻石型语法；

 

**Java SE 8****（**于2014-3-14发布**）**     相关视频：[极客学院Java8新特性视频教程](http://www.php.cn/course/613.html)

从Java 8开始开发代号已经弃用了，所以没有官方的开发代号了。Java SE 8中的新特性：

·    接口的Default方法：Java 8允许我们使用 default关键字给接口添加一个非抽象的方法实现，这个特征又叫做扩展方法。

·    方法与构造函数引用：Java 8 允许你使用 **::** 关键字来传递方法或者构造函数引用，通常用类名”**.**“来引用一个静态方法，我们也可以引用一个对象的方法，代码如下：

converter = something**::**startsWith;

String converted = converter.convert("Java");

System.out.println(converted);

·    Lambda表达式：在Java 8 中没必要使用传统的匿名对象的方式，提供了更简洁的语法：

Collections.sort(names, (String a, String b) -> {

return b.compareTo(a);

});

·    Lambda 作用域：在Lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。

访问局部变量：可以直接在lambda表达式中访问标记了final的外层局部变量。

访问对象字段与静态变量：和本地变量不同的是Lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的。

·    函数式接口：Lambda表达式是如何在Java的类型系统中表示的呢？每一个Lambda表达式都对应一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的Lambda表达式都会被匹配到这个抽象方法。因为默认方法不算抽象方法，所以你也可以给你的函数式接口添加默认方法。

·    访问接口的默认方法：

JDK 1.8 API包含了很多内建的函数式接口，在老Java中常用到的比如Comparator或者Runnable接口，这些接口都增加了@FunctionalInterface注解以便能用在lambda上。

Java 8 API同样还提供了很多全新的函数式接口来让工作更加方便，有一些接口是来自Google Guava库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到Lambda上使用的。

·    Pipelines和Streams

·    Date和Time API

·    Type注解

·    Nashhorn JavaScript引擎

·    并发计数器

·    Parallel操作

·    移除PermGen Error

·    TLS SNI

 

**JDK1.9** **新特性：（2017.9.21发布）**

\1. Java 平台级modularity System模块系统

​    Modularity提供了类似于OSGI框架的功能，模块之间存在相互的依赖关系，可以导出一个公共的API，并且隐藏实现的细节。引入模块系统，是为了解决公共类JAR文件（已经存在、或者重复项）相互依赖关系，真正地对代码进行封装，精简JDK减少内存的开销。

\2. Linking

当你使用具有显式依赖关系的模块和模块化的JDK时，这可以通过Java 9中的新的 jlink 工具实现，创建针对你的应用程序进行优化的最小运行时映像而不需要使用完全加载JDK安装版本。

\3. JShell : 交互式 Java REPL

​    许多语言已经具有交互式编程环境，Java 现在加入了这个俱乐部。您可以从控制台启动 jshell ，并直接启动输入和执行Java代码。jshell 的即时反馈使它成为探索API和尝试语言特性的好工具。

\4. Html5风格的Java帮助文档

​    Javadoc 现在支持在API文档中进行搜索。另外，每个Javadoc页面输出符合兼容HTML5标准，还包含有关JDK模块类或接口来源的信息。

\5. 不可变集合类的工厂方法

通常，您希望在代码中创建一个集合（例如，List 或 Set ），并直接用一些元素填充它。实例化集合，几个“add”调用，使得代码重复。Java 9，添加了几种集合工厂方法：

  Set<Integer> ints = Set.of(1,2,3);  List<String> strings =  List.of("first","second");  

除了更短和更好阅读之外，这些方法也可以避免您选择特定的集合实现。事实上，从工厂方法返回已放入数个元素的集合实现是高度优化的。因为它们是不可变的：在创建后，继续添加元素到这些集合会导致“UnsupportedOperationException”。

\6. 改进的 Stream API

通过这套Stream API可以在集合上建立用于转换的申明管道。在Stream接口中添加了4个新方法：dropWhile, takeWhile, ofNullable，还有个iterate方法的新重载方法，可以让你提供一个 Predicate (判断条件)来指定什么时候结束迭代：

```
Stream.of(1,2,3,2,1).dropWhile(i -> i < 3)``.collect(Collectors.toList()); // [3,2,1]``Stream.of(1,2,3,2,1).takeWhile(i -> i < 3)``.collect(Collectors.toList()); // [1,2]``IntStream.iterate(1, i -> i <100, i -> i + 1)``.forEach(System.out::println);
```

除了对 Stream 本身的扩展，Optional 和 Stream 之间的结合也得到了改进。现在可以通过 Optional 的新方法 ` stream ` 将一个 Optional 对象转换为一个(可能是空的) Stream 对象：

  Stream<Integer>  s = Optional.of(1).stream();  

在组合复杂的 Stream 管道时，将Optional转换为Stream非常有用。

\7. 引入Reactive Streams API：是一个发布订阅型框架，使我们能够非常简单地使用 Java 语言就能实现异步的、可拓展的和并行的应用。Java SE 9引进下面这些API来开发Reactive Streams：

- java.util.concurrent.Flow
- java.util.concurrent.Flow.Publisher
- java.util.concurrent.Flow.Subscriber
- java.util.concurrent.Flow.Processor

\8. 接口中的私有方法

Java 8 为我们带来了接口的默认方法。接口现在也可以包含行为，而不仅仅是方法签名。但是，如果在接口上有几个默认方法，都有一部分代码几乎相同，会发生什么情况？通常，您将重构这些方法，调用一个可复用的私有方法。但默认方法不能是私有的。将复用代码创建为一个默认方法不是一个解决方案，因为该辅助方法会成为公共API的一部分。使用Java 9，您可以向接口添加私有辅助方法来解决此问题：

  public  interface MyInterface {  void  normalInterfaceMethod();  default  void interfaceMethodWithDefault(){  init();  // 差异部分代码  … …  }  default  void anotherDefaultMethod(){  init();  //差异部分代码 … …  }     //  This method is not part of the public API exposed by MyInterface  private void init(){  System.out.println("Initializing");  }  }  

\9. HTTP 2 Client API

Oracle在“java.net.http”包下引入新的 HTTP 2 Client API处理HTTP调用，用于代替老旧的 `HttpURLConnection` API。它将同时支持 HTTP/1.1 和 HTTP/2 协议，也同时支持同步（Blocking Mode）和异步模式，支持 WebSocket API 使用中的异步模式。

  HttpClient  client = HttpClient.newHttpClient();  HttpRequest  req = HttpRequest.newBuilder(URI.create(  "http://www.google.com"  )).header("User-Agent",  "Java").GET().build();     HttpResponse<String>  resp = client.send(req, HttpResponse.BodyHandler.asString());  

除了这个简单的请求/响应模型之外，HttpClient 还提供了新的API来处理HTTP/2的特性，比如流和服务端推送。

\10. 多版本兼容JAR

解决Java旧版本切换新版本，向后兼容不能在库中运用新版Java库所提供的新特性。幸运的是，多版本兼容JAR功能能让你创建仅在特定版本的Java环境中运行库程序时选择使用的class版本。

 

# JDK 1.8 G1垃圾收集算法的改进？

G1（Garbage First）提供的一个工作在新生代基于“复制算法”和老年代基于“标记-整理”算法实现的收集器，在收集结束后可以避免内存碎片问题。

1. 并行与并发：充分利用多CPU来缩短Stop The World的停顿时间；
2. 分代收集：不需要其他收集配合就可以管理整个Java堆，采用不同的方式处理新建的对象、已经存活一段时间和经历过多次GC的对象获取更好的收集效果;
3. 空间整合：与CMS的”标记-清除”算法不同，G1在运行期间不会产生内存空间碎片，有利于应用的长时间运行，且分配大对象时，不会导致由于无法申请到足够大的连续内存而提前触发一次Full GC;
4. 停顿预测：G1中可以建立可预测的停顿时间模型，能让使用者明确指定在M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。

 

1、优化G1性能调优的参数项。开发人员仅仅需要声明以下参数即可：

-XX:+UseG1GC –Xmx16g -XX:MaxGCPauseMillis=200

​    其中-XX:+UseG1GC为开启G1垃圾收集器，-Xmx16g 设计堆内存的最大内存为16G，-XX:MaxGCPauseMillis=200设置GC的最大暂停时间为200ms。如果我们需要调优，在内存大小一定的情况下，我们只需要修改最大暂停时间即可。

 

2、G1将Java整个堆的内存布局划分为多个大小相等的独立区域Region，新生代和老年代不再是物理隔离，都是一部分Region（不需要连续）的集合。取消了新生代，老年代的物理空间划分。这样我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。

 

3、移除了永久代（Permanent Generation）使用本地化的内存存放类的元数据，这个空间叫做元空间（Metaspace）。

 

# Java8新特性如何使用，函数式编程为什么要添加进来

​    **方法引用**(Method Reference)，在Java8中用**“****::****”**双冒号操作符来直接访问类或者实例的已经存在的方法或者构造方法。方法引用提供了一种引用而不执行方法的方式，它需要由兼容的函数式接口构成的目标类型上下文。计算时，方法引用会创建函数式接口的一个实例。我们可以直接通过方法引用来**简写**lambda表达式中已经存在的方法。方法引用分类：

| **类型**     | **语法**           | **对应的****Lambda****表达式**       |
| ------------ | ------------------ | ------------------------------------ |
| 静态方法引用 | 类名::staticMethod | (args) -> 类名.staticMethod(args)    |
| 实例方法引用 | inst::instMethod   | (args) -> inst.instMethod(args)      |
| 对象方法引用 | 类名::instMethod   | (inst,args) -> 类名.instMethod(args) |
| 构建方法引用 | 类名::new          | (args) -> new 类名(args)             |

​    面向对象编程是对数据进行抽象，而[函数式编程](https://www.baidu.com/s?wd=函数式编程&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)是对（某一类共有的）行为进行抽象。Java8新引入函数式编程方式，函数式编程语法能够精简代码，大大的提高了编码效率。在面对大型数据集合时，为了能够更加高效的开发，编写的代码更加易于维护，更加容易运行在多核CPU上，Java在语言层面增加了Lambda表达式。Lambda表达式即匿名函数，它是一段没有函数名的函数体，可以作为参数直接传递给相关调用者。而函数式接口是Java支持函数式编程的基础。

​    **函数式接口**(Functional Interface)**：**是Java8中新定义了一种接口类型，它与其他接口的区别：

\1. 函数式接口中只能有一个抽象方法（但是可以有多个非抽象方法，还不包括与Object的方法重名的方法，在Java9允许接口中定义私有实现方法，封装给Java8允许接口默认方法内部调用）；

\2. 可以有从Object继承过来的抽象方法，因为所有类的最终父类都是Object；

\3. 接口中唯一抽象方法的命名并不重要，因为函数式接口就是对某一行为进行抽象，主要目的就是可以被隐式（匿名）转换为Lambda表达式。

​    一般通过@FunctionalInterface这个注解来表明某个接口是一个函数式接口,虽然这个注解的使用不是强制性的，但是使用它的好处是让此接口的目的更加明确，同时编译器也会对代码进行检查，来确保被该注解标注的接口的使用没有语法错误。

​    此前就有Comparator<T>和Runnable函数式接口，Java8在java.util.function包下又内置了四种核心函数式接口：

| **函数式接口** | **参数类型** | **返回类型** | **用途**                                                     |
| -------------- | ------------ | ------------ | ------------------------------------------------------------ |
| Consumer       | T            | 无           | 消费型接口，对类型T参数操作，无返回结果，包含方法 void accept(T t) |
| Supplier       | 无           | T            | 供给型接口，返回T类型参数，方法时 T get()                    |
| Function       | T            | R            | 函数型接口，对类型T参数操作，返回R类型参数，包含方法 R apply（T t） |
| Predicate      | T            | boolean      | 断言型接口，对类型T进行条件筛选操作，返回boolean，包含方法 boolean test（T t） |

 

# Java9比Java8改进了什么；

**String****底层存储结构更换：**Java8之前 String的底层结构类型都是 char[] ,但是Java9 就替换成 byte[] 这样来讲，更节省了空间和提高了性能。

**接口规范改进：**可私有接口的方法，默认和静态方法更好的共享接口的私有方法。若私有方法为静态该方法属于这个接口，不为静态则只能被该接口的实例调用。

**提供创建不可变集合的静态工厂方法**

List、Set、Map 接口中，提供新的静态工厂方法直接创建不可变的集合实例。

作用：创建不可变集合更方便，一行代码就搞定，节省了开销。

**私有接口方法**

在接口中也允许编写 private 修饰的私有方法了。

作用：增强了接口的功能，提高了可扩展性。

 

# 说一下Java多线程之内存可见性

​    （其实就是java的volatile实现原理，我补充了volatile的禁止指令重排序的原理。这里我扯到了synchronized的JVM底层实现原理，AQS工具包。）

​    首先要明确一点，每个线程都有属于自己的工作内存。除了线程自己拥有的工作内存外，还有公共的物理主内存。如果一个变量在多个线程的工作内存中都存在副本，那么这个变量就是这几个线程的**共享变量**。若其中一个线程对共享变量的修改，能够被其它线程看到，那么就能说明共享变量在线程之间是**可见的**。**为什么会出现共享变量可见性的问题？**这是因为JMM中线程操作内存的两个基本规定：①线程对共享变量的所有操作都必须在自己的工作内存中进行，不能从主内存中读写；②而且不同线程之间无法直接访问其它线程工作内存中的变量，线程间变量值的传递需要通过主内存来完成。

​    Java语言层面支持的可见性实现方式有两种：

n **1****、Synchronized**：不仅能通过互斥锁来实现同步（原子性），而且还能够实现可见性。**线程解锁前对共享变量的修改在下次加锁时对其他线程可见，****JMM****关于synchronized 的两条规定：**

u 线程解锁前，必须把共享变量的最新值刷新到主内存中；

u 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁需要的是同一把锁）

**线程执行互斥代码的过程：**

1、 获得互斥锁

2、 清空工作内存

3、 从主内存拷贝变量的最新副本到工作内存

4、 执行代码

5、 将更改后的共享变量的值刷新到主内存

6、 释放互斥锁

n **2****、volatile**：通过加入内存屏障和禁止指令重排序优化来实现可见性的，**但不保证原子性**。

u 对volatile变量执行**写**操作时，会在写操作后加入一条store屏障指令，这样就会把读写时的数据缓存加载到主内存中；

u 对volatile变量执行**读**操作时，会在读操作前加入一条load屏障指令，这样就会从主内存中加载变量；

​    所以说，volatile变量在每次被线程访问时，都强迫从主内存中重读该变量的值，而当该变量发生变化时，就会强迫线程将最新的值刷新到主内存，这样任何时刻，不同的线程总能看到该变量的最新值。

# 除了volatile还有什么方法保证数据一致性

volatile的使用场景：

l 状态标志(开关模式) 

l 双重检查锁定

l 需要利用顺序性（防止指令重排序）。

除了volatile在多线程情况下能保证数据一致性，还有以下3种方法：

l 使用synchronized关键字

l 使用Lock锁

l 使用Atomic原子类

# 深入剖析volatile关键字

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。

2）禁止进行指令重排序。volatile关键字禁止指令重排序有两层意思：

　　（A）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；

　　（B）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。

volatile 关键字的作用是禁止指令的重排序，强制从公共堆栈（主存）中取得变量的值，而不是从线程私有的数据栈（工作内存）中取变量的值。

先看一段代码，假如线程1先执行，线程2后执行：

// 线程1

boolean stop = false;

while(!stop){

  doSomething();

}

 

// 线程2

stop = true;

 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。

下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。

那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。

但是用volatile修饰之后就变得不一样了：

第一：使用volatile关键字会强制将修改的值立即写入主存；

第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；

第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。

那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。那么线程1读取到的就是最新的正确的值。

从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？

​    不能。读**->**存工作内存**->**操作**->**写工作内存**->**写主存。只能synchronized和Lock锁来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。

**volatile****的原理和实现机制**

前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。

下面这段话摘自《深入理解Java虚拟机》：

“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”

lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；

2）它会强制将对缓存的修改操作立即写入主存；

3）如果是写操作，它会导致其他CPU中对应的缓存行无效。

使用volatile必须具备以下2个条件：

　　1）对变量的写操作不依赖于当前值

　　2）该变量没有包含在具有其他变量的不变式中

列举几个Java中使用volatile的几个场景：1.状态标记量，**2.double check****。**

# 什么是内存屏障？

l **内存屏障**（Memory Barrier）是一种CPU指令。

​    内存屏障也称为内存栅栏或栅栏指令，是一种屏障指令，它使CPU或编译器对屏障指令之前和之后发出的内存操作执行一个排序约束。目前的高级处理器CPU，为了提高内部逻辑元件的利用率以提高运行速度，通常会采用多指令发射、乱序执行等各种措施。现在普遍使用的一些超标量处理器通常能够在 一个指令周期内并发执行多条指令。**可以解决数据一致性问题：**由于编译器的优化和缓存的使用，导致对内存的写入操作不能及时的反应出来，也就是说当完成对内存的写入操作之后，读取出来的可能是旧的内容。为了防止编译器和硬件的不正确优化，使得对存储器的访问顺序（其实就是变量）和书写程序时的访问顺序不一致而提出的一种解决办法。

​    **内存屏障的分类：**

1、 编译器引起的内存屏障

2、 缓存引起的内存屏障

3、 乱序执行引起的内存屏障

**按功能分类有以下四种：**

   **1****、write（或store）内存屏障**

   保证所有该屏障之前的store操作，看起来一定在所有该屏障之后的store操作之前执行。

   **2****、read（或load）内存屏障**

   保证所有该屏障之前的load操作，看起来一定在所有该屏障之后的load操作之前执行。仅保证load指令上的偏序关系，不要求对store指令有什么影响。

   **3****、数据依赖屏障**

   是read屏障的一种较弱形式。在执行两个load指令，第二个依赖于第一个的执行结果（例如：第一个load执行获取某个地址，第二个load指令取该地址的值）时，可能就需要一个数据依赖屏障，来确保第二个load指令在获取目标地址值的时候，第一个load指令已经更新过该地址。仅保证相互依赖的load指令上的偏序关系，不要求对store指令，无关联的load指令以及重叠的load指令有什么影响。

   **4****、通用内存屏障**

   确保所有该屏障之前的load和store操作，看起来一定在所有屏障之后的load和store操作之前执行。它能保证load和store指令上的偏序关系。

   **5****、一对隐式的屏障变种（LOCK和UNLOCK操作）：**

   LOCK操作可以看作是一个单向渗透的屏障。它保证所有在LOCK之后的内存操作看起来一定在LOCK操作后才发生。

   UNLOCK操作也是一个单向渗透屏障。它保证所有UNLOCK操作之前的内存操作看起来一定在UNLOCK操作之前发生。

 

​    实际运用场景：volatile便是基于内存屏障实现的。可以了解一下Dekker算法中的内存屏障。该算法利用volatile变量协调两个线程之间的共享资源访问。

# 什么是内存对齐？

l **内存对齐：**

​    内存地址对齐，是一种在计算机内存中排列数据（表现为变量的地址）、访问数据（表现为CPU读取数据）的一种方式，包含了两种相互独立又相互关联的部分：基本数据对齐和结构体数据对齐 。

​    为什么需要内存对齐？对齐有什么好处？是我们程序员来手动做内存对齐呢？还是编译器在进行自动优化的时候完成这项工作？

​    在现代计算机体系中，每次读写内存中数据，都是按字（word，4个字节，对于X86架构，系统是32位，数据总线和地址总线的宽度都是32位，所以最大的寻址空间为2的32次方 = 4GB，按A[31,30…2,1,0]这样排列，但是请注意为了CPU每次读写 4个字节寻址，A[0]和A[1]两位是不参与寻址计算的。）为一个块（chunks）来操作（而对于X64则是8个字节为一个快）。注意，这里说的 CPU每次读取的规则，并不是变量在内存中地址对齐规则。既然是这样的，如果变量在内存中存储的时候也按照这样的对齐规则，就可以加快CPU读写内存的速度，当然也就提高了整个程序的性能，并且性能提升是客观，虽然当今的CPU的处理数据速度(是指逻辑运算等,不包括取址)远比内存访问的速度快，程序的执 行速度的瓶颈往往不是CPU的处理速度不够，而是内存访问的延迟，虽然当今CPU中加入了高速缓存用来掩盖内存访问的延迟，但是如果高密集的内存访问，这种延迟是无可避免的，内存地址对齐会给程序带来了很大的性能提升。

  内存地址对齐是计算机语言自动进行的，也即是编译器所做的工作。但这不意味着我们程序员不需要做任何事情，因为如果我们能够遵循某些规则，可以让编译器做得更好，毕竟编译器不是万能的。

**1****、基本数据对齐**

​    在X86，32位系统下基于Microsoft、Borland和GNU的编译器，有如下数据对齐规则：

​    a、一个char（占用1-byte）变量以1-byte对齐。

​    b、一个short（占用2-byte）变量以2-byte对齐。

​    c、一个int（占用4-byte）变量以4-byte对齐。

​    d、一个long（占用4-byte）变量以4-byte对齐。

​    e、一个float（占用4-byte）变量以4-byte对齐。

​    f、一个double（占用8-byte）变量以8-byte对齐。

​    g、一个long double（占用12-byte）变量以4-byte对齐。

​    h、任何pointer（占用4-byte）变量以4-byte对齐。

​    **而在64位系统下，与上面规则对比有如下不同：**

​    a、一个long（占用8-byte）变量以8-byte对齐。

​    b、一个double（占用8-byte）变量以8-byte对齐。

​    c、一个long double（占用16-byte）变量以16-byte对齐。

​    d、任何pointer（占用8-byte）变量以8-byte对齐。

  **2****、结构体数据对齐**

  结构体数据对齐，是指结构体内的各个数据对齐。在结构体中的第一个成员的首地址等于整个结构体的变量的首地址，而后的成员的地址随着它声明的顺序和实际占用的字节数递增。为了总的结构体大小对齐，会在结构体中插入一些没有实际意思的字符来**填充（padding）**结构体。

  在结构体中，成员数据对齐满足以下规则：

  a、结构体中的第一个成员的首地址也即是结构体变量的首地址。

  b、结构体中的每一个成员的首地址相对于结构体的首地址的偏移量（offset）是该成员数据类型大小的整数倍。

  c、结构体的总大小是对齐模数（对齐模数等于#pragma pack(n)所指定的n与结构体中最大数据类型的成员大小的最小值）的整数倍。

# Synchronized锁粒度（使用方法和作用域）

1、修饰**方法**：在范围操作符之后，返回类型声明之前使用。每次只能有一个线程进入该方法，

​    此时线程获得的是**方法锁**。

​    public synchronized void method(){ }

2、修饰**代码块**：每次只能有一个线程进入该代码块，

​       此时线程获得的是（this）**对象锁**。

​    public void method() {synchronized(this) {// dosomething }}

3、修饰**对象**：如果当前线程进入，那么其他线程在该类所有对象上的任何操作都不能进行，

​       此时当前线程获得的是**对象锁**。

​    public void method() {synchronized(objInstance) {// dosomething }}

4、修饰**类**：如果当前线程进入，那么其他线程在该类中所有操作不能进行，包括静态变量和静态方法，

​       此时当前线程获得的是Class**类对象锁**。

   public void method1() {synchronized(MyClass.class){ }}

   public static synchronized void method2(){ }

# Java的synchronized加在静态方法和动态方法的区别？

synchronized修饰静态方法，是对该类对象（XXX.class)加锁，俗称“类锁”。对于静态同步方法，锁是针对这个类的，锁对象是该类的Class对象。静态和非静态方法的锁互不干预。例如：

public static synchronized void method1( ) {  }

public static void method1( ) { synchronized(Xxx.class) {  } }

synchronized修饰非静态方法，是对调用该方法的对象加锁，俗称“对象锁”。静态同步方法和非静态同步方法将永远不会彼此阻塞，因为静态方法锁定在Class对象上，非静态方法锁定在该类的对象上。

public synchronized void method1() {  }

public void method1() { synchronized(this) {  } }

一个线程获得锁，当在一个同步方法中访问另外对象上的同步方法时，会获取这两个对象锁。

# 静态方法跟非静态方法的锁区别

**类锁（又称全局锁，static synchronized）**

​    synchronized修饰静态方法，该锁是对该类Class对象加锁，无论实例出多少个对象，类对象只有一个，那么线程依然共享该锁。和用单例模式声明一个对象来调用非静态方法的情况是一样的，因为永远就只有这一个对象。所以访问同步方法之间一定是互斥的。

​    static synchronized是限制多线程中该类的所有实例同时访问该类所对应的代码块。

**注意：**

1、static synchronized并不是关键字，只是代表给静态方法加锁。

2、锁住的只是static synchronized块，synchronized块锁不住，而不加锁的方法更加锁不住

**对象锁（实例锁，synchronized）**

​    synchronized修饰非静态方法，该锁是对调用该方法的当前实例对象加锁，每个对象有且仅有唯一的1个锁。

​    synchronized是对类的当前实例（当前对象）进行加锁，防止其他线程同时访问该类的该实例的所有synchronized块。

**注意：**

1、指的是“类的当前实例”， 类的两个不同实例就没有这种约束了。

2、锁住的只是synchronized块，static synchronized块锁不住，而不加锁的方法更加锁不住。

**总结:**

·    静态方法的锁属于类, 一个类中所有加锁的静态方法共用该锁

·    非静态方法的锁属于对象, 一个对象中所有加锁的非静态方法共用, 和静态方法的锁不同而互不相干

·    加锁的方法的执行不会影响同一个类/对象中未加锁的方法的执行(因为其他方法没有锁呀)

# 何时需要同步

在多个线程同时并发访问同一个共享资源（全局变量）时，应该使用同步机制（独占方式访问）以保证此资源的数据安全。互斥确保不会同时修改它，即线程安全。要跨线程维护正确的可见性，只要在几个线程之间共享非 final 变量，就必须使用synchronized（或 volatile）以确保一个线程可以看见另一个线程做的更改。为了在线程之间进行可靠的通信，也为了互斥访问，同步是必须的。这归因于java语言规范的内存模型，它规定了：一个线程所做的变化何时以及如何变成对其它线程可见。因为多线程将异步行为引进程序，所以在需要同步时，必须有一种方法强制进行。

Java同步机制有4种实现方式：

**①ThreadLocal:** 线程级别作用域副本，既保证全局变量线程安全，又实现存在当前线程中多次访问全局变量的便利，如JDBC Connection对象，需在线程级别下多个方法多次访问数据库连接。

**②synchronized( )****：**监视器字节码指令monitorenter、monitorexit，重量级锁、悲观锁、内置锁

**③wait()****与notify()**：对象锁

**④volatile****：**内存屏障（Memory Barriers）不允许线程内部缓存（即直接修改内存）和重排序。

**监控器（Monitor）**是一个控制机制，可以认为是一个很小的、只能容纳一个线程的盒子，一旦一个线程进入监控器，其它的线程必须等待，直到那个线程退出监控为止。通过这种方式，一个监控器可以保证共享资源在同一时刻只可被一个线程使用。这种方式称之为同步。

**锁（Lock）**提供了两种主要特性：互斥（mutual exclusion）和可见性（visibility）。**互斥**即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样，一次就只有一个线程能够使用该共享数据。**可见性**要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 —— 如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，造成数据不一致导致计算结果错误。

# 进程与线程的区别

​    **进程：**是并发执行的程序在执行过程中分配和管理资源的基本单位，是一个动态概念，竞争计算机系统资源的基本单位。

​    **线程：**是进程的一个执行单元，是进程内科调度实体，也是处理器调度的基本单位。比进程更小的独立运行的基本单位。线程也被称为轻量级进程。

​    进程是（系统）资源分配最小单位，线程是程序执行的最小单位。关系是进程–>线程–>程序。所以线程是程序执行流的最小单位，而进程是系统进行资源分配和调度的一个独立单位。

**进程与线程的区别：**

·    **地址空间**：同一进程的线程共享本进程的地址空间，而进程之间则是独立的地址空间。

·    **资源拥有**：同一进程内的线程共享本进程的资源如内存、I/O、cpu等，但是进程之间的资源是独立的。线程占用的资源要⽐进程少很多。

·    **执行过程**：每个独立的进程都有一个程序运行的入口、顺序执行序列和程序入口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。

 

# 线程状态，以及相互转化的过程

![img](http://image.itstabber.com/2020-09-10/clip_image017.png)

\1.   **新建(new)**：新创建了一个线程对象，并没有调用start()方法之前。

\2.   **可运行(runnable)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权。

\3.   **运行(running)**：可运行状态(runnable)的线程获得了CPU时间片（timeslice），执行程序代码。

\4.   **阻塞(block)**：阻塞状态是指线程因为某种原因放弃了CPU使用权，也即让出了CPU timeslice，暂时停止运行（线程仍旧是活的）。直到线程进入可运行(runnable)状态，才有机会再次获得CPU timeslice转到运行(running)状态。阻塞的情况分三种：

**(****一). 等待阻塞**：运行(running)的线程执行锁对象的o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。

**(****二). 同步阻塞**：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(**lock** pool)中。

**(****三). 其他阻塞**: 运行(running)的线程执行睡眠Thread.sleep(**long** ms)或合并t.**join**()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时**join**()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

\5.   **死亡(dead)**：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

# 有哪些方式方法可以让线程离开运行状态？

1、调用Thread.sleep()：使当前线程睡眠至少多少毫秒（尽管它可能在指定的时间之前被中断）。

2、调用Thread.yield()：不能保障太多事情，尽管通常它会让当前运行线程回到可运行性状态，使得有相同优先级的线程有机会执行。

3、调用join()方法：保证当前线程停止执行，直到该线程所加入的线程完成为止。然而，如果它加入的线程没有存活，则当前线程不需要停止。

除了以上三种方式外，还有下面几种特殊情况可能使线程离开运行状态：

1、线程的run()方法完成。

2、在持有锁的对象上调用wait()方法（不是在线程上调用）。

3、线程未能获得对象锁（阻塞状态），它正试图运行该对象的同步方法或同步代码。

4、线程调度程序可以决定将当前运行状态移动到可运行状态，以便让另一个线程获得运行机会，而不需要任何理由。

# 锁类型

可重入锁：在执行对象中所有同步方法不用再次获得锁

可中断锁：在等待获取锁过程中可中断

公平锁： 按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利

读写锁：对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写

# 两种锁机制的底层的实现策略

**互斥同步**最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。synchronized采用的便是这种并发策略。

  随着指令集的发展，我们有了另一种选择：基于冲突检测的**乐观并发策略**，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock采用的便是这种并发策略。

  在**乐观并发策略**中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是CAS操作（Compare and Swap）。JDK1.5之后，Java程序才可以使用CAS操作。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState，这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。

  Java 5中引入了注入AutomicInteger、AutomicLong、AutomicReference等特殊的原子性变量类，它们提供的如：compareAndSet（）、incrementAndSet（）和getAndIncrement（）等方法都使用了CAS操作。因此，它们都是由硬件指令来保证的原子方法。

# Lock接口中主要有哪些方法

lock()：获取锁，如果锁被暂用则一直等待

unlock():释放锁

tryLock(): 注意返回类型是boolean，如果获取锁的时候锁被占用就返回false，否则返回true

tryLock(long time, TimeUnit unit)：比起tryLock()就是给了一个时间期限，保证等待参数时间

lockInterruptibly()：用该锁的获得方式，如果线程在获取锁的阶段进入了等待，那么可以中断此线程，先去做别的事

# Java锁Lock——ReentrantLock实现原理及源码分析

​    **Lock****完全用Java写成，在java这个层面是无关JVM实现的。在java.util.concurrent.locks包中有很多Lock的实现类，常用的有ReentrantLock、ReadWriteLock（实现类ReentrantReadWriteLock），其实现都依赖java.util.concurrent.AbstractQueuedSynchronizer类，实现思路都大同小异，因此我们以ReentrantLock作为讲解切入点。**

**ReentrantLock****是Java并发包中提供的一个可重入的互斥锁。ReentrantLock和synchronized在基本用法，行为语义上都是类似的，同样都具有可重入性。只不过相比原生的Synchronized，ReentrantLock增加了一些高级的扩展功能，比如它可以实现公平锁，同时也可以绑定多个Conditon。**

**ReentrantLock****是基于AQS的，AQS是基于CAS+CHL实现，它是Java并发包中众多同步组件的构建基础，它通过一个int类型的状态变量state和一个FIFO队列（CLH队列）来完成共享资源的获取，线程的排队等待等。AQS是个底层框架，采用模板方法模式，它定义了通用的较为复杂的逻辑骨架，比如线程的排队，阻塞，唤醒等，将这些复杂但实质通用的部分抽取出来，这些都是需要构建同步组件的使用者无需关心的，使用者仅需重写一些简单的指定的方法即可（其实就是对于共享变量state的一些简单的获取释放的操作）。**

l **ReentrantLock****的调用过程**

经过观察ReentrantLock把所有Lock接口的操作都委派到一个**Sync****类**上，该类继承了**AbstractQueuedSynchronizer**：

```
static abstract class Sync extends AbstractQueuedSynchronizer
```

Sync又有两个子类：

```
final static class NonfairSync extends Sync
final static class FairSync extends Sync
```

显然是为了支持公平锁和非公平锁而定义，默认情况下为非公平锁。

先理一下Reentrant.lock()方法的调用过程（默认非公平锁）：

![img](http://image.itstabber.com/2020-09-10/clip_image018.png)

这些讨厌的Template模式导致很难直观的看到整个调用过程，其实通过上面调用过程及AbstractQueuedSynchronizer的注释可以发现，AbstractQueuedSynchronizer中抽象了绝大多数Lock的功能，而只把tryAcquire方法延迟到子类中实现。tryAcquire方法的语义在于用具体子类判断请求线程是否可以获得锁，无论成功与否AbstractQueuedSynchronizer都将处理后面的流程。

l **CLH****队列**

AQS内部维护着一个FIFO的队列，即CLH队列。AQS的同步机制就是依靠CLH队列实现的。CLH队列是FIFO的双端双向队列，实现公平锁。线程通过AQS获取锁失败，就会将线程封装成一个Node节点，插入队列尾。当有线程释放锁时，后尝试把队头的next节点占用锁。**CLH****队列结构如下：**

![img](http://image.itstabber.com/2020-09-10/clip_image019.png)

CLH队列由Node对象组成，Node是AQS中的内部类。

l **锁实现（加锁）**

简单说来，AbstractQueuedSynchronizer会把所有的请求线程构成一个CLH队列，当一个线程执行完毕（lock.unlock()）时会激活自己的后继节点，但正在执行的线程并不在队列中，而那些等待执行的线程全部处于阻塞状态，经过调查线程的显式阻塞是通过调用LockSupport.park()完成，而LockSupport.park()则调用sun.misc.Unsafe.park()本地方法，再进一步，HotSpot在Linux中中通过调用pthread_mutex_lock函数把线程交给系统内核进行阻塞。该队列如图：

p(predecessor) 前任，前辈，前身；mutex：n，互斥、互斥锁、互斥体、互斥元、互斥量

![img](http://image.itstabber.com/2020-09-10/clip_image020.png)

与synchronized相同的是，这也是一个虚拟队列，不存在队列实例，仅存在节点之间的前后关系。令人疑惑的是为什么采用CLH队列呢？原生的CLH队列是用于自旋锁，但Doug Lea把其改造为阻塞锁。
 **当有线程竞争锁时，该线程会首先尝试获得锁，这对于那些已经在队列中排队的线程来说显得不公平，这也是非公平锁的由来**，与synchronized实现类似，这样会极大提高吞吐量。

如果已经存在Running线程，则新的竞争线程会被追加到队尾，具体是采用基于CAS（Compare and Swap）的Lock-Free算法，因为线程并发对Tail调用CAS可能会导致其他线程CAS失败，解决办法是**循环CAS直至成功**。AbstractQueuedSynchronizer的实现非常精巧，令人叹为观止，不入细节难以完全领会其精髓，下面详细说明实现过程：

l **1 Sync.nonfairTryAcquire**

nonfairTryAcquire方法将是lock方法间接调用的第一个方法，每次请求锁时都会首先调用该方法。

l **2 AbstractQueuedSynchronizer.addWaiter**

addWaiter方法负责把**当前无法获得锁的线程包装为一个Node添加到队尾**

l **3 AbstractQueuedSynchronizer.acquireQueued**

acquireQueued的主要作用是把已经追加到队列的线程节点（addWaiter方法返回值）进行阻塞，但阻塞前又通过tryAccquire重试是否能获得锁，如果重试成功能则无需阻塞，直接返回。

LockSupport.park最终把线程交给系统（Linux）内核进行阻塞。当然也不是马上把请求不到锁的线程进行阻塞，还要检查该线程的状态。

l **解锁**

​    解锁代码相对简单，主要体现在AbstractQueuedSynchronizer.release和Sync.tryRelease方法。tryRelease与tryAcquire语义相同，把如何释放的逻辑延迟到子类中。tryRelease语义很明确：如果线程多次锁定，则进行多次释放，直至status==0则真正释放锁，所谓释放锁即设置status为0，因为无竞争所以没有使用CAS。release的语义在于：如果可以释放锁，则唤醒队列第一个线程（Head），最后通知系统内核继续该线程，在Linux下是通过pthread_mutex_unlock完成。

p(predecessor) 前任，前辈，前身；mutex：n，互斥、互斥锁、互斥体、互斥元、互斥量

# 说一下悲观锁和乐观锁，synchronized（内置锁、悲观锁）和lock（CAS乐观锁）的区别

​    简答介绍悲观锁和乐观锁的含义，有对具体锁的实现举了例子，比如乐观锁CAS实现，悲观锁synchronized又引入了乐观锁CAS的**ABA问题**（采用版本号，每次更新把版本号加一，那么A－B－A检查变化就会变成1A-2B－3A）。

​    AbstractQueuedSynchronizer通过构造一个基于阻塞的CLH队列容纳所有的阻塞线程，而对该队列的操作均通过Lock-Free（CAS）操作，但对已经获得锁的线程而言，ReentrantLock实现了偏向锁的功能。synchronized的底层也是一个基于CAS操作的等待队列，但JVM实现的更精细，把等待队列分为ContentionList和EntryList，目的是为了降低线程的出列速度；当然也实现了偏向锁，从数据结构来说二者设计没有本质区别。但synchronized还实现了自旋锁，并针对不同的系统和硬件体系进行了优化，而Lock则完全依靠系统阻塞挂起等待线程。

​    当然Lock比synchronized更适合在应用层扩展，可以继承AbstractQueuedSynchronizer定义各种实现，比如实现读写锁（ReadWriteLock），公平或不公平锁；同时，Lock对应的Condition也比wait/notify要方便的多、灵活的多。

# Synchronized和ReentrantLock关系与区别汇总

# synchronized底层实现原理和过程？并与reentrantlock区别？

（1）synchronized是JVM层面的实现的，JVM会确保释放锁，而且synchronized使用简单；而Lock是个普通类，需要在代码中finally中显式释放锁lock.unlock()，但是使用灵活。

（2）synchronized采用的是悲观锁机制，线程获得独占锁，而其他线程只能阻塞来等待释放锁。当竞争激烈时，CPU频繁的上下文切换会降低效率（PS：JDK1.6~1.7对Synchronized做了优化实现）。而Lock是乐观锁机制，每次假设不存在竞争而不上锁，若存在竞争就重试。当竞争激烈时JVM可以花更少的时间来调度线程，把更多时间用在执行线程上，因此性能最佳。

（3）ReentrantLock可以实现定时锁、轮询锁，可以选择放弃等待或者轮询请求。有效防止了死锁。

lock();//用来获取锁，如果锁已被其他线程获取，则进行等待 

tryLock(); //尝试获取锁，若成功返回true，失败（即锁已被其他线程获取）则返回false 

tryLock(long timeout, TimeUnit unit); //在拿不到锁时会等待一定的时间 

//两个线程同时通过lock.lockInterruptibly()想获取某个锁时 

//若线程A获取到了锁，而线程B在等待 

//线程B调用threadB.interrupt()方法能够中断线程B的等待过程 

lockInterruptibly(); 

（4）synchronized是非公平锁。而ReentrantLock可以通过构造函数传入true实现公平锁，即按照申请锁顺序获得锁。

（5）ReentrantLock类有一个重要的函数newCondition()，用于获取Lock上的一个条件，Condition可用于线程间通信。

# 详解synchronized与Lock的区别与使用

[详解synchronized与Lock的区别与使用](https://blog.csdn.net/u012403290/article/details/64910926)

[java中synchronized和lock底层原理](https://blog.csdn.net/SumResort_LChaowei/article/details/72857921)

l **两者的区别：**

![img](http://image.itstabber.com/2020-09-10/clip_image021.png)

​    在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞的是实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。多线程环境下，synchronized的吞吐量下降的非常严重，而ReentrankLock则能基本保持在同一个比较稳定的水平上。

  到了JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。官方也表示，他们也更支持synchronize，在未来的版本中还有优化余地，所以还是提倡在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步。

l **synchronized****的原理**

​    其实synchronized映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。(内存屏障|内存栅栏)在java语言中存在两种内建的synchronized语法：1、synchronized语句；2、synchronized方法。对于synchronized语句当Java源代码被javac编译成bytecode的时候，会在同步块的入口位置和退出位置分别插入MonitorEnter和MonitorExit字节码指令。而synchronized方法则会被翻译成普通的方法调用和返回指令如:InvokeVirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。

l **synchronized****的具体 ：** 

\1. 线程状态及状态转换

  当多个线程同时请求某个对象监视器时，对象监视器会设置几种状态用来区分请求的线程：

Contention List：所有请求锁的线程将被首先放置到该竞争队列

Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List

Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set

OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck

Owner：获得锁的线程称为Owner

!Owner：释放锁的线程

下图反映了个状态转换关系：

![img](http://image.itstabber.com/2020-09-10/clip_image022.png)

　　新请求锁的线程将首先被加入到ConetentionList中，当某个拥有锁的线程（Owner状态）调用unlock之后，如果发现EntryList为空则从ContentionList中移动线程到EntryList，下面说明下ContentionList和EntryList的实现方式：

**1.1 Contention List****虚拟队列**

　　Contention List并不是一个真正的Queue，而只是一个虚拟队列，原因在于ContentionList是由Node及其next指针逻辑构成，并不存在一个Queue的数据结构。ContentionList是一个后进先出（LIFO）的队列，每次新加入Node时都会在队头进行，通过CAS改变第一个节点的的指针为新增节点，同时设置新增节点的next指向后续节点，而取得操作则发生在队尾。显然，该结构其实是个Lock-Free的队列。

因为只有Owner线程才能从队尾取元素，也即线程出列操作无争用，当然也就避免了CAS的ABA问题。

![img](http://image.itstabber.com/2020-09-10/clip_image023.png)

**1.2 EntryList**

EntryList与ContentionList逻辑上同属等待队列，ContentionList会被线程并发访问，为了降低对ContentionList队尾的争用，而建立EntryList。Owner线程在unlock时会从ContentionList中迁移线程到EntryList，并会指定EntryList中的某个线程（一般为Head）为Ready（OnDeck）线程。Owner线程并不是把锁传递给OnDeck线程，只是把竞争锁的权利交给OnDeck，OnDeck线程需要重新竞争锁。这样做虽然牺牲了一定的公平性，但极大的提高了整体吞吐量，在Hotspot中把OnDeck的选择行为称之为“竞争切换”。

OnDeck线程获得锁后即变为owner线程，无法获得锁则会依然留在EntryList中，考虑到公平性，在EntryList中的位置不发生变化（依然在队头）。如果Owner线程被wait方法阻塞，则转移到WaitSet队列；如果在某个时刻被notify/notifyAll唤醒，则再次转移到EntryList。

# 1 . 什么是可重入锁

​    锁的概念就不用多解释了,当某个线程A已经持有了一个锁,当线程B尝试进入被这个锁保护的代码段的时候.就会被阻塞.而锁的操作粒度是”线程”,而不是调用(至于为什么要这样,下面解释).同一个线程再次进入同步代码的时候.可以使用自己已经获取到的锁,这就是可重入锁。java里面内置锁(synchronize)和Lock(ReentrantLock)都是可重入的。

# 2 . 为什么要可重入

​    如果线程A继续再次获得这个锁呢？比如一个方法是synchronized，递归调用自己，那么第一次已经获得了锁，第二次调用的时候还能进入吗？直观上当然需要能进入，这就要求必须是可重入的。可重入锁又叫做递归锁。再举个例子：

```java
public class Widget {

​    public synchronized void doSomething() {

​      ...

​    }

}

public class LoggingWidget extends Widget {

​    public synchronized void doSomething() {

​      System.out.println(toString() + ": calling doSomething");

​      super.doSomething();// 若内置锁是不可重入的，则发生死锁

​    }

}
```



这个例子是java并发编程实战中的例子，synchronized是父类Widget的内置锁，当执行子类的方法时，先获取了一次Widget的锁，然后在执行super时，就要获取一次，如果不可重入，那么就跪了。

# 3 . 如何实现可重入锁

​    为每个锁关联一个**获取计数器和一个所有者线程，**当计数值为0的时候，这个所就没有被任何线程持有，当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1，如果同一个线程再次获取这个锁，计数值将递增，退出一次同步代码块，计算值递减，当计数值为0时，这个锁就被释放。ReentrantLock源码里面有实现 PS：可重入是指对同一线程而言。

# 4 . 有不可重入锁吗

​    Linux下的pthread_mutex_t锁是默认是非递归的，可以通过设置PTHREAD_MUTEX_RECURSIVE属性，将pthread_mutex_t锁设置为递归锁。如果要自己实现不可重入锁，同可重入锁，这个计数器只能为1或者0，再次进入的时候，发现已经是1了，就进行阻塞，JDK里面没有默认的实现类。

​    recursive：递归的、循环的

# 5 . demo代码展示

5.1 内置锁的可重入

```java
public class Reentrant {
    public void method1() {
        synchronized (Reentrant.class) {
            System.out.println("method1 run");
            method2();
        }
    }

    public void method2() {
        synchronized (Reentrant.class) {
            System.out.println("method2 run in method1");
        }
    }

    public static void main(String[] args) {
        new Reentrant().method1();
    }
}

```



 Lock对象可重入

```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class Reentrant2 {
    private Lock lock = new ReentrantLock();

    public void method1() {
        lock.lock();
        try {
            System.out.println("method1 run");
            method2();
        } finally {
            lock.unlock();
        }
    }

    public void method2() {
        lock.lock();
        try {
            System.out.println("method2 run in method1");
        } finally {
            lock.unlock();
        }
    }

    public static void main(String[] args) {
        new Reentrant2().method1();
    }
}

```



在同一线程里，method1调用持同样锁的method2，不会等锁。这就是锁的”重入”。

不同线程里锁不可重入。因为不可重入，所以不同线程可以看到T2一定会等到T1释放锁之后。

#  synchronized优化

​    简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）如果每次都调用Mutex Lock那么将严重的影响程序的性能。不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。

在jdk1.6~jdk1.7，对synchronized做了优化，具体优化如下：

**1****、线程自旋和适应性自旋**

​    java线程其实是映射在内核之上的，线程的挂起和恢复会极大的影响开销。并且jdk官方人员发现，很多线程在等待锁的时候，在很短的一段时间就获得了锁，所以它们在线程等待的时候，并不需要把线程挂起，而是让他无目的的循环，一般设置10次。这样就避免了线程切换的开销，极大的提升了性能。
 而适应性自旋，是赋予了自旋一种学习能力，它并不固定自旋10次一下。他可以根据它前面线程的自旋情况，从而调整它的自旋，甚至是不经过自旋而直接挂起。

**2****、锁消除（Lock Elimination）**

​    什么叫锁消除呢？就是把不必要的同步在编译阶段进行移除。通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配（同时还可以减少Heap上的垃圾收集开销）。

​    我自己写的代码我会不知道这里要不要加锁？我加了锁就是表示这边会有同步呀？并不是这样，这里所说的锁消除并不一定指代是你写的代码的锁消除，我打一个比方：

​    在jdk1.5以前，我们的String字符串拼接操作其实底层是StringBuffer来实现的（这个大家可以用我前面介绍的方法，写一个简单的demo，然后查看class文件中的字节码指令就清楚了），而在jdk1.5之后，那么是用StringBuilder来拼接的。我们考虑前面的情况，比如如下代码：

```java
String str1="qwe";

String str2="asd";

String str3=str1+str2;
```



底层实现会变成这样：

```java
StringBuffer sb = new StringBuffer();

sb.append("qwe");

sb.append("asd");
```



我们知道，StringBuffer是一个线程安全的类，也就是说两个append方法都会同步，通过指针逃逸分析（就是变量不会外泄），我们发现在这段代码并不存在线程安全问题，这个时候就会把这个同步锁消除。

**3****、锁粗化（Lock Coarsening）**

​    是减少不必要的紧连在一起的lock和unlock操作，将多个连续的锁扩展成一个范围更大的锁。在用synchronized的时候，我们都讲究为了避免大开销，尽量同步代码块要小。那么为什么还要加粗呢？我们继续以上面的字符串拼接为例，我们知道在这一段代码中，每一个append都需要同步一次，那么我可以把锁粗化到第一个append和最后一个append（这里不要去纠结前面的锁消除，我仅打个比方）

**4****、轻量级锁（Lightweight Locking）**

​    这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒。

**5****、偏向锁（Biased Locking）**

​    偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，虽然CAS原子指令相对于重量级锁来说开销比较小，但还是存在非常可观的本地延迟。

**6****、适应性自旋（Adaptive Spinning）**

​    当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁（mutex semaphore）前会进入忙等待（Spinning）然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore（即互斥锁）进入到阻塞状态。

ps：涉及对象头的内存布局，这些数据被称为 Mark Word

​    JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。虚拟机栈中的Lock record和锁对象对应。

​    **轻量级锁**是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。

​    当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 

​    如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 

​    **偏向锁**的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。 当锁对象第一次被线程获得锁时，进入偏向状态，标记为1。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

# 浅析以下两种锁机制的底层的实现策略:

  **互斥同步**最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。synchronized采用的便是这种并发策略。

  随着指令集的发展，我们有了另一种选择：基于冲突检测的**乐观并发策略**，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock采用的便是这种并发策略。

  在**乐观并发策略**中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是CAS操作（Compare and Swap）。JDK1.5之后，Java程序才可以使用CAS操作。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState，这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。

  Java 5中引入了注入AotomicInteger、AotomicLong、AotomicReference等特殊的原子性变量类，它们提供的如：compareAndSet（）、incrementAndSet（）和getAndIncrement（）等方法都使用了CAS操作。因此，它们都是由硬件指令来保证的原子方法。

# ReentrantLock与synchronized用途比较

​    基本语法上，ReentrantLock与synchronized很相似，它们都具备一样的线程重入特性，只是代码写法上有点区别而已，一个表现为API层面的互斥锁（Lock），一个表现为原生语法层面的互斥锁（synchronized）。除此之外ReentrantLock还增加了一些高级功能，主要有以下三项：

  **1****、等待可中断**：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常上的同步块很有帮助。而在等待由synchronized产生的互斥锁时，会一直阻塞，是不能被中断的。

  **2****、可实现公平锁**：多个线程在等待同一个锁时，必须按照申请锁的时间顺序排队等待，而非公平锁则不保证这点，在锁释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁为非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过构造方法ReentrantLock(ture)来使用公平锁。

  **3****、锁可以绑定多个条件**：ReentrantLock对象可以同时绑定多个Condition对象（名曰：条件变量或条件队列），而在synchronized中，锁对象的wait（）和notify（）或notifyAll（）方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无需这么做，只需要多次调用newCondition()方法即可。而且我们还可以通过绑定Condition对象来判断当前线程通知的是哪些线程（即与Condition对象绑定在一起的其他线程）。

# [我们常说的 CAS 自旋锁是什么](https://www.cnblogs.com/fengzheng/p/9018152.html)

​    CAS（Compare and swap），即比较并交换，也是实现我们平时所说的自旋锁或乐观锁的核心操作。它的实现很简单，就是用一个预期的值和内存值进行比较，如果两个值相等，就用预期的值替换内存值，并返回 true。否则，返回 false。

l **使用场景（保证原子操作）：**

CAS 适合简单对象的操作，比如布尔值、整型值等；

CAS 适合冲突较少的情况，如果太多线程在同时自旋，那么长时间循环会导致 CPU 开销很大；

l **ABA****问题**

​    CAS 存在一个问题，就是一个值从 A 变为 B ，又从 B 变回了 A，这种情况下，CAS 会认为值没有发生过变化，但实际上是有变化的。对此，并发包下倒是有 AtomicStampedReference 提供了根据**版本号**判断的实现，可以解决一部分问题。

# 浅析一下ReentrantLock的Condition用法

（1）通过Condition能够更加精细的控制多线程的休眠与唤醒。

（2）对于一个锁，我们可以为多个线程间建立不同的Condition。

**1.** **使用Condition实现一个ArrayBlockingQueue**

我们将实现的MyArrayBlockingQueue类需要包括以下功能：

（1）如果一个线程调用该类的take()获取元素时，若集合为空则使调用线程阻塞。直到有其他线程为集合加入新元素。

（2）如果一个线程调用该类的put()添加新元素时，若集合满了则使调用线程阻塞。直到有其他线程从集合充take出数据。

**1.1** **内部成员以及构造方法**

从下面源码中可以看出，我们使用了泛型，并且默认使用长度为10的数组来维护数据集合。定义了一个锁，并且根据锁的lock.newCondition()创建了两个条件，分别对应集合满和集合空两个条件。

```java
//维护的数据
private final T[] datas;
//数据的个数
private int count;
//插入取出的索引
private int put_index;
private int take_index;

//锁
private final Lock lock = new ReentrantLock();
//定义两个条件，分别为“集合满”和“集合空”
private Condition full = lock.newCondition();
private Condition empty = lock.newCondition();
	
//提供MyArrayBlockingQueue的构造方法，初始化T[]数据
public MyArrayBlockingQueue() {
    this(10);
}
	
public MyArrayBlockingQueue(int maxSize) {
    this.datas = (T[]) new Object[maxSize];
}

```



**1.2 put/get** **方法**

```java
public void put(T data){
    lock.lock();
    try {
	if(count == datas.length){
		//此时集合已经满了
		System.out.println("集合已满，请等待...");
		//使调用线程挂起
		full.await();
	}
	//不满则添加新元素
	datas[put_index++] = data;
	count++;
			
	//此时唤醒等待取数据的线程
	empty.signalAll();
			
        } catch (Exception e) {
	e.printStackTrace();
	}finally{
		lock.unlock();
		}
}

public T take(){
	lock.lock();
	try {
	    if(count == 0){
		//此时集合已经空了
		System.out.println("集合已空，请等待...");
		//使调用线程挂起
		empty.await();
	    }
			
	    //不空则取出最后一个数据
	    take_index = count - 1;
	    T result = datas[take_index--];
	    count--;
			
	    //此时唤醒等待写数据的线程
	    full.signalAll();
			
	    return result;
			
	 } catch (Exception e) {
		e.printStackTrace();
	}finally{
		lock.unlock();
	}
	return null;
}

```

​    put方法中，如果集合满了，就调用await()方法使对应的线程释放锁，并且使调用线程阻塞。直到其他线程调用了take()方法，并调用了full.signalAll()时，该请求线程会被精准唤醒，重新竞争到锁后，代码继续往下执行。

​    若集合不满，则添加新元素，并且通过empty.signalAll()精准唤醒等待取数据的线程。

可以看到在take方法中也是类似的逻辑。这样就灵活并且方便的使用Condition完成了一个简单的线程安全的阻塞队列，一些角标等细节没有处理，毕竟主角是Condition。

**2.** **总结**

在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。Condition的强大之处在于，对于一个锁，我们可以为多个线程间建立不同的Condition。

如果采用Object类中的wait(), notify(), notifyAll()实现的话，当写入数据之后需要唤醒读线程时，不可能通过notify()或notifyAll()明确的指定唤醒读线程，而只能通过notifyAll唤醒所有线程，但是notifyAll无法区分唤醒的线程是读线程，还是写线程。所以，通过Condition能够更加精细的控制多线程的休眠与唤醒。

# CountDownLatch是什么？如何工作（执行过程）？应用场景？

​    [CountDownLatch](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/CountDownLatch.html)是一个计数器闭锁，主要的功能就是通过await()方法来阻塞住当前线程，然后等待计数器countdown()减少到0了，再唤起这些线程继续执行。是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。CountDownLatch的伪代码如下所示：

//Main thread start

//Create CountDownLatch for N threads 

//Create and start N threads

//Main thread wait on latch （待执行的程序先执行，这里通过CountDownLatch的值来判断前面的线程是否执行完毕，如果没有执行完毕会一直卡着）

//N threads completes there tasks are returns

//Main thread resume execution

**执行过程：**

构造器中的计数值（count）实际上就是闭锁需要等待的线程数量。这个值只能被设置一次，而且CountDownLatch没有提供任何机制去重新设置这个计数值。与CountDownLatch的第一次交互是主线程等待其他线程。主线程必须在启动其他线程后立即调用CountDownLatch.await()方法。这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。（重要）其他N个线程必须引用闭锁对象，因为他们需要通知CountDownLatch对象，他们已经完成了各自的任务。这种通知机制是通过 CountDownLatch.countDown()方法来完成的；每调用一次这个方法，在构造函数中初始化的count值就减1。所以当N个线程都调 用了这个方法，count的值等于0，然后主线程就能通过await()方法，恢复执行自己的任务。

**在实时系统中的使用场景**

​    尝试罗列出在java实时系统中CountDownLatch都有哪些使用场景。我所能想到的如下：

\1.   **实现最大的并行性**：有时我们想同时启动多个线程，实现最大程度的并行性。例如，我们想测试一个单例类。如果我们创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，那么我们可以很轻松地完成测试。我们只需调用 一次countDown()方法就可以让所有的等待线程同时恢复执行。

\2.   **开始执行前等待n个线程完成各自任务**：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了。

\3.   **死锁检测：**一个非常方便的使用场景是，你可以使用n个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。

# Semaphore（信号量）

Semaphore与CountDownLatch相似，不同的地方在于Semaphore的值被获取到后是可以释放的，并不像CountDownLatch那样一直减到底。它也被更多地用来限制流量，类似阀门的功能。如果限定某些资源最多有N个线程可以访问，那么超过N个主不允许再有线程来访问，同时当现有线程结束后，就会释放，然后允许新的线程进来。有点类似于锁的lock与unlock过程。可以用Semaphore来实现限流场景。相对来说他也有两个主要的方法：

用于获取权限的acquire(),其底层实现与CountDownLatch.countdown()类似;

用于释放权限的release()，其底层实现与acquire()是一个互逆的过程。

# CyclicBarrier（屏障、关卡）

CyclicBarrier是用来一个关卡来阻挡住所有线程，等所有线程全部执行到关卡处时，再统一执行下一步操作，它里面最重要的方法是await()方法。即每个线程执行完后调用await(),然后在await()里，线程先将计数器减1,如果计数器为0，则执行定义好的操作，然后再继续执行原线程的内容。这个类比之前两个类的一个好处是有点类似于切面编程，可以让我们在同类线程的某个切面切入一块逻辑，并且可以同步所有的线程的执行速度。

# ThreadLocal线程安全原理

**ThreadLocal****提供了线程的本地副本，也就是说每个线程将会拥有一个自己独立的变量副本。它**本身并没有承担存储每个线程中的数据的职责，它是通过操作每个线程内部的一个“副本”-ThreadLocalMap（是ThreadLocal的静态内部类，他是一个设计用来保存thread local 变量的自定义的hash map，key为ThreadLocal<this>本身，所有的操作方法都是私有的，也就是不对外暴露任何操作方法，也就是只能在ThreadLocal中使用）来实现线程之间的隔离，从而保证了线程安全。ThreadLocal操作值的时候是取得当前线程的ThreadLocalMap对象，然后把值设置到了这个对象中，这样对于不同的线程得到的就是不同的ThreadLocalMap，那么向其中保存值或者修改值都只是会影响到当前线程，这样就保证了线程安全。Synchronized（同步访问）关键字也用来解决多线程环境下访问变量的问题，这两者的**区别**在于ThreadLocal是用空间换取时间，synchronized关键字是用时间换空间。

若两个线程同时对一个ThreadLocal变量进行操作，互相之间是没有影响的，换句话说，这很显然并不是用来解决共享变量的一些并发问题，比如多线程的协作。因为ThreadLocal的设计理念就是共享**变私有**，都已经私有了，还谈啥共享？但是共享变私有，如同并发变串行，或许适合解决一些场景的线程安全问题，因为看起来就如同没有共享变量了，不共享即安全，但是他并不是为了解决线程安全问题而存在的。**一个线程中一个，也就是线程隔离，既然是一个线程一个，那么同一个线程中调用的方法也就是共享了，所以说，有时，ThreadLocal会被用来作为参数传递的工具。**因为它能够保障同一个线程中的值是唯一的，那么他就共享于所有的方法中，对于所有的方法来说，相当于一个全局变量了！

**所以可以用来同一个线程内全局参数传递****。****不过要慎用，因为“全局变量”的使用对于维护性、易读性都是挑战，尤其是ThreadLocal这种线程隔离，但是方法共享的“全局变量”。**

# ThreadLocal最根本的使用场景

​    在每个线程希望有一个独有的变量时（这个变量还很可能需要在同一个线程内共享），为了避免每个线程还需要主动地去创建这个对象（如果还需要共享，也一并解决了参数来回传递的问题）。换句话说就是，“如何优雅的解决：线程间隔离与线程内共享的问题”，而不是说用来解决线程安全问题。所以说如果有些场景你需要线程隔离，那么考虑ThreadLocal，而不是你有了什么线程安全问题需要解决，然后求助于ThreadLocal。既然能够线程内共享，自然的确是可以用来线程内全局传参，但是不要滥用，再次注意：

​    ThreadLocal只是具有这样的能力，是你能够做到每个线程一个独有变量，但是如果你set时，不是传递的**new**出来的**新**变量，也就只是理解成“每个线程不同的引用”，对象还是那个对象（有点像参数传递时的值传递，对于对象传递的就是**引用**）。

​    ThreadLocal可以用来优雅的解决线程间隔离的对象，即线程独有的对象，通常都是通过new创建，再借助于ThreadLocal无需在线程中每个方法之前传递参数或重新显式的创建对象，解决方案很优雅。

```
public class DateFormatWrapper {
    private static final SimpleDateFormat SDF = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
    // format(); parse();
}
```

​    经测试发现，SimpleDateFormat 在多线程共享的情况下，不仅可能会出现结果错误的情况，还可能会由于并发访问导致运行异常。当然，我们肯定有解决的办法：

1. 为 DateFormatWrapper 的 format 和 parse 方法加上 synchronized 关键字，坏处就是前面提到的这会加大线程间的竞争和切换而降低效率；
2. 不使用全局的 SimpleDateFormat 对象，而是每次使用 format 和 parse 方法都新建一个 SimpleDateFormat 对象，坏处也很明显，每次调用 format 或者 parse 方法都要新建一个 SimpleDateFormat，这会加大 GC 的负担；
3. 使用 ThreadLocal。ThreadLocal<SimpleDateFormat> 可以为每个线程提供一个独立的 SimpleDateFormat 对象，创建的 SimpleDateFormat 对象个数最多和线程个数相同，相比于 (1)，使用ThreadLocal不存在线程间的竞争；相比于 (2)，使用ThreadLocal创建的 SimpleDateFormat 对象个数也更加合理（不会超过线程的数量）。

我们使用 ThreadLocal 来对 DateFormatWrapper 进行修改，使得每个线程使用单独的 SimpleDateFormat：

```
public class DateFormatWrapper {
 
    private static final ThreadLocal<SimpleDateFormat> SDF = new ThreadLocal<SimpleDateFormat>() {
        @Override
        protected SimpleDateFormat initialValue() {
            return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
        }
    };
 
    public static String format(Date date) {
        return SDF.get().format(date);
    }
 
    public static Date parse(String str) throws ParseException {
        return SDF.get().parse(str);
    }
}
```

如果使用 Java8，则初始化 `ThreadLocal` 对象的代码可以改为：

```
private static final ThreadLocal<SimpleDateFormat> SDF
            = ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"));
```

 

# ThreadLocal什么时候会出现OOM（内存泄漏）的情况？为什么？

​    ThreadLocal很好地解决了线程数据隔离的问题，但是很显然，也引入了另一个空间问题。如果线程数量很多，如果ThreadLocal类型的变量很多，将会占用非常大的空间。而对于ThreadLocal本身来说，他只是作为key，数据并不会存储在它的内部，所以对于ThreadLocal“壳”操作的副本ThreadLocalMap内部的这个Entity的key是弱引用（WeakReference<ThreadLocal<?>>）。

![img](http://image.itstabber.com/2020-09-10/clip_image024.png)

​    如上图所示，实线表示强引用，虚线表示弱引用。对于真实的值是保存在Thread里面的ThreadLocal.ThreadLocalMap threadLocals中的，借助于内部的这个map，通过“壳”ThreadLocal变量的get，可以获取到这个map的真正的值，也就是说，当前线程中持有对真实值value的强引用

而对于ThreadLocal变量本身，如下代码所示，栈中的变量与堆空间中的这个对象，也是强引用的

 static ThreadLocal<String> threadLocal = new ThreadLocal<>();

不过对于Entity来说，key是弱引用。当一系列的执行结束之后，ThreadLocal的强引用也会消亡，也就是堆与栈之间的从ThreadLocal Ref到ThreadLocal的箭头会断开。由于Entity中，对于key是弱引用，所以ThreadLocal变量会被回收（GC时会回收弱引用），而对于线程来说，如果迟迟不结束，那么就会一直存在：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value的强引用，所以value迟迟得不到回收，就会可能导致内存泄漏 。ThreadLocalMap的设计中已经考虑到这种情况，所以ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。一旦将value设置为null之后，就斩断了引用于真实内存之间的引用，就能够真正的释放空间，防止内存泄漏。

![VsmGt2](http://image.itstabber.com/2020-09-10/VsmGt2.jpg)

但是这只是一种**被动**的方式，如果这些方法都没有被调用怎么办？

而且现在对于多线程来说，都是使用**线程池**，那个线程很可能是与应用程序共生死的，怎么办？

那你就每次使用完ThreadLocal变量之后，执行remove方法！！！！

从以上分析也看得出来，由于ThreadLocalMap的生命周期跟Thread一样长，所以很可能导致内存泄漏，弱引用是相当于增加了一种防护手段，通过key的弱引用，以及remove方法等内置逻辑，通过合理的处理，减少了内存泄漏的可能，如果不规范，就仍旧会导致内存泄漏。

 

# JAVA多线程之线程间的通信方式

l **①synchronized****同步**

​    这里讲的同步是指多个线程通过synchronized关键字这种方式来实现线程间的通信。由于线程A和线程B持有同一个MyObject类的对象object，尽管这两个线程需要调用不同的方法，但是它们是同步执行的，比如：线程B需要等待线程A执行完了methodA()方法之后，它才能执行methodB()方法。这样，线程A和线程B就实现了 通信。

​    这种方式，本质上就是“**共享内存**”式的通信。多个线程需要访问同一个**共享变量**，谁拿到了**锁**（获得了访问权限），谁就可以执行。在Java 中 volatile，synchronized 以及各种锁机制，均为了解决线程间公共状态的串行访问问题。

l **②while****轮询的方式**

​    在这种方式下，线程A不断地改变条件，线程ThreadB不停地通过while语句检测特定的某个条件是否成立，从而实现了线程间的通信。但是**这种方式会浪费CPU资源**。之所以说它浪费资源，是因为JVM调度器将CPU交给线程B执行时，它没做啥“有用”的工作，只是在不断地测试某个条件是否成立。*就类似于现实生活中，某个人一直看着手机屏幕是否有电话来了，而不是： 在干别的事情，当有电话来时，响铃通知TA电话来了。*关于线程的轮询的影响，[可参考：](http://www.cnblogs.com/hapjin/p/5467984.html)[JAVA多线程之当一个线程在执行死循环时会影响另外一个线程吗？](http://www.cnblogs.com/hapjin/p/5467984.html)

​    这种方式还存在另外一个问题：轮询的条件的可见性问题，关于内存可见性问题，可参考：[JAVA多线程之volatile 与 synchronized 的比较](http://www.cnblogs.com/hapjin/p/5492880.html)中的第一点“**一，volatile关键字的可见性**”。线程都是先把变量读取到本地线程栈空间，然后再去再去修改的本地变量。因此，如果线程B每次都在取本地的条件变量，那么尽管另外一个线程已经改变了轮询的条件，它也察觉不到，这样也会造成**死循环**。

l **③wait/notify****机制 （**必须在synchronized中使用**）**

​    线程A要等待某个条件满足时才执行操作，线程B则不断地改变这个条件。A,B之间如何通信的呢？也就是说，线程A如何知道这个条件已经满足了呢？这里用到了Object类的 wait() 和 notify() 方法。

当条件未满足时，线程A调用wait() 放弃CPU，并进入阻塞状态。（---不像②while轮询那样占用CPU）当条件满足时，线程B调用notify()通知 线程A，所谓通知线程A，就是唤醒线程A，并让它进入可运行状态。这种方式的一个好处就是CPU的利用率提高了。

​    但也有一些缺点：比如，线程B先执行，一下子就到达了A线程满足的条件，并调用了notify()发送了通知，而此时线程A还执行（没有处理等待阻塞状态）；当线程A执行并调用wait()时，那它永远就不可能被唤醒了。因为，线程B已经发了通知了，以后不再发通知了。这说明：**通知过早，会打乱程序的执行逻辑**。

l **④管道通信**

​    就是使用java.io.PipedInputStream 和 java.io.PipedOutputStream进行通信。管道流过程：生产者向管道中输出数据，消费者从管道中读取数据。当然，生产者的管道输出要与消费者的管道输入进行连接。

​    **总结：**分布式系统中说的两种通信机制：**共享内存机制**和**消息通信机制**。感觉前面的①中的synchronized关键字和②中的while轮询“属于”共享内存机制，由于是轮询的条件使用了volatile关键字修饰时，这就表示它们通过判断这个“共享的条件变量“是否改变了，来实现进程间的交流。而**管道通信**，更像消息传递机制，也就是说：通过管道，将一个线程中的消息发送给另一个。

​    当然还有其他类似的通信方式，如：

​       1、使用 `**Thread.join()**`方法，保证代码阻塞，直到子线程执行完毕再继续执行；

​    2、**Lock**锁提供了一个`**Condition**`类来保持协调替代了同步监视器的功能；

​    3、使用**阻塞队列**（`**BlockingQueue**`它最主要作用不是作为容器，而是作为线程同步工具）。

| **BlockingQueue****方法** | **抛出异常** | **不同返回值** | **阻塞线程** | **指定超时时长**   |
| ------------------------- | ------------ | -------------- | ------------ | ------------------ |
| **队尾插入元素**          | add(e)       | offer(e)       | put(e)       | offer(e,time,unit) |
| **队头删除元素**          | remove()     | poll()         | take()       | poll(time,unit)    |
| **获取、不删除元素**      | element()    | peek()         | 无           | 无                 |

 

# wait(10)代表什么？

```
public final native void wait(long timeout) throws InterruptedException;
```

​    表示在持有对象锁的前提下，在其他线程调用此对象的 `notify()` 方法或 `notifyAll()` 方法通知唤醒之前，或者超过指定的时间量（单位：milliseconds毫秒）之前，导致当前线程等待。也就是说，最多会让当前线程进入阻塞状态等待10毫秒。阻塞等待时，会释放互斥锁。

​    **wait****()****方法**的实现细节是将当前线程放入**阻塞线程队列**中，再把当前线程注册为指定对象的监听器，并且释放指定对象的锁；当被notify/notifyAll通知时，重新争取指定对象的锁，并把当前线程从指定对象的监听器中移除，把当前线程从阻塞队列放入**就绪队列**，等待被调度。只有当重新占用互斥锁之后才会进入可运行状态。此方法必须在sychronized代码块中，且锁定的对象要与等待通知来源的对象一致。如果当前线程不是对象锁的持有者，会抛出java.lang.IllegalMonitorStateException 异常”。

​    而**wait****(****long**` **timeout**`**)****方法**阻塞时放入的是**就绪队列**，等待时间到期或被通知就可被调度，其他与wait()方法相同。

# 线程的交互[——wait，notify，notifyAll，synchronized](https://www.cnblogs.com/lixuwu/p/10534787.html){ }

1、wait、notify以及notifyAll都是Object对象的方法，他们必须在被 synchronized 同步方法或同步代码块中调用（同步环境即当前线程拥有对象锁的情况下），否则会报错。

2、调用wait()会使当前线程进入等待状态，并且会释放被同步对象的锁，直到其他线程调用该对象的notify() 方法或 notifyAll() 方法。

3、notify()唤醒在此对象监视器上等待的单个线程。可以唤醒一个因执行wait而处于阻塞状态的线程，使其进入就绪状态，被唤醒的线程会去尝试着获取对象锁，然后执行wait之后的代码。如果发出notify操作时，没有线程处于阻塞状态，那么该命令会忽略。注意执行notify并不会马上释放对象锁，会等到执行完该同步方法或同步代码块后才释放。notify方法可以随机唤醒等待队列中等待同一共享资源的“一个”线程，使其退出等待队列进入可运行状态。

4、notifyAll()唤醒在此对象监视器上等待的所有线程。可以唤醒等待队列中等待同一共享资源的“全部”线程从等待状态退出，进入可运行状态。此时，优先级最高的那个线程优先执行，但也有可能是随机执行，这取决于JVM虚拟机的实现。

**最后说下 wait和sleep的区别，这也是面试经常面到的问题。**

l sleep是Thread类的方法而wait是Object类的方法。

l sleep不会立马释放对象锁，而wait会释放。

 

# 死锁（Java多线程死锁和数据库死锁），工作中怎么解决？

**一、多线程死锁是怎么造成的？**

1. 多线程锁定同一**资源**（共享变量、锁、磁盘、线程池中的线程、网络连接池的连接、数据库引擎锁等）会造成死锁；
2. 线程池中的任务使用当前线程池也可能出现死锁。

```
@Slf4j
public class DeadLock2 {
 
      public static void main(String[] args) {
            ExecutorService pool = Executors.newFixedThreadPool(1);
            pool.submit(() -> {
                try{
                    log.info("First");
                    pool.submit(() -> log.info("second")).get();
                    log.info("third");
                }catch (InterruptedException | ExecutionException e){
                    log.error("Error",e);
                }
            });
            System.out.println("process is over");
      }
}
```

死锁出现了！我们来一步一步分析：

l 打印“First”的任务被提交到只有一个线程的线程池

l 任务开始执行并打印“First”

l 我们向线程池提交了一个内部任务，来打印“Second”

l 内部任务进入等待任务队列。没有可用线程因为唯一的线程正在被占用

l 我们阻塞住并等待内部任务执行结果。不幸的是，我们等待内部任务的同时也在占用着唯一的可用线程

l get() 方法无限等待，无法获取线程

l 死锁

l **死锁预防，避免死锁**

1、尽量避免加多个锁，嵌套死锁

2、以确定的顺序获得锁：加锁顺序

3、超时放弃（加锁限时）：Lock接口提供了`boolean tryLock(long time, TimeUnit unit) throws InterruptedException`方法，该方法可以按照固定时长等待锁，因此线程可以在获取锁超时以后，主动释放之前已经获得的所有的锁。通过这种方式，也可以很有效地避免死锁。

4、工具检测死锁

l **检测工具1：Jstack命令**

jstack是java虚拟机自带的一种堆栈跟踪工具。用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。还可以用于生成java虚拟机当前时刻的线程快照。**线程快照**是当前java虚拟机内每一条线程**正在执行**的**方法堆栈**的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如`线程间死锁`、`死循环`、`请求外部资源导致的长时间等待`等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。

**首先**，我们通过jps确定当前执行任务的进程号:

```
jonny@~$ jps
1370 JConsole
1362 AppMain
1421 Jps
1361 Launcher
```

可以确定任务进程号是1362，**然后**执行jstack命令查看当前进程堆栈信息：

```
jonny@~$ jstack -F 1362
Attaching to process ID 1362, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 23.21-b01
Deadlock Detection:
Found one Java-level deadlock:
=============================
"Thread-1":
  waiting to lock Monitor@0x00007fea1900f6b8 (Object@0x00000007efa684c8, a java/lang/Object),
which is held by "Thread-0"
"Thread-0":
  waiting to lock Monitor@0x00007fea1900ceb0 (Object@0x00000007efa684d8, a java/lang/Object),
  which is held by "Thread-1"
Found a total of 1 deadlock.
```

可以看到，进程的确存在死锁，两个线程分别在等待对方持有的Object对象

l **检测工具2：JConsole工具**

​    Jconsole是JDK自带的监控工具，在JDK/bin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在Java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗。

我们在命令行中敲入jconsole命令，会自动弹出以下对话框，选择进程1362，并点击“链接”新建连接

进入所检测的进程后，选择“线程”选项卡，并点击“检测死锁”。

​    以上例子我都是用synchronized关键词实现的死锁，如果读者用ReentrantLock制造一次死锁，再次使用死锁检测工具，也同样能检测到死锁，不过显示的信息将会更加丰富。

**二、数据库死锁**

**1****、innodb隔离级别、索引与锁：****锁id主键行，锁二级索引对应主键行，没命中索引则锁全表**

**2****、锁与隔离级别的关系**

数据库的事务隔离级别：mysql> select @@tx_isolation;

l 未提交读RU（read uncommitted)

l 已提交读RC（read committed）：能读到已经提交的数据。

l 可重复读RR（repeatable read）：在同一个事务内查询都是事务开始时刻一致的，InnoDB默认级别。

l 串行化（Serializable)

[**详解MySQL****（InnoDB****）是如何处理死锁的**](https://www.cnblogs.com/mxb0611/p/12143494.html)

**一、什么是死锁****：**两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁。

**二、为什么会形成死锁**：MySQL的并发控制有两种方式，一个是 MVCC，一个是两阶段锁协议。

**两阶段锁协议（2PL）**官方定义：

​    两阶段锁协议是指所有事务必须分两个阶段对数据加锁和解锁，在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁；在释放一个封锁之后，事务不再申请和获得任何其他封锁。

对应到 MySQL 上分为两个阶段：

1. 扩展阶段（事务开始后，commit     之前）：获取锁
2. 收缩阶段（commit     之后）：释放锁

就是说呢，只有遵循两段锁协议，才能实现 可串行化调度。

但是两阶段锁协议不要求事务必须一次将所有需要使用的数据加锁，并且在加锁阶段没有顺序要求，所以这种并发控制方式会形成死锁。

**三、MySQL 如何处理死锁？**

MySQL有两种死锁处理方式：

1. 等待，直到超时（innodb_lock_wait_timeout=50s）。
2. 发起死锁检测，主动回滚一条事务，让其他事务继续执行（innodb_deadlock_detect=on）。

由于性能原因，一般都是使用死锁检测来进行处理死锁。

**死锁检测**

死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。

**回滚**

检测到死锁之后，选择插入更新或者删除的行数最少的事务回滚，基于 INFORMATION_SCHEMA.INNODB_TRX 表中的 trx_weight 字段来判断。

**四、如何避免发生死锁**

**收集死锁信息：**

1. 利用命令 SHOW     ENGINE INNODB STATUS查看死锁原因。
2. 调试阶段开启     innodb_print_all_deadlocks，收集所有死锁日志。
3. mysql>show full processlist; 查看当前库里面的线程情况，有sleep的线程事务一直没有commit或者rollback而是卡住了

**减少死锁：**

1. 使用事务，不使用     lock tables 。
2. 保证没有长事务。
3. 操作完之后立即提交事务，特别是在交互式命令行中。
4. 如果在用     (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)，尝试降低隔离级别。
5. 修改多个表或者多个行的时候，将修改的顺序保持一致。
6. 创建索引，可以使创建的锁更少。
7. 最好不要用     (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)。
8. 如果上述都无法解决问题，那么尝试使用 lock tables t1, t2, t3 锁多张表

# [MySQL的innoDB锁机制以及死锁处理](https://www.cnblogs.com/my_life/articles/10219562.html)

InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。行级锁与表级锁本来就有许多不同之处，innodb正常的select ID from table where id=1；不会上任何锁，接下来详细讨论InnoDB的锁问题;

**一：InnoDB行锁的介绍。**

**共享锁（S）**：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁,也就是我读取的行，你不能修改；

**排他锁（X)**：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。也就是我更新的行，不允许其他的事务读取和更新相同的行；

另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种**内部使用的意向锁（Intention Locks）**，这两种意向锁都是**表锁**。

意向共享锁（IS）：

  事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。

意向排他锁（IX）：

  事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加**排他锁（X)**；对于普通SELECT语句，InnoDB不会加任何锁；**事务**可以通过以下语句显示给记录集加共享锁或排他锁。

共享锁（S）：SELECT * FROM table_name WHERE ... **LOCK IN SHARE MODE**；

排他锁（X)：SELECT * FROM table_name WHERE ... **FOR UPDATE**；

InnoDB行锁模式兼容性列表：

 

如果一个**事务**请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。

 

**二：关于innodb锁机制，实现原理：**

InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**

索引分为**主键**索引和**二级索引【也就是非主键索引】**两种，**如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引;如果一条语句操作了二级索引，MySQL会先锁定该二级索引，再锁定相关的主键索引。**

然后innodb行锁分为三种情形：（三种锁级别：页级、表级、行级）

1）Record lock ：对索引项加锁，即锁定一条记录。

2）Gap lock：对索引项之间的‘间隙’、对第一条记录前的间隙或最后一条记录后的间隙加锁，即**锁定一个范围的记录，不包含记录本身**

3）Next-key Lock：锁定一个范围的记录并包含记录本身（上面两者的结合）。

注意：**InnoDB****默认级别是repeatable-read级别，所以下面说的都是在RR级别中的**。

**三：关于innodb锁机制需要注意的是：**

1）InnoDB行锁是通过给索引项加锁实现的，如果没有索引，InnoDB会通过隐藏的聚簇索引来对记录加锁。也就是说：如果不通过索引条件检索数据，那么InnoDB将对表中所有数据加锁，实际效果跟表锁一样。

2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。说白了就是，where id=1 for update 会锁定所有id=1的数据行，如果是where id=1 and name='liuwenhe' for update,这样会把所有 id=1以及所有name='liuwenhe'的行都上排它锁；

3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。

4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL优化器通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，或者隐式转换，或者like百分号在前等等，这种情况下InnoDB将使用表锁，而不是行锁。

因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。

 

**四：查看innodb的相关锁；**

1）查询相关的锁：

**information_schema** **库**中增加了三个关于锁的表：

innodb_trx    ## 当前运行的所有事务 ，还有具体的语句，

innodb_locks   ## 当前出现的锁，只有

innodb_lock_waits ## 锁等待的对应关系

**mysql> show processlist; ##****可以看出来当前库的等待线程情况**

或者

**mysql> show engine innodb status\G ##****也可以要看出相关死锁的问题**

或者：

mysql> select ID,STATE from information_schema.processlist where user='system user';

mysql> select concat('KILL ',id,';') from information_schema.processlist where user='system user';

批量kill多个进程。

mysql>select concat('KILL ',id,';') from information_schema.processlist where user='root' into outfile '/tmp/a.txt';

检查自动提交mysql> select @@autocommit;

设置自动提交mysql> set global autocommit=1;

**五：关于死锁：**

**MyISAM****表锁是deadlock free的**，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的**事务**外，**锁是逐步获得的【一个包含多条sql的事务】**，这就决定了在InnoDB中发生死锁是可能的。

发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数 **innodb_lock_wait_timeout**来解决。

需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。

通常来说，**死锁都是应用设计的问题**，通过调整业务流程、数据库对象设计、**事务大小**，以及访问数据库的SQL语句，绝大部分死锁都可以避免。

下面就通过实例来介绍几种避免死锁的常用方法。

（1）在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。

（2）在程序以批量方式处理数据的时候，如果事先**对数据排序**，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。

（3）在事务中，**如果要更新记录，应该直接申请足够级别的锁，即排他锁**，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。

如果出现死锁，可以用mysql> **show engine innodb status\G**命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

总结：MySQL innodb引擎的锁机制比myisam引擎机制复杂，但是innodb引擎支持更细粒度的锁机制，当然也会带来更多维护的代价；然后innodb的行级别是借助对索引项加锁实现的，值得注意的事如果表没有索引，那么就会上表级别的锁，同时借助行级锁中gap锁来解决部分幻读的问题。只要知道MySQL innodb中的锁的机制原理，那么再解决死锁或者避免死锁就会很容易！

# 线程的调度——休眠Thread.sleep()

线程休眠的目的是使线程让出CPU的最简单的做法之一，线程休眠时候，会将CPU资源交给其他线程，以便能轮换执行，当休眠一定时间后，线程会苏醒，进入准备状态等待执行。线程休眠的方法是Thread.sleep(long millis) 和Thread.sleep(long millis, int nanos) ，均为静态方法，哪个线程调用sleep，就休眠哪个线程。

# 线程的调度——优先级thread.setPriority(1~10)

与线程休眠类似，线程的优先级仍然无法保障线程的执行次序。只不过，优先级高的线程获取CPU资源的概率较大，优先级低的并非没机会执行。线程的优先级用1-10之间的整数表示，数值越大优先级越高，默认的优先级为5。在一个线程中开启另外一个新线程，则新开线程称为该线程的子线程，子线程初始优先级与父线程相同。

# 线程的调度——让步：Thread.yield()

线程的让步含义就是使当前运行着线程让出CPU资源，但是然给谁不知道，仅仅是让出，线程状态回到可运行状态。 线程的让步使用Thread.yield()方法，yield() 为静态方法，功能是暂停当前正在执行的线程对象，并执行其他线程。

# 线程的调度——合并thread.join()

线程的合并让主线程等待子线程运行结束后再继续运行，可以将几个并行线程当作子线程合并到一个主线程上执行，应用场景是当一个线程必须等待另一个线程执行完毕才能执行时可以使用join方法。join为非静态方法，定义如下：

void join()   等待该线程终止。

void join(long millis)  等待该线程终止的时间最长为 millis 毫秒。

void join(long millis, int nanos)  等待该线程终止的时间最长为 millis 毫秒 + nanos 纳秒。

# 线程的调度——守护线程thread.setDaemon(true)

Daemon Thread守护线程与User Thread(用户线程)普通线程写法上基本么啥区别，用个比较通俗的比如，任何一个守护线程都是整个JVM中所有非守护线程的保姆。只要当前JVM实例中尚存在任何一个非守护线程没有结束，守护线程就全部工作；只有当最后一个非守护线程结束时，守护线程随着JVM一同结束工作。因为没有了被守护者，Daemon也就没有工作可做了，也就没有继续运行程序的必要了。

Daemon的作用是为其他线程的运行提供便利服务，守护线程最典型的应用就是，JVM的GC (垃圾回收器)、内存管理等线程都是守护线程。还有就是在做数据库应用时候，使用的数据库连接池，连接池本身也包含着很多后台线程，监控连接个数、超时时间、状态等等。补充说明：

定义：守护线程--也称“服务线程”，在没有用户线程可服务时会自动离开。

优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。

在start()方法被调用之前调用线程对象的方法setDaemon(true)，则可以将其设置为守护线程。setDaemon方法的详细说明：

public final void setDaemon(boolean on) // 将该线程标记为守护线程或用户线程。

这里有几点需要注意： 

(1) thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。

(2) 在Daemon线程中产生的新线程也是Daemon的。 

(3) 不要认为所有的应用都可以分配给Daemon来进行服务，比如读写操作或者计算逻辑。 

因为你不可能知道在所有的User完成之前，Daemon是否已经完成了预期的服务任务。一旦User退出了，可能大量数据还没有来得及读入或写出，计算任务也可能多次运行结果不一样。这对程序是毁灭性的。造成这个结果理由已经说过了：一旦所有User Thread离开了，虚拟机也就退出运行了。

# 核心线程是线程初始化就会创建出来？

Java使用Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。Java可以用四种方式来创建线程，如下所示：

1）继承Thread类创建线程

2）实现Runnable接口创建线程

3）使用Callable和Future创建线程

4）使用线程池例如用Executor框架

# 控制线程顺序执行的方法有哪些？

例如：现有A、B、C、D、E五个线程，现在需要E线程在ABCD四个线程结束之后再执行：

\1. join 让主线程等待子线程运行结束后再继续运行

\2. 利用并发包里的Excutors的newSingleThreadExecutor产生一个单线程的线程池，而这个线程池的底层原理就是一个先进先出（FIFO）的 队列。代码中executor.submit依次添加了123线程，按照FIFO的特性，执行顺序也就是123的执行结果，从而保证了执行顺序。

\3. 使用 CountDownLatch 控制多个线程执行顺序 cutDown()方法和await()方法

# java多线程的异步调用，比如a方法调动b方法的异步返回结果怎么获取的？

#### Future、FutureTask介绍

Future是一个接口，该接口用来返回异步的结果。是一个抽象的概念，它表示一个值，该值可能在某一点变得可用。一个Future要么获得 计算完的结果，要么获得计算失败后的异常。在java.util.concurrent包中，Future接口是Java线程Future模式的实现，可以来进行异步计算。有了Future就可以进行三段式的编程了，1.启动多线程任务2.处理其他事3.收集多线程任务结果。从而实现了非阻塞的任务调用。在途中遇到一个问题，那就是虽然能异步获取结果，但是Future的结果需要通过isDone()来判断是否有结果，或者使用get()函数来阻塞式获取执行结果。这样就不能实时跟踪其他线程的结果状态了，所以直接使用get还是要慎用，最好配合isdone来使用。

FutureTask是一个类，是Future 的一个实现。

# 线程池的工作机制,Java通过Executors工具类创建出来的线程池有什么区别，为什么这样定义？

```
Executors.newCachedThreadPool();     // 创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE
Executors.newSingleThreadExecutor();  // 创建容量为1的缓冲池，可以按提交顺序依次执行
Executors.newFixedThreadPool(int);    // 创建固定容量大小的缓冲池
```

# 线程池有哪些参数，具体含义是什么? 共7个参数

# 创建线程池有哪几个核心参数？ 如何合理配置线程池的大小？

corePoolSize 核心池的线程数，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；

maximumPoolSize线程池最大线程数，它表示在线程池中最多能创建多少个线程；

RejectedExecutionHandler饱和策略：DiscardPolicy，DiscardOldPolicy，CallerRunPolicy，AbortPolicy

keepAliveTime存活时间，表示线程没有任务执行时最多保持多久时间会终止；

TimeUnit 线程活动保持时间keepAliveTime的单位，有7种取值，在TimeUnit类中有7种静态属性；

workQueue阻塞队列 ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous

threadFactory线程工厂，用来创建线程

# 线程池的原理，为什么要创建线程池？创建线程池的方式；

## 线程池原理 

提交一个任务到线程池中，线程池的处理流程如下： 

1、判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。 

2、线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。 

3、判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。

![img](http://image.itstabber.com/2020-09-10/clip_image026.png)

## 为什么要使用线程池

\1.  减少资源消耗,通过重复的使用已创建好的线程，避免了线程的频繁创建和销毁所造成的**消耗**

\2.  提高响应速度,当任务到达时，不需要再去创建，可以直接使用已经创建好的线程就能立即执行任务

\3.  提高线程的管理性,线程池可以统一管理线程的创建，销毁，分配，调优监控

解决的问题：通过固定的几个线程为大量的操作服务,降低线程的频繁创建,销毁线程所需要消耗的时间，从而提高效应效率。

在面向对象编程中，对象创建和销毁是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是对一些很耗资源的对象创建和销毁。如何利用已有对象来服务就是一个需要解决的关键问题，其实这就是一些"池化资源"技术产生的原因。比如大家所熟悉的数据库连接池就是遵循这一思想而产生的，下面将介绍的线程池技术同样符合这一思想。

多线程技术主要解决处理器单元内多个线程执行的问题，它可以显著减少处理器单元的闲置时间，增加处理器单元的吞吐能力。但如果对多线程应用不当，会增加对单个任务的处理时间。可以举一个简单的例子：

假设一台服务器完成一项任务的时间为T

```
 1. T1 创建线程的时间
 2. T2 在线程中执行任务的时间，包括线程间同步所需时间> 
 3. T3 线程销毁的时间
```

显然T ＝ T1＋T2＋T3。注意这是一个极度简化的假设。

可以看出T1，T3是多线程本身附加的开销，用户希望减少T1，T3所用的时间，从而减少T的时间。但一些线程的使用者并没有注意到这一点，所以在应用程序中频繁的创建或销毁线程，这导致T1和T3在T中占有非常大的比例。

线程池技术正是关注如何缩短或调整T1，T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了，线程池不仅调整T1，T3产生的时间，而且它还显著减少了创建线程的数目。

## 创建线程&线程池

java创建线程的三种方式：

```
1. 继承Thread类创建线程类
2. 实现Runnable接口
3. 通过Callable和Future创建线程
```

java创建线程池的四种方式：

```
1. newCachedThreadPool 创建一个可缓存的线程池，如果线程池长度超过处理需求，可灵活回收空闲线程，若无可回收，则新建线程。
2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会唯一的工作线程来执行任务，保证所有任务按照指定顺序（FIFO，LIFO，优先级）执行。
```

## 线程池的好处

通过重复利用已创建的线程，减少在创建和销毁线程上所花的时间以及系统资源的开销。

提高响应速度，当任务到达时，任务可以不需要等到线程创建就可以立即执行。 提高线程的可管理性，使用线程池可以对线程进行统一的分配和监控。

如果不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存。

## 线程池的注意事项：

线程池的大小：多线程应用并非线程越多越好。需要根据系统运行的硬件环境以及应用本身的特点决定线程池的大小。一般来说，如果代码结构合理，线程数与cpu数量相适合即可。如果线程运行时可能出现阻塞现象，可相应增加池的大小、如果有必要可采用自适应算法来动态调整线程池的大小。以提高cpu的有效利用率和系统的整体性能。

并发错误：多线程应用要特别注意并发错误，要从逻辑上保证程序的正确性，注意避免死锁现象的发生。
 线程泄露：这是线程池应用中的一个严重的问题、当任务执行完毕而线程没能返回池中就会发生线程泄露现象。

# 线程的生命周期，什么时候会出现僵死进程；

![img](http://image.itstabber.com/2020-09-10/clip_image027.png)

![img](http://image.itstabber.com/2020-09-10/clip_image028.png)

上图中基本上囊括了Java中多线程各重要知识点。掌握了上图中的各知识点，Java中的多线程也就基本上掌握了。主要包括：

**Java****线程具有七种基本状态**

**新建状态（New）：至今尚未启动的线程的状态。线程刚被创建，但尚未启动****。**如：Thread t = new MyThread();

**就绪状态（Runnable）：**当调用线程对象的start()方法（t.start();），线程即进入就绪状态。正在等待被分配给CPU时间片，也就是说此时线程正在就绪队列中排队等候得到CPU资源。并不是说执行了t.start()此线程立即就会执行；

**运行状态（Running）****：**线程获得CPU资源正在执行任务（执行run()方法），此时除非此线程自动放弃CPU资源或者有优先级更高的线程进入,线程将一直运行到结束或者时间片结束。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；

无限期等待（Waiting）：位于对象等待池中的阻塞状态（Blocked in object’s wait pool）：当线程处于运行状态时，如果执行了某个对象的wait()方法，Java虚拟机就会把线程放到这个对象的等待池中，这涉及到“线程通信”的内容。处于这种状态的线程不会被分配处理器执行时间，它们要等待被其他线程显示唤醒。以下方法会让线程陷入无限期的等待状态：

·    没有设置timeout参数的Object::wait()方法

·    没有设置timeout参数的Thread::join()方法

·    LockSupport::park()方法

**限期等待（Timed Waiting）****：**处于这种状态的线程也不会被分配处理器执行时间，不过无须等待其他线程显示唤醒，在一定时间后它们由系统自动唤醒。以下方法会让线程进入期限等待状态：

·    Thread::sleep()方法

·    设置了timeout参数的Object::wait()方法

·    设置了timeout参数的Thread::join()方法

·    LockSupport::parkNanos()方法

·    LockSupport::parkUntil()方法

**阻塞状态（Blocked）：**处于运行状态中的线程由于某种（当线程处于运行状态时，试图获得某个对象的同步锁时，如果该对象的同步锁已经被其他线程占用，Java虚拟机就会把这个线程放到这个对象的锁池中。这涉及到“线程同步”的内容，【线程在获取synchronized同步锁失败(因为锁被其它线程所占用)】）原因，暂时放弃对CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才有机会再次被CPU调用以进入到运行状态。由于某种原因导致正在运行的线程让出CPU并暂停自己的执行，即进入堵塞状态。阻塞结束后线程进入就绪状态。堵塞的情况分三种：

(一)等待堵塞：执行的线程执行wait()方法，JVM会把该线程放入等待池中。

(二)同步堵塞：执行的线程在获取对象的同步锁时，若该同步锁被别的线程占用。则JVM会把该线程放入锁池中。

(三)其它堵塞：执行的线程执行sleep()或join()方法，或者发出了I/O请求时。JVM会把该线程置为堵塞状态。

当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完成时。线程又一次转入就绪状态。

 “阻塞状态”与“等待状态”的区别：“阻塞状态”在等待着获取一个排它锁，这个事件将在另一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作发生。在程序进入同步区域的时候，线程就会进入阻塞状态。

**死亡状态（Dead）：**线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

# 线程池队列如何设置多长

**1. ThreadPoolExecutor****的重要参数**

·    corePoolSize：核心线程数

o  核心线程会一直存活，及时没有任务需要执行

o  当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理

o  设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭

·    queueCapacity：任务队列容量（阻塞队列）

o  当核心线程数达到最大时，新任务会放在队列中排队等待执行

·    maxPoolSize：最大线程数

o  当线程数>=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务

o  当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常

·    keepAliveTime：线程空闲时间

o  当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize

o  如果allowCoreThreadTimeout=true，则会直到线程数量=0

·    allowCoreThreadTimeout：允许核心线程超时

·    rejectedExecutionHandler：任务拒绝处理器

o  两种情况会拒绝处理任务：

o  当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务

o  当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务

o  线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常

o  ThreadPoolExecutor类有几个内部实现类来处理这类情况：

o  AbortPolicy 丢弃任务，抛运行时异常

o  CallerRunsPolicy 执行任务

o  DiscardPolicy 忽视，什么都不会发生

o  DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务

o  实现RejectedExecutionHandler接口，可自定义处理器

**2. ThreadPoolExecutor****执行顺序：**线程池按以下行为执行任务

\1.   当线程数小于核心线程数时，创建线程。

\2.   当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。

\3.   当线程数大于等于核心线程数，且任务队列已满

1)   若线程数小于最大线程数，创建线程

2)   若线程数等于最大线程数，抛出异常，拒绝任务

**3.** **如何设置参数**

·    默认值

o  corePoolSize=1

o  queueCapacity=Integer.MAX_VALUE

o  maxPoolSize=Integer.MAX_VALUE

o  keepAliveTime=60s

o  allowCoreThreadTimeout=false

o  rejectedExecutionHandler=AbortPolicy()

·    如何来设置

o  需要根据几个值来决定

o  tasks ：每秒的任务数，假设为500~1000

o  taskcost：每个任务花费时间，假设为0.1s

o  responsetime：系统允许容忍的最大响应时间，假设为1s

o  做几个计算

o  corePoolSize = 每秒需要多少个线程处理？ 

o  threadcount = tasks/(1/taskcost) =tasks*taskcout =  (500~1000)*0.1 = 50~100 个线程。corePoolSize设置应该大于50

o  根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可

o  queueCapacity = (coreSizePool/taskcost)*responsetime

o  计算可得 queueCapacity = 80/0.1*1 = 80。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行

o  切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。

o  maxPoolSize = (max(tasks)- queueCapacity)/(1/taskcost)

o  计算可得 maxPoolSize = (1000-80)/10 = 92

o  （最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数

o  rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理

o  keepAliveTime和allowCoreThreadTimeout采用默认通常能满足

·    以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件（呵呵）和优化代码，降低taskcost来处理。

# 类加载过程和双亲委派模型

![img](http://image.itstabber.com/2020-09-10/clip_image029.png)

上图中的加载，验证，准备，初始化，卸载这5个步骤的顺序是固定的，类的加载器也必须按这个顺序开始，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定l在加载阶段，虚拟机需要完成以下三件事情：

·    通过一个类的全限定名来获取定义此类的二进制字节流

·    将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构

·    在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类各种数据的访问入口

但虚拟机规范中并未指明二进制字节流要从哪里获取，应该怎样获取，因此加载阶段是非常灵活的。例如：

·    我们可以从jar，war等格式的文件中获取

·    也可以在运行的时候通过计算生成，最典型的就是动态代理技术

### 加载阶段（Loading）

它是Java将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构（Class对象），这里的数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等；如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。加载阶段是用户参与的阶段，可以自定义类加载器，去实现自己的类加载过程。

### 链接（Linking）

这是核心的步骤，简单说是把原始的类定义信息平滑地转化入JVM运行的过程中。这里可进一步细分为三个步骤：

l  验证(Verification)，是虚拟机安全的重要保障，JVM需要核验字节信息是符合Java虚拟机规范的，否则就被认为是VerifyError，这样就防止了恶意信息或者不合规的信息危害JVM的运行，验证阶段有可能触发更多class的加载。

l  准备（Preparation），创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。

l  解析（Resolution），在这一步会将常量池中的符号引用（symbolic reference）替换为直接引用。在Java虚拟机规范中，详细介绍了类、接口、方法和字段等各个方面的解析。

### 初始化阶段（initialization）

这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。

 

### 系统有哪些类加载器？

![img](http://image.itstabber.com/2020-09-10/clip_image030.png)

如上图所示：

·    Bootstrap ClassLoader：这个类由C/C++实现的是虚拟机的自身的一部分

·    Extension ClassLoader：扩展类加载器，它默认加载<JAVA_HOME>\lib\ext目录下的，也可以加载由java.ext.dirs指定的路径中的所有类库

·    Application ClassLoader：应用程序类加载器，它主要负责加载用户类路径上所指定的类库，这个也是默认的程序中的类加载器。

### 双亲委派模型

简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载Java类型。

```java
protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        // 加锁机制
        synchronized (getClassLoadingLock(name)) {
            // 检查这个类是否被加载过
            Class<?> c = findLoadedClass(name);
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    if (parent != null) {
                        // 调用父类的ClassLoader来加载
                        c = parent.loadClass(name, false);
                    } else {
                        // 查找最顶层的BootstrapClassLoader
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    .....
                }

                if (c == null) {
                    // 如果父类加载器都没找到,就直接调用查找类的方法去查找
                    long t1 = System.nanoTime();
                    c = findClass(name);
                    ......
                }
            }
            if (resolve) {
                resolveClass(c);
            }
            return c;
        }
    }

```



上面的代码很清楚，我们每个`ClassLoader`都会持有一个父类的ClassLoader对象，当调用当前的加载类的方法时候，其实内部会调用`父类的``ClassLoader`来完成加载，如果最顶层的`父类加载器抛出异常`，说明父类无法完成加载请求，此时就由子类来完成，`查找类`，`加载类`的过程了。

# Class文件结构是如何解析的

![https://img-blog.csdnimg.cn/20200531220253179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW56aG9uZ2hhb3Fpbmc=,size_16,color_FFFFFF,t_70](http://image.itstabber.com/2020-09-10/clip_image031.png)

 

![https://img-blog.csdnimg.cn/2020053122040134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpYW56aG9uZ2hhb3Fpbmc=,size_16,color_FFFFFF,t_70](http://image.itstabber.com/2020-09-10/clip_image032.png)

   Class文件是一组以**8****位字节**为基础单位的二进制流，各个数据项目严格按照顺序准确地排列在Class文件中，中间没有任何分隔符。当遇到8位字节以上的数据时，就按照高位在前的方式（最高位字节在地址最低位、最低位字节在地址最高位的顺序储存）分割成多个8位字节储存。

   Class文件格式采用一种类似于C语言结构体的伪结构来储存数据的，这种伪结构有两种数据类型：**无符号数**和**表**。

   **无符号数**是基本数据类型，以u1、u2、u4、u8分别代表1个字节、2个字节、4个字节和8个字节的无符号数，可以用来描述数字、索引引用、数量值或者UTF-8编码构成的字符串值。

   **表**是由多个无符号数或其他表作为数据项构成的复合数据类型，所有的表都习惯地以“_info”结尾。**表**的数据结构和树很类似，**无符号数**相当于它的叶子节点，其他的表相当于它的子节点。整个Class文件就本质上也是一个表，具体结构如下：

| **类型**       | **名称**            | **数量**                | **描述**           |
| -------------- | ------------------- | ----------------------- | ------------------ |
| u4             | magic               | 1                       | 魔数(Magic Number) |
| u2             | minor_version       | 1                       | 次版本号           |
| u2             | major_version       | 1                       | 主版本号           |
| u2             | constant_pool_count | 1                       | 常量池容量计数值   |
| cp_info        | constant_pool       | constant_pool_count - 1 | 常量池             |
| u2             | access_flags        | 1                       | 访问标志           |
| u2             | this_class          | 1                       | 类索引             |
| u2             | super_class         | 1                       | 父类索引           |
| u2             | interfaces_count    | 1                       | 接口索引计数值     |
| u2             | interfaces          | interface_count         | 接口索引           |
| u2             | fields_count        | 1                       | 字段计数值         |
| field_info     | fields              | fields_count            | 字段表             |
| u2             | methods_count       | 1                       | 方法计数值         |
| method_info    | fields              | methods_count           | 方法表             |
| u2             | attributes_count    | 1                       | 属性计数值         |
| attribute_info | attributes          | attributes_count        | 属性表             |

   可以发现，无论是**无符号数**还是**表**，当需要描述同一种类型又数量不定的多条数据时，就会用一个前置的计数器加几个连续的数据项的方式，这个时候我们就把这种一系列连续的某种类型的数据叫做这个类型的**集合**。在Class文件中，无论是顺序还是数量，甚至是数据存储的字节序，都必须严格按照上面表格进行设定，哪个字节代表什么含义，长度是多少，先后顺序怎么样，都不允许改变。有个一个专门分析Class文件字节码的工具javap: E:\>javap -verbose YourTest E:\>javap -v YourTest

## 如何解析

​    组成Class文件的各个数据项中，例如魔数、Class文件的版本、访问标志、类索引和父类索引等数据项，它们在每个Class文件中都占用固定数量的字节，在解析时只需要读取相应数量的字节。除此之外，需要**灵活处理**的主要包括4部分：**常量池**、**字段表集合**、**方法表集合和属性表集合**。字段和方法都可以具备自己的属性，Class本身也有相应的属性，因此，在解析字段表集合和方法表集合的同时也包含了属性表集合的解析。

​    **常量池**占据了Class文件很大一部分的数据，用于存储所有的常量信息。其中主要存放两大类常量：**字面量**(Literal)和**符号引用**(Symbolic References)。字面量如文本字符串、声明为final的常量值等。符号引用包括三类常量：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。

   **字段表**(field_info)是用来描述接口或类中声明的变量。包括类级变量（静态变量）和实例级变量（成员变量），但是不包括在方法内部声明的局部变量。

   **方法表**的结构和字段表的是一样的，也是依次包括了访问标志(access_flags)、名称索引(name_index)、描述符索引(descriptor_index)和属性表集合(attributes)。

   **属性表**(attribute_info)在前面的分享中出现了几次，在Class文件、字段表、方法表都可以有自己的属性表集合，用来描述某些场景下特有的信息。属性表不在要求具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以写入自己定义的属性信息，Java虚拟机在运行时会忽略掉它不认识的属性。

# 类加载器的组织结构

类加载器 ClassLoader是具有层次结构的，也就是父子关系。其中，Bootstrap是所有类加载器的父亲。

（1）Bootstrapclass loader： 启动类加载器

当运行Java虚拟机时，这个类加载器被创建，它负责加载虚拟机的核心类库，如java.lang.*等。

（2）Extensionclass loader：标准扩展类加载器

用于加载除了基本 API之外的一些拓展类。

（3）AppClassLoader：加载应用程序和程序员自定义的类。

# 类的加载机制：加载（内存中生成class对象）， 链接（验证 准备 解析）， 初始化

类被加载到虚拟机内存包括加载、链接、初始化几个阶段。其中链接又细化分为验证、准备、解析。

这里需要注意的是，解析阶段在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的运行时绑定。

各个阶段的作用整理如下：

# 加载阶段

加载阶段可以使用系统提供的类加载器(ClassLoader)来完成，也可以由用户自定义的类加载器完成，开发人员可以通过定义类加载器去控制字节流的获取方式。

ps：可以自定义类加载器，从加密和安全两个角度出发来加载特殊的类。具体参考[自定义类加载器](http://www.cnblogs.com/lixuwu/p/8492322.html) 

（1）通过类的全名产生对应类的二进制数据流。

（2）将这些二进制数据流转换为方法区的运行时数据结构。

（3）创建代表这个类的java.lang.Class对象。作为方法区这些数据的访问入口。

# 链接阶段（实现 Java 的动态性的重要一步）

（1）验证：验证阶段的主要目的是确保class文件字节流的正确性，要验证比如class文件格式规范、这个类是否继承了final类、不能把一个父类对象赋值给子类数据类型等等。

（2）准备：准备阶段为方法区中的静态变量分配内存空间。并将其赋值为初始值，所有原始类型的值都为0。如float为0f、 int为0、boolean为0、引用类型为null。

（3）解析：解析阶段把符号引用解析为直接引用。

符号引用是一个字符串，它唯一标识一个类、一个字段、一个方法等目标。

而直接引用对于类变量、类方法指的是指向方法区的指针，然后对于实例方法、实例对象来说就是偏移量，比如一个实例方法，子类中方法表中的偏移量和父类是一致的，这个偏移量可以确定某个方法的位置。

# 初始化

到了初始化阶段，才是真正执行用户定义的程序代码。在初始化阶段就是执行类构造器方法的过程，工作包括赋值类变量、静态语句块的合并。

//定义在静态语句块之后的变量可以赋值，但不能访问

public class Test{

  static{ 

​    i=0;//給变量赋值，可以通过编译

​    System.out.print(i);//这句编译器会提示非法向前引用

  }

  static int i=1;

}

初始化过程会被触发的条件汇总：

（1）使用new关键字实例化对象、访问一个类的静态字段、静态方法的时候。

（2）对类进行反射调用的时候。

（3）当初始化子类时，如果发现其父类还没有进行过初始化，则进行父类的初始化。

 

【关于构造器方法拓展知识】（可以不看）

（1）类构造器<clinit>()方法与类的构造函数不同，它不需要显式调用父类构造，虚拟机会保证在子类<clinit>()方法执行之前，父类的<clinit>()方法已经执行完毕。因此在虚拟机中的第一个执行的<clinit>()方法的类肯定是java.lang.Object。

（2）由于父类的<clinit>()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。

（3）<clinit>()方法不是必须的，如果一个类中没有静态语句，那么编译器可以不为这个类生成<clinit>()方法。

（4）接口中不能使用静态语句块，和类不同的是，执行接口的<clinit>()方法不需要先执行父接口的<clinit>()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的<clinit>()方法。

（5）虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确加锁和同步，可能会导致阻塞。

 

# 类加载的三种方式

（1）由 new 关键字创建一个类的实例。

（2）调用 Class.forName() 方法，通过反射加载类。

（3）调用某个ClassLoader实例的loadClass()方法。

三者的区别汇总如下：

（1）方法1和2都是使用的当前类加载器。方法3是由用户指定的类加载器加载。

（2）方法1是静态加载，2、3是动态加载。

（3）对于两种动态加载，如果程序需要类被初始化，就必须使用Class.forName(name)的方式。

```
Class.forName(className);
//实际上是调用的是：
Class.forName(className, true, this.getClass().getClassLoader());//第二个参为true即默认类需要初始化，初始化会触发目标对象静态块的执行和静态变量的初始化
```

 ClassLoader.loadClass(className);

```
//实际上调用的是:
ClassLoader.loadClass(name, false);//第二个参数即默认得到的class还没有进行链接，意味着不进行初始化等系列操作，即静态代码块不会执行
```

# JVM里的有几种ClassLoader，为什么会有多种？

​    类加载器作用是通过类名来获取二进制字节流。主要分为四种加载器，启动类->扩展类->应用类->自定义类。BootStrap ClassLoader，负责加载<JAVA_HOME>/lib或被-Xbootclasspath指定路径下的类库，开发者不可以直接使用。Extension ClassLoader,负责加载<JAVA_HOME>/lib/ext或被java.ext.dirs系统变量指定的路径中的所有类库，开发者可以直接使用。App ClassLoader，这个类加载器是ClassLoader.getSystemClassLoader()的返回值，负责加载用户类路径上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序没有自定义类加载器，那么系统默认使用这个类加载器。因为他们代表几种不同的信任级别：最可信的级别是java核心API类。然后是安装的拓展类，最后才是在类路径中的类。

\* 多种类加载器待办可以同时加载多个应用程序（一个加载服务，另外的加载器用来服务器内部的部署）。

\* 每种加载器都有对应的层级来加载某些特定（同名）的类，来保证他们之间的安全性。

举例：同一个Tomcat部署多个项目应用，可能使用相同的库，但是不同版本，如果用同一个类加载器去加载，就会造成两个应用类的覆盖。

# 什么是双亲委派机制？介绍一些运作过程，双亲委派模型的好处；

​    双新委派机制：先在启动类加载器找，找不到再到扩展类加载器找，找不到再到应用程序类加载器找，找不到就从自己定义的类；由下到上加载，顶层加载不了再交给下层加载，如果回到底层位置加载 还加载不到，那就会报ClassNotFound错误了。“委托机制” 是指先从父类开始找：这是从安全角度出发，因为怕有人恶意编写类（例如java.lang.String）并且装载到JVM中，那会有多么可怕的后果，但是有了“全盘负责委托机制”，java.lang.String永远是由跟装载器来加载，这就避免了上述事件的发生。双亲委派机制的好处，就是保证类加载的优先级层次顺序，防止核心API库被随意篡改，越基础的类交给越高级的加载器加载。

# 双亲委派模型的工作过程如下：

(1）当前类加载器从自己已经加载的类中查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。

（2）如果没有找到，就去委托父类加载器去加载（如代码c = parent.loadClass(name, false)所示）。父类加载器也会采用同样的策略，查看自己已经加载过的类中是否包含这个类，有就返回，没有就委托父类的父类去加载，一直到启动类加载器。因为如果父加载器为空了，就代表使用启动类加载器作为父加载器去加载。

（3）如果启动类加载器加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用拓展类加载器来尝试加载，继续失败则会使用AppClassLoader来加载，继续失败则会抛出一个异常ClassNotFoundException，然后再调用当前加载器的findClass()方法进行加载。

双亲委派模型的好处：

（1）主要是为了安全性，避免用户自己编写的类动态替换 Java的一些核心类，比如 String。

（2）同时也避免了类的重复加载，因为 JVM中区分不同类，不仅仅是根据类名，相同的 class文件被不同的 ClassLoader加载就是不同的两个类。

# 双亲委派模型，动态代理原理

**(1)****什么是代理？**

代理这种设计模式是通过不直接访问被代理对象的方式，而访问被代理对象的方法。这个就好比 商户---->明星经纪人(代理)---->明星这种模式。我们可以不通过直接与明星对话的情况下，而通过明星经纪人(代理)与其产生间接对话。

**(2)****什么情况下使用代理？**

​      设计模式中有一个设计原则是开闭原则，是说对修改关闭对扩展开放，我们在工作中有时会接手很多前人的代码，里面代码逻辑让人摸不着头脑，这时就很难去下手修改代码，那么这时我们就可以通过代理对类进行增强。Spring的AOP机制就是采用动态代理的机制来实现切面编程。

**(3)****静态代理和动态代理**

​      我们根据加载被代理类的时机不同，将代理分为静态代理和动态代理。如果我们在代码编译时就确定了被代理的类是哪一个，那么就可以直接使用静态代理；如果不能确定，那么可以使用类的动态加载机制，在代码运行期间加载被代理的类这就是动态代理，比如RPC框架和Spring AOP机制。

​      静态代理是实现被代理的接口类，并在代理类中引入了被代理类的对象，在重写接口的方法上进行增强。

​      动态代理的实现代码，涉及到java反射包下的InvocationHandler接口和Proxy类。InvocationHandler这个方法委托接口类只有一个invoke方法，我们在通过代理类调用被代理类的方法时，最终都会委托给这个invoke方法执行，所以我们就可以在这个invoke方法中对被代理类进行增强或做一些其他操作。而Proxy类的public static Object newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h)方法内部通过拼接字节码的方式来创建代理类。

# 什么情况下我们需要破坏双亲委派模型；

### 情况一：JDBC为什么要破坏双亲委派模型

​      因为类加载器受到加载范围的限制，在某些情况下父类加载器无法加载到需要的文件，这时候就需要委托子类加载器去加载class文件。

​      JDBC的Driver接口定义在JDK中，其实现由各个数据库的服务商来提供，比如MySQL驱动包。DriverManager 类中要加载各个实现了Driver接口的类，然后进行管理，但是DriverManager位于 $JAVA_HOME中jre/lib/rt.jar 包，由BootStrap类加载器加载，而其Driver接口的实现类是位于服务商提供的 Jar 包，**根据类加载机制，当被装载的类引用了另外一个类的时候，虚拟机就会使用装载第一个类的类装载器装载被引用的类。**也就是说BootStrap类加载器还要去加载jar包中的Driver接口的实现类。我们知道，BootStrap类加载器默认只负责加载 $JAVA_HOME中jre/lib/rt.jar 里所有的class，所以需要由子类加载器去加载Driver实现，这就破坏了双亲委派模型。

### 情况二：Tomcat为什么要破坏双亲委派模型

**每个****Tomcat****的****webappClassLoader****加载自己的目录下的****class****文件，不会传递给父类加载器。**

事实上，tomcat之所以造了一堆自己的classloader，大致是出于下面三类目的：

·    对于各个 `webapp`中的 `class`和 `lib`，需要相互隔离，不能出现一个应用中加载的类库会影响另一个应用的情况，而对于许多应用，需要有共享的lib以便不浪费资源。

·    与 `jvm`一样的安全性问题。使用单独的 `classloader`去装载 `tomcat`自身的类库，以免其他恶意或无意的破坏；

·    热部署。相信大家一定为 `tomcat`修改文件不用重启就自动重新装载类库而惊叹吧。

# 为什么需要自定义类加载器（自定义类的应用场景）

（1）加密：Java代码可以轻易的被[反编译](https://www.baidu.com/s?wd=反编译&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHcvrjTdrH00T1d9rj6Yuhn3n1b3uWwBn1wb0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EP1R1rjD3njnzPWc1n1RdPW6Y)，如果你需要把自己的代码进行加密以防止反编译，可以先将编译后的代码用某种加密算法加密，类加密后就不能再用Java的ClassLoader去加载类了，这时就需要自定义ClassLoader在加载类的时候先解密类，然后再加载。

（2）从非标准的来源加载代码：如果你的字节码是放在数据库、甚至是在云端，就可以自定义类加载器，从指定的来源加载类。

（3）以上两种情况在实际中的综合运用：比如你的应用需要通过网络来传输 Java 类的字节码，为了安全性，这些字节码经过了加密处理。这个时候你就需要自定义类加载器来从某个网络地址上读取加密后的字节代码，接着进行解密和验证，最后定义出在Java虚拟机中运行的类。

# 自定义类加载器

（1）从上面源码看出，调用loadClass时会先根据委派模型在父加载器中加载，如果加载失败，则会调用当前加载器的findClass来完成加载。（ps：在所有加载器找不到的情况下，就会调用用户自定义的类加载器来加载）

（2）因此我们自定义的类加载器只需要继承ClassLoader，并覆盖findClass方法，下面是一个实际例子，在该例中我们用自定义的类加载器去加载我们事先准备好的class文件。

自定义一个类加载器，需要继承ClassLoader类，并实现findClass方法。其中defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class（只要二进制字节流的内容符合Class文件规范）。

# 集合框架常见的有哪些

**Collection**(单列集合)

   -- List 1. 有序(存取有序) 2. 有索引  3. 可重复

​       \- ArrayList  数组

​       \- LinkedList 链表

​       \- Vector    数组 JDK1.0产物 已经被ArrayList取代，线程安全，效率低下

   -- Set 1. 无序(存取无序) 2. 无索引  3. 不可重复

​      \- HashSet  哈希算法(去重)

​      \- TreeSet   红黑树(去重并排序)

​     \- LinkedHashSet （去重，但是怎么存，就怎么取 ,有以一批量的数据，有重复元素，又不想打乱现有的顺序 ) 

​         

 **Map**(双列集合)

​     \- HashMap  哈希算法(去重)

​     \- TreeMap  红黑树(去重并排序)

​     \- Hashtable Hashtable的命运和Vector雷同！他们都是线程安全的，jdk1.0的产物

​             Hashtable不能存储null键null值；线程安全

​             HashMap可以存储null键null值；线程不安全，HashMap已经全面的取代了Hashtable;

​    \- Properties  可以与IO流技术结合使用

  1.TreeSet如何去重并排序？
   2.HashMap的底层去重和存储原理？
   3.Collections工具类的简单运用？
   4.HashMap与Hashtable的区别？
   5.数组，链表操作元素的原理？
   6.浅谈hash底层算法？
   7.二叉树的原理？

# List 和 Map 区别

List特点：元素有放bai入du顺序，元素可重复zhi

Map特点：元素按键值对存储，无放入顺序

Set特点：元素无放入顺序，元素不可重复（注意：元素虽然无放入顺序，但是元素在set中的位置是有该元素的HashCode决定的，其位置其实是固定的）

# ArrayList 与 Vector 区别；

一. 同步性: Vector是线程安全的，也就是说是同步的，而ArrayList是线程序不安全的，不是同步的 

二. 数据增长: 当需要增长时，Vector默认增长为原来一倍，而ArrayList却是原来的一半

# ArrayList和LinkedList的内部实现

ArrayList是实现了基于动态数组结构，实现了RandomAccess接口，因此对元素的随机访问速度非常快，因为是数组，所以ArrayList在初始化的时候，有初始大小10，插入新元素的时候会判断是否需要扩容，扩容的步长是0.5倍原容量，扩容方式是利用数组的复制，因此有一定的开销，另外，ArrayList在进行元素插入的时候，需要移动插入位置之后的所有元素，位置越靠前，需要位移的元素越多，开销越大，相反，插入位置越靠后的话，开销就越小了，如果在最后面进行插入，那就不需要进行位移。

LinkedList 底层的数据结构是基于双向循环链表，LinkedList有一个内部类作为存放元素的单元（节点），里面有三个属性，中间用来存放元素本身的业务数据以及前后2个单元的引用(位置信息)。另外LinkedList内部还有一个header属性（头节点中不存放数据）用来标识起始位置，LinkedList的第一个单元和最后一个单元都会指向header，因此形成了一个双向的链表结构LinkedList的元素并不需要连续存放，但是每个存放元素的单元比元素本身需要更大的空间，LinkedList对空间的要求比较大，但是扩容的时候不需要进行数组复制，因此没有这一环节的开销但是，LinkedList的随机访问速度惨不忍睹，因为无论你要访问哪一个元素，都需要从header起步正向或反向的进行元素遍历。

​    由此可见，ArrayList适合需要大量进行随机访问或者对靠近集合中尾部的元素进行增删的场景；而LinkedList则适合对靠近集合首部的元素进行增删的场景。

# ArrayList扩容过程，与LinkedList区别

ArrayList 底层会新生成一个数组，在JDK1.7中扩容规则长度为原数组的 1.5 倍（扩容后的大小= 原始大小+原始大小/2），然后将原数组的内容复制到新数组当中，并且后续增加的内容都会放到新数组当中。当新数组无法容纳增加的元素时，重复该过程。扩容数组调用的方法Arrays.copyOf(objArr, objArr.length + 1);

LinkedList的扩容机制：由于它的底层是用双向链表实现的，没有初始化大小，也没有扩容的机制。

# 哈希表（散列表）

​    在讨论哈希表之前，我们先大概了解下其他数据结构在新增，查找等基础操作执行性能：

​    **数组**：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)

　　**线性链表**：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)

　　**二叉树**：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。

　　**哈希表**：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。

　　我们知道，数据结构的物理存储结构只有两种：**顺序****存储结构**和**链式****存储结构**（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中还是这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，**哈希表的主干就是****数组**。

　　比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。

　　　　　　　　**存储位置** **= f(****关键字****)**

其中，这个函数f一般称为**哈希函数**，这个函数的设计好坏会直接影响到哈希表的优劣。

查找操作同理，先通过哈希函数计算出实际存储地址，然后从数组中对应地址取出即可。

​    **哈希冲突**

　　如果两个不同的元素，通过哈希函数得出的实际存储地址相同，即当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的**哈希冲突**，也叫哈希碰撞。哈希函数的设计至关重要，好的哈希函数会尽可能地保证 **计算简单**和**散列地址分布均匀。**但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是**数组****+****链表**的方式。

# HashTable HashMap ConcurrentHashMap的区别、数据结构、线程安全

一. 历史原因:Hashtable是基于陈旧的Dictionary类的，HashMap是Java 1.2引进的Map接口的实现 

二. 同步性:Hashtable是线程安全的，也就是说是同步的（简单粗暴，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把**大锁**，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作**串行化**，在竞争激烈的并发场景中性能就会非常差）；而HashMap是线程序不安全的，不是同步的 

三. 值：只有HashMap可以让你将空值作为一个表的条目的key或value

四. 而JDK1.7的ConcurrentHashMap的主干是个Segment数组，采用的"**分段锁**"思想，在容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。Segment继承了ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在ConcurrentHashMap，一个Segment就是一个子哈希表，Segment里维护了一个HashEntry数组，并发环境下，对于不同Segment的数据进行操作是不用考虑锁竞争的。（就按默认的ConcurrentLeve为16来讲，理论上就允许16个线程并发执行）所以，对于同一个Segment的操作才需考虑线程同步，不同的Segment则无需考虑。Segment类似于HashMap，一个Segment维护着一个HashEntry数组。

# HashMap内部的数据结构是什么？底层是怎么实现的？

// 还可能会延伸考察ConcurrentHashMap与HashMap、HashTable等，考察对技术细节的深入了解程度

Jdk7中hashMap采用数组+链表。Jdk8中hashMap采用数组+链表/红黑树。

​    如果多个hashCode()的值落到同一个桶内的时候，这些值是存储到一个链表中的。最坏的情况下，所有的key都映射到同一个桶中，这样hashmap就退化成了一个链表——查找时间从O(1)到O(n)。 随着HashMap的大小的增长，get()方法的开销也越来越大。由于所有的记录都在同一个桶里的超长链表内，平均查询一条记录就需要遍历一半的列表。

**JDK1.8HashMap****的红黑树是这样解决的**：

​    **如果某个桶中的记录过大的话（当前是TREEIFY_THRESHOLD =** **8****），HashMap会动态的使用一个专门的****TreeNode****实现来替换掉它。这样做的结果会更好，是****O(logn)****，而不是糟糕的****O(n)****。**

但是超过这个阈值后HashMap开始将列表升级成一个二叉树，**使用哈希值作为树的分支变量，如果两个哈希值不等，但指向同一个桶的话，较大的那个会插入到右子树里。如果哈希值相等，HashMap希望key值最好是实现了Comparable接口的，这样它可以按照顺序来进行插入**。

​    /**     * Entry for Tree bins.  Extends LinkedHashMap.Entry (which in turn     * extends Node) so can be  used as extension of either regular or     * linked node.     */    **static** **final** **class** TreeNode<K,V> **extends**  LinkedHashMap.Entry<K,V> {      TreeNode<K,V> parent; // red-black  tree links      TreeNode<K,V> left;      TreeNode<K,V> right;      TreeNode<K,V> prev;  // needed to  unlink next upon deletion      **boolean** red;    }  

# HashMap红黑树的实现原理和应用场景

Java 8之前，HashMap 底层的数据结构是数组+链表实现的， Java 8之后是数组+链表+红黑树实现的，当链表的长度超过8(树化阈值)之后，会转换成红黑树。作用：解决因哈希冲突导致的链表过长，查询效率低的问题。

# JDK1.8中对Hashmap做了哪些改动

- 默认初始化容量=0
- 引入红黑树，优化数据结构
- 将链表头插法改为尾插法，解决1.7中多线程循环链表的bug
- 优化hash算法
- resize计算索引位置的算法改进
- 先插入后扩容

# HashMap和ConcurrentHashMap的内部实现

​    Java8将HashMap原来的数组+链表的结构优化成了数组+链表+红黑树的结构，减少了hash碰撞造成的链表长度过长，时间复杂度过高的问题。Java8也改进了Concurrenthashmap在jdk1.7中是采用Segment + ReentrantLock + HashEntry的分段锁臃肿的方式，采用**transient** **volatile** Node<K,V>[] table; Synchronized + CAS + 数组 + Node链表 + 红黑树来保证并发安全进行实现保存数据，其数据结构已经接近HashMap。

l  红黑树：是一种自平衡二叉查找树，是一种数据结构，典型的用途是实现关联数组，存储有序的数据。将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。

l  红黑树的约束:

Ø  根节点是黑色的，节点可以是红色的或者黑色的。

Ø  叶子节点(特指空节点)是黑色的。

Ø  每个红色节点的子节点都是黑色的。

Ø  任何一个节点到其每一个叶子节点的所有路径上黑色节点数相同。

l  红黑树的特点: 速度特别快，趋近平衡树，查找叶子元素最少和最多次数不多于二倍。

l  红默树的时间复杂度是O(logn)以2为底的对数每次查找范围减少一半，而链表是糟糕的O(n)

![img](http://image.itstabber.com/2020-09-10/clip_image033.png)

​      JDK1.7版本的ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶HashBucket。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。每个Segment守护者一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。相比于对整个Map加锁的设计，分段锁大大的提高了高并发环境下的处理能力。但同时，由于不是对整个Map加锁，导致一些需要扫描整个Map的方法（如size(), containsValue()）需要使用特殊的实现，另外一些方法（如clear()）甚至放弃了对一致性的要求（ConcurrentHashMap是弱一致性的）。

​      \1. 在使用锁来协调多线程间并发访问的模式下，减小对锁的竞争可以有效提高并发性。有两种方式可以减小对锁的竞争：

​           减小请求同一个锁的频率

​           减少持有锁的时间

​      \2. ConcurrentHashMap 的高并发性主要来自于三个方面：

​           使用分离锁减小了请求同一个锁的频率，实现多个线程间的更深层次的共享访问。

​           用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。

​           通过对同一个Volatile变量的写/读访问，协调不同线程间读/写操作的内存可见性。

**总结**

​    其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。

​    1.数据结构：取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。

​    2.保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。

​    3.锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。

​    4.链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8(树化阈值)时，会将链表转化为红黑树进行存储。

​    5.查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。

# 为何HashMap的数组长度一定是2的次幂？

**“****取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是length是2的n次方；）。”** 并且 **采用二进制位操作&，相对于%能够提高运算效率****。**

 

// 我们的数组索引位置的计算是通过对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置：

![https://images2015.cnblogs.com/blog/1024555/201611/1024555-20161115133556388-1098209938.png](http://image.itstabber.com/2020-09-10/clip_image034.png)

![img](http://image.itstabber.com/2020-09-10/clip_image035.png)

// hash()函数用了很多的异或、移位等运算，对key的hashcode进一步**按位与的散列算法**来保证最终获取存储主数组的index位置尽量分布均匀

// 以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置

​      indexFor()方法h&(length-1);保证获取的index一定在数组范围内。例如，默认容量16，length-1=15，h=18,转换成二进制计算为：

```
        1  0  0  1  0
    &   0  1  1  1  1
        0  0  0  1  0  = 2
```

最终计算出的index=2。有些版本的对于此处的计算会使用取模运算，也能保证index一定在数组范围内，不过位运算对计算机来说，性能更高一些（HashMap中有大量位运算）。

​      key.hashCode();

​      int h = rehash(key); // 元素key的hashCode进行一次再哈希

 在按位与的场景下，只要低4位相同，则总会获取相同的位置下标。rehash就是为了消除这种较高冲突的可能，根据某种算法，打乱低4位，最终得到不同的位置下标。当然，如果两个h一样，那是肯定会分配到相同的位置下标的。

   通过以上得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。

// 如果数组进行扩容，数组长度发生变化，而存储位置 index = h&(length-1),index也可能会发生变化，需要重新计算index

```
void` `resize(``int` `newCapacity){}
```

// transfer()方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中。

```
void` `transfer(Entry[] newTable, ``boolean` `rehash) {}
```

hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。

![img](http://image.itstabber.com/2020-09-10/clip_image036.png)

 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如：

![img](http://image.itstabber.com/2020-09-10/clip_image037.png)

　　我们看到，上面的&运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。

![img](http://image.itstabber.com/2020-09-10/clip_image038.png)

如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。

# Hashmap中resize()过程

JDK1.8版本中扩容相对复杂。在1.7版本中，重新根据hash计算索引位置即可；而在1.8版本中分2种情况，下边用图例来解释。

![img](http://image.itstabber.com/2020-09-10/clip_image039.png)

 

![img](http://image.itstabber.com/2020-09-10/clip_image040.png)

其余还有为什么阈值=8转红黑树，长度<=6 转链表这些问题。基本都是数据科学家根据概率做出的经验值，同时避免数据结构频繁的转换引起的性能开销。

# ConcurrentHashMap怎么做扩容rehash数据重整的

​    现由于添加新元素，进行rehash操作。相对于HashMap的resize，ConcurrentHashMap的rehash原理类似，但是Doug Lea为rehash做了一定的优化，避免让所有的节点都进行复制操作：由于扩容是基于2的幂指来操作，假设扩容前某HashEntry对应到Segment中数组的index为i，数组的容量为capacity，那么扩容后该HashEntry对应到新数组中的index只可能为i或者i+capacity，因此大多数HashEntry节点在扩容前后index可以保持不变。基于此，rehash方法中会定位第一个后续所有节点在扩容后index都保持不变的节点，然后将这个节点之前的所有节点重排即可。

# ConcurrentHashMap怎么count过程，除了最简单的加锁

```
// 该属性保存着整个哈希表中存储的所有的结点的个数总和，有点类似于 HashMap 的 size 属性
```

  /**

   \* Base counter value, used mainly when there is no contention,

   \* but also as a fallback during table initialization

   \* races. Updated via CAS.

   */

  **private** **transient** **volatile** **long** baseCount;

  /**

   \* Table initialization and resizing control. When negative, the

   \* table is being initialized or resized: -1 for initialization,

   \* else -(1 + the number of active resizing threads). Otherwise,

   \* when table is null, holds the initial table size to use upon

   \* creation, or 0 for default. After initialization, holds the

   \* next element count value upon which to resize the table.

   */

**private** **transient** **volatile** **int** sizeCtl;

# HashMap链表转红黑树，再回转链表的关键属性条件

```
  /** 创建HashMap时未指定初始容量情况下的默认容量
```

   \* The default initial capacity - MUST be a power of two.

   */

  **static** **final** **int** ***DEFAULT_INITIAL_CAPACITY\*** = 1 << 4; // aka 16

 

```
    /** HashMap的最大容量
```

   \* The maximum capacity, used if a higher value is implicitly specified

   \* by either of the constructors with arguments.

   \* MUST be a power of two <= 1<<30.

   */

  **static** **final** **int** ***MAXIMUM_CAPACITY\*** = 1 << 30;

 

```
    /** HashMap默认的装载因子，当HashMap中元素数量超过 容量*装载因子 时，则进行resize()扩容操作
```

   \* The load factor used when none specified in constructor.

   */

  **static** **final** **float** ***DEFAULT_LOAD_FACTOR\*** = 0.75f;

 

```
    /** 用来确定何时解决hash冲突的，链表转为红黑树
```

   \* The bin count threshold for using a tree rather than list for a

   \* bin. Bins are converted to trees when adding an element to a

   \* bin with at least this many nodes. The value must be greater

   \* than 2 and should be at least 8 to mesh with assumptions in

   \* tree removal about conversion back to plain bins upon

   \* shrinkage.

   */

  **static** **final** **int** ***TREEIFY_THRESHOLD\*** = 8;

 

```
    /** 用来确定何时解决hash冲突的，红黑树转变为链表
```

   \* The bin count threshold for untreeifying a (split) bin during a

   \* resize operation. Should be less than TREEIFY_THRESHOLD, and at

   \* most 6 to mesh with shrinkage detection under removal.

   */

  **static** **final** **int** ***UNTREEIFY_THRESHOLD\*** = 6;

 

```
/** 当想要将解决hash冲突的链表转变为红黑树时，需要判断下此时数组的容量，
 *  若是由于数组容量太小（小于MIN_TREEIFY_CAPACITY）而导致hash冲突，则不进行链表转为红黑树的操作，而是利用resize()函数对HashMap扩容
```

   \* The smallest table capacity for which bins may be treeified.

   \* (Otherwise the table is resized if too many nodes in a bin.)

   \* Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts

   \* between resizing and treeification thresholds.

   */

**static** **final** **int** ***MIN_TREEIFY_CAPACITY\*** = 64;

# Hashtable跟HashMap的区别

**1****、产生时间**

Hashtable是Java一开始发布时就提供的键值映射的数据结构，而HashMap产生于JDK1.2。

**2** **继承的父类不同**

HashMap和Hashtable不仅作者不同，而且连父类也是不一样的。HashMap是继承自AbstractMap类，而HashTable是继承自Dictionary类。不过它们都实现了同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口

**3****、对Null key 和Null value的支持不同**

·    Hashtable既不支持Null key也不支持Null value；

·    HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。

**4****、线程安全和效率不同**

 

**5****、遍历方式的内部实现上不同**

HashMap的Iterator迭代器是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。

**6****、初始容量大小和每次扩充容量大小的不同**

Hashtable默认初始大小为11，之后每次扩充容量变为原来的2n+1。HashMap默认初始化大小为16，之后每次扩充容量变为原来的2倍。

# HashMap的get方法的过程

// HashMap::get返回一个数据节点, 如果不存在则返回空;

\1. 调用hash()方法获取到key的hash值

\2. 调用getNode()方法通过key和hash获取对应的value。不存在则返回null

核心方法是getNode()方法，下面我会先分析一下getNode()方法。

   ```java
public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
}

    final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
            // 先比较hashcode，再比较equals方法
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                do {
                    // 先比较hashcode，再比较equals方法
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }

   ```



1 通过 hash & (table.length - 1)获取该key对应的数据节点的hash槽;

2 判断首节点是否为空, 为空则直接返回空;

3 再判断首节点key是否和目标值相同，相同则直接返回(首节点不用区分链表还是红黑树);

4 首节点next为空, 则直接返回空;

5 首节点是树形节点, 若是则进入红黑树数的取值流程, 并返回结果;

6 否则进入链表的取值流程, 遍历链表，检索`key`和`hash`与入参相同的节点，若找到则返回该节点，否则返回`null`。

# equals和==区别， 重写equals一定要重写hashcode方法吗？为什么？hashcode方法有什么作用?

  对于基本类型来说，==比较两个基本类型的值是否相等，对于引用类型来说，==比较的是内个引用类型的内存地址。

   Object类中的equals方法和“==”是一样的，没有区别，即俩个对象的比较是比较他们的栈内存中存储的内存地址。而String类，Integer类等等一些类，是重写了equals方法，才使得equals和“==不同”，他们比较的是值是不是相等。所以，当自己创建类时，自动继承了Object的equals方法，要想实现不同的等于比较，必须重写equals方法。

​    equals说明: equals用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object类的，所以适用于所有对象，如果没有对该方法进行覆盖的话，调用的仍然是Object类中的方法，而Object中的equals方法返回的却是==的判断。

   重写equals一般是要重写hashcode方法的，首先equals与hashcode间的关系是这样的：

   1、如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同；

   2、如果两个对象的hashCode相同，它们并不一定相同(即用equals比较返回false)  

   比如说两个字符串的hashcode相同，但是这两个字符串可以是不同的字符串，对象也是同理，自己理解的。

   至于hashcode有什么用？

   为了提高程序的效率才实现了hashcode方法，先进行hashcode的比较，如果不同，那没就不必在进行equals的比较了，这样就大大减少了equals比较的次数，这对比需要比较的数量很大的效率提高是很明显的，一个很好的例子就是在集合中的使用；

# 重写equal为什么一定也要同时重写hashcode？

**1.equals()****的所属以及内部原理（即Object中equals方法的实现原理）**

public boolean equals(Object obj) {  return (this == obj);   }

在Object类中这个方法实际上是判断两个对象是否具有相同的引用，如果有，它们就一定相等。

实际上我们知道所有的对象都拥有标识(内存地址)和状态(数据)，同时“==”比较两个对象的的内存地址，所以说 Object 的 equals() 方法是比较两个对象的内存地址是否相等，即若 object1.equals(object2) 为 true，则表示 object1和 object2实际上是引用同一个对象。

**2.equals()****与‘==’的区别**

默认情况下也就是从超类Object继承而来的equals方法与‘==’是完全等价的，比较的都是对象的内存地址，但我们可以重写equals方法，使其按照我们的需求的方式进行比较，如String类重写了equals方法，使其比较的是字符的序列，而不再是内存地址。

**3.equals()****的重写规则**

· 自反性：对于任何非null的引用值x，x.equals(x)应返回true。

· 对称性：对于任何非null的引用值x与y，当且仅当：y.equals(x)返回true时，x.equals(y)才返回true。

· 传递性：对于任何非null的引用值x、y与z，如果y.equals(x)返回true，y.equals(z)返回true，那么x.equals(z)也应返回true。

· 一致性：对于任何非null的引用值x与y，假设对象上equals比较中的信息没有被修改，则多次调用x.equals(y)始终返回true或者false。

· 非空性：对于任何非空引用值x，x.equal(null)应返回false。

**4.****为什么重写equals()的同时还得重写hashCode()**

​    hashCode的意思就是散列码，也就是哈希码，是由对象导出的一个整型值。在java中，我们可以使用hashCode()来获取对象的哈希码，其值就是对象的存储地址，这个方法在Object类中声明，因此所有的子类都含有该方法。

​      这个问题主要是针对Map接口映射相关的操作，Map接口的类会使用到键对象的哈希码，当我们调用put方法或者get方法对Map容器进行操作时，都是根据键对象的哈希码来计算存储位置的，因此如果我们对哈希码的获取没有相关保证，就会造成哈希冲突，降低Map的访问效率。

​      在Java API文档中关于hashCode方法有以下几点规定：

·    在java应用程序执行期间，如果在equals方法比较中所用的信息没有被修改，那么在同一个对象上多次调用hashCode方法时必须一致地返回相同的整数。如果多次执行同一个应用时，不要求该整数必须相同。

·    如果两个对象通过调用equals方法是相等的，那么这两个对象调用hashCode方法必须返回相同的整数。

·    如果两个对象通过调用equals方法是不相等的，不要求这两个对象调用hashCode方法必须返回不同的整数。但是程序员应该意识到对不同的对象产生不同的hash值可以提供哈希表的性能。

​      通过前面的分析，我们知道在Object类中，hashCode方法是通过Object对象的地址计算出来的，因为Object对象只与自身相等，所以同一个对象的地址总是相等的，计算取得的哈希码也必然相等，对于不同的对象，由于地址不同，所获取的哈希码自然也不会相等。因此到这里我们就明白了，如果一个类重写了equals方法，但没有重写hashCode方法，将会直接违法了第2条规定，这样的话，如果我们通过映射表(Map接口)操作相关对象时，就无法达到我们预期想要的效果。

**5.****重写equals()中getClass与instanceof的区别**

​      在重写equals() 方法时，一般都是推荐使用 getClass 来进行类型判断（除非所有的子类有统一的语义才使用instanceof），不是使用 instanceof。instanceof 的作用是判断其左边对象是否为其右边类的实例，返回 boolean 类型的数据。可以用来判断继承中的子类的实例是否为父类的实现。

**6.****编写一个完美equals()的几点建议**

1）显式参数命名为otherObject，稍后需要将它转换成另一个叫做other的变量（参数名命名，强制转换请参考建议5）

2）检测this与otherObject是否引用同一个对象 ：if(this == otherObject) return true;（存储地址相同，肯定是同个对象，直接返回true）

3) 检测otherObject是否为null，如果为null，返回false。if(otherObject == null) return false;

4) 比较this与otherObject是否属于同一个类 （视需求而选择）

·    如果equals的语义在每个子类中有所改变，就使用getClass检测 ：if(getClass()!=otherObject.getClass()) return false;

·    如果所有的子类都拥有统一的语义，就使用instanceof检测 ：if(!(otherObject instanceof ClassName)) return false;

5) 将otherObject转换为相应类的类型变量：ClassName other = (ClassName) otherObject;

6) 现在开始对所有需要比较的域进行比较 。使用==比较基本类型域，使用equals比较对象域。若所有的域都匹配，就返回true，否则flase。

·    如果在子类中重新定义equals，就要在其中包含调用super.equals(other)

·    当此方法被重写时，通常有必要重写 hashCode 方法，以维护 hashCode 方法的常规协定：相等对象必须具有相等的哈希码。

# hashcode和equals过程？

   在大多数编程实践中，归根结底会落实到数据的存取问题上。Java 以面向对象为核心思想，把数据按照一定的数据结构保存到存储单元（容器类）中，根据不同的数据结构封装提供了丰富的操作数据的API，降低了数据操作的复杂度。其中Map 和 Set 的绝大多数实现类的底层都会用到散列表结构，它们是**不允许重复**的**散列表结构****，**这些容器在存储元素的时必须对元素做出判断：**在当前的容器中有没有和新元素相同的元素？用****equals()** **会有力不从心的时候（**要调用容器中所有对象的 equals() 方法和新元素进行比较，时间复杂度为 O(n)**），而****hashCode()** **小力出奇迹（****两个相同的对象，****hashCode()** **一定相同****：运用** **hashCode()** **判断是否有相同元素的代价，只是一次哈希计算能定位存放的位置，时间复杂度为****O(1)****，若已存在再与新元素调用****1****次****equals****方法****）。**

hashcode和equals二者的关系：

1、如果两个对象equals，Java运行时环境会认为他们的hashcode一定相等。

2、如果两个对象不equals，他们的hashcode有可能相等。

3、如果两个对象hashcode相等，他们不一定equals。

4、如果两个对象hashcode不相等，他们一定不equals。

​    hashcode的作用主要体现在哈希表结构中，如果hashCode()每次都返回相同的数，这种极端冲突会将哈希表退化为链表，那么所有的对象都会被放到同一个bucket中，每次执行查找操作都会遍历链表，这样也就完全失去了哈希的作用。

# final类事务是怎样的

**关键字、修饰符修饰数据、方法、类**

**1.** **最终值**

·    当final修饰基本类型数据时，保证值不能改变

·    当final修饰引用类型数据时，地址值不能改变

·    当final修饰成员变量，保证对象创建完成之前（可以在构造函数中）给值

·    当final修饰静态变量（静态常量）时，保证类加载完成之前给值

**2.** **最终方法**   支持重载，不支持重写

**3.** **最终类**    可以继承别的类，但是不能被别的类继承

​    使用final显示的声明变量是一个非常良好的编码习惯，因为java会对final修饰的变量进行内联，提高代码的性能。可以利用final关键字的同步作用，构建一个线程安全（可在线程之间共享）的类。final能够做出如下保证：当你创建一个对象时，使用final关键字能够使得另一个线程不会访问到处于“部分创建”的对象，否则是会可能发生的。这是因为，当用作对象的一个属性时，final有着如下的语义：

用来保证对象的安全发布（初始化），防止对象引用被其他线程在对象被完全构造完成前拿到并使用。

当构造函数结束时，final类型的值是被保证其他线程访问该对象时，它们的值是可见的。  **另外：**

·    final类型的成员变量的值，包括那些用final引用指向的collections的对象，是读线程安全而无需使用synchronization的；

·    不可变对象（指所有的成员都是final并且成员要么是基本类型，要么指向另一个不可变对象）可以并发访问而无需使用同步机制；

·    通过final引用读取“实际不可变”对象（指成员虽然实际并不是final，然而却从不会改变）也是安全的。然而，从程序设计的角度来看，在此种情况下强化不可变性是明智的（如用Collections.unmodifiableList()封装一个collection）；

·    如果你有一个指向collection，数组或其他可变对象的final引用，如果存在其他线程访问，仍然需要使用同步机制来访问该对象（或使用ConcurrentHashMap）。

·    与Volatile 有相似作用，不过Final主要用于不可变变量（基本数据类型和非基本数据类型），进行安全的发布（初始化）。而Volatile可以用于安全的发布不可变变量，也可以提供可变变量的可见性。

应用场景：

​      1、饿汉单例模式，将静态的最终的单例实例的引用率先存放在静态区中。

​      2、ThreadPoolExecutor、ConcurrentHashMap.Node{Key, hash}

### 安全发布的常用模式

·    在静态初始化函数中初始化一个对象引用

·    将对象的应用保存到volatile类型的域或者AtomicReferance对象中

·    将对象的引用保存到某个正确构造对象的final类型域中

·    将对象的引用保存到一个由锁保护的域中。

# 说说反射的用途及实现，反射是不是很慢，我们在项目中是否要避免使用反射；

​      Java反射是指我们可以于运行时加载、探知、使用编译期间完全未知的classes。换句话说，Java程序可以加载一个运行时才得知名称的class，获悉其完整构造（但不包括methods定义），并生成其对象实体、或对其fields设值、或唤起其methods。这种“看透class”的能力被称为introspection（内省、内观、反省）。

​      反射大概比直接调用慢50~100倍（JDK7以后对反射有优化，大概在5倍到20倍不等了），但是需要你在执行100万遍的时候才会有所感觉。为了更好的使用反射，我们应该在项目启动的时候将反射所需要的相关配置及元数据加载进内存中，在运行阶段都从缓存中取这些元数据进行反射操作。

![img](http://image.itstabber.com/2020-09-10/clip_image042.png)

## Java Reflection反射框架主要提供以下功能

\1. 在运行时判断任意一个对象所属的类；

\2. 在运行时构造任意一个类的对象；

\3. 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）；

\4. 在运行时调用任意一个对象的方法

反射最重要的用途就是开发各种通用框架(Spring，hibernate，mybatis)。学习Spring 的依赖注入和反转控制，可以对反射有更好的理解。

## 反射的实现(反射相关的类一般都在java.lang.relfect包里)

1、获得Class对象：

  Hero.class          // 直接获取某一个类的class

  new Hero().getClass();   // 调用某个对象的getClass()方法

   Class.forName("com.Hero"); // 使用Class类的forName静态方法

2、判断是否为某个类的实例

  (hero **instanceof** Hero) // 用**instanceof**关键字来判断是否为某个类的实例

3、获取构造器信息：

   Constructor con = clazz.getConstructor(形参.class);

  Constructor[] conArray = clazz.getConstructors(); // 所有公有构造方法

  conArray = clazz.getDeclaredConstructors(); // 所有的构造方法(包括：私有、受保护、默认、公有)

4、创建实例：

   Hero.**class**.newInstance(); // 使用Class对象的newInstance()方法创建Class对象对应类的实例。

   Hero hero = con.newInstance(实参); // 先通过Class对象获取指定构造器Constructor，再调用con对象的newInstance()创建实例。

5、获取类的成员变量（字段）信息

​    Hero.**class**.getFields(); // 访问共有的成员变量

​    Hero.**class**.getDeclareFields(); // 得到所有的字段，包括公共，保护，默认（包）和私有变量，但不包括继承的字段。

   Field f1 = hero.getDeclaredField("属性名"); // 获取属性

  f1.set(hero, 实参); // 修改属性，注意这里的hero是对象，不是类对象

6、获取方法

   Method[] methods = Hero.**class**.getDeclaredMethods();

  Method m = hero.getClass().getMethod("setName", String.class);

7、调用方法

  m.setAccessible(true); // 暴力访问(忽略掉访问修饰符)

  m.invoke(hero, "hero2"); // 对hero对象，调用这个方法

8、利用反射创建数组

   Array.newInstance();

9、生成动态代理

  在java的动态代理机制中，有两个重要的类或接口，一个是InvocationHandler(Interface)、另一个则是Proxy(Class)。可以通过使用Proxy.newProxyInstance()方法创建动态代理。newProxyInstance()方法有三个参数：

  1、类加载器（ClassLoader）用来加载动态代理类。

  2、一个要实现的接口的数组。

  3、一个InvocationHandler把所有方法的调用都转到代理上。

由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。

另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。

# 静态代理、动态代理和Cglib代理

一、静态代理

​      1、需要定义接口或者父类

​      2、被代理对象与代理对象一起实现相同的接口或者是继承相同父类

​      3、在代理对象中声明一个该接口或者父类的成员变量

​      4、在代理对象构造时注入该接口或者父类的一个实例，作为被代理对象，赋值给代理对象的成员变量

​      5、代理对象在重写该接口或父类的方法中调用被代理对象相应的方法，做到在不修改目标对象的功能前提下，对目标功能进行扩展和增强。

二、动态代理

​      1、代理对象，不需要实现接口；但是目标对象一定要实现接口，否则不能用动态代理

​      2、代理对象的生成，是利用JDK的API，动态的在内存中构建代理对象

JDK中生成代理对象的API代理类所在包:java.lang.reflect.Proxy.newProxyInstance()方法： 

static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h)

注意该方法是在Proxy类中是静态方法，且接收的三个参数依次为:

·    ClassLoader loader：指定当前目标对象使用类加载器，获取加载器的方法是固定的

·    Class<?>[] interfaces：目标对象实现的接口的类型，使用泛型方式确认类型

·    InvocationHandler h：事件处理，执行目标对象的方法时，会触发事件处理器的方法，会把当前执行目标对象的方法作为参数传入

三、Cglib代理

目标对象只是一个单独的对象，并没有实现任何的接口，这个时候就可以使用以目标对象子类的方式类实现代理，这种方法就叫做：Cglib代理。Cglib代理，也叫作子类代理，它是在内存中构建一个子类对象从而实现对目标对象功能的扩展。

·    Cglib是一个强大的高性能的代码生成包，它可以在运行期扩展java类与实现java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和synaop，为他们提供方法的MethodInterceptor (拦截)。

·    Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类，不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。

**Cglib****子类代理实现方法：**

1、需要引入cglib的jar文件，但是Spring核心包中已经包括了Cglib功能，所以直接在Maven中添加s`pring-core.jar`即可。如果非Maven工程则需要引入cglib.jar和asm.jar；

2、引入功能包后，就可以在内存中动态构建子类（代理类实现MethodInterceptor接口，通过Enhancer工具类给目标对象创建一个代理对象）

3、代理的类不能为final，否则报错

4、目标对象的方法如果为final/static，那么就不会被拦截，即不会执行目标对象额外的业务方法。

# 说说自定义注解的场景及实现；

## 使用场景

·    类属性自动赋值，例如对上下文、传入参数等赋值。@Value

·    验证对象属性完整性，例如，对参数的校验。@NotNull

·    代替配置文件功能，像spring基于注解的配置。@Configuration

·    可以生成文档，例如java 最早提供的注解。常用的有 @param @return 等

·    利用注解针对性做一些前置或者后置的处理。例如：登陆校验、权限拦截、记录日志等，以及各种框架如Spring，Hibernate，Junit

## 实现方法

·    Java自定义注解通过**运行期间靠反射获取注解**，实际开发过程中，如果我们需要获取某个方法的调用日志，可以通过**AOP（动态代理机制）** 对方法添加切面，通过反射获取方法包含的注解，如果包含了日志注解，就进行日志记录。

·    Java反射实际是通过对Class对象进行操作而实现，Class对象为我们提供了一系列方法对类进行操作。

·    在JVM角度上来说，**Class文件**是**一组以8字节为基础单位的二进制流，各个数据项目按照严格的顺序紧凑的排列在一起**，里面包含了类、方法、字段等有关数据，**通过对Class数据流进行相应的处理**，就可以得到相应的字段、方法、注解、类等元数据。

## 注解的作用

·    注解是一种元数据形式。即注解是属于java的一种数据类型，和类、接口、数组、枚举类似。

·    注解用来修饰，类、方法、变量、参数、包。

·    注解不会对所修饰的代码产生直接的影响。

## 自定义注解

·    首先使用 @interface声明注解名称

·    自定义注解还会用到4个元注解：@Retention、@Inherited、@Documented、@Target

·    @Documented –注解是否将包含在JavaDoc中

·    @Retention –什么时候使用该注解

·    @Target –注解用于什么地方

·    @Inherited – 是否允许子类继承该注解

  @Target(ElementType.TYPE) // ElementType枚举：CONSTRUCTOR、FIELD、LOCAL_VARIABLE、METHOD、PACKAGE、PARAMETER、TYPE  @Retention(value = RetentionPolicy.RUNTIME)  public @interface Custom1  {      String[] values();  }  

 

# 跳跃表原理

   跳跃表（SkipList），就是在普通链表的基础上增加了多层索引链表，这样在查找时就可以通过在上下不同层级的索引链表间跳跃，以达到快速查找的目的。跳跃表是一种基于有序链表的扩展，利用类似索引的思想，提取出链表中的部分关键节点作为索引链表层。对于节点数目达到上W个，可以进一步在已经提取出的一层关键节点作为索引之上再提取，提出一层索引的索引。当节点足够多的时候，我们不止能提出两层索引，还可以向更高层次提取，保证每一层是上一层节点数的一半。至于提取的极限，则是同一层只有两个节点的时候，因为一个节点没有比较的意义。这样的多层链表结构就是所谓的跳跃表。如上图结构所示。

蓝色最下层原链表是真正存储数据的数据链表，其中每个Node节点都有三个字段：

·    key：键值对的KEY

·    value：键值对的VALUE

·    next：指向下一个数据节点

1级索引层索引链表是分层级的，而且同时指向它的下层索引节点以及同层级的右侧的索引节点。因此，每个Index节点也有三个字段：

·    node：同一列的Index节点都指向最下层的同一个Node节点，目的是可以随时通过索引节点判断出它对应的数据节点是哪个

·    down：指向下一层的索引节点

·    right：指向同一层的右侧的索引节点

2级索引层上级头部（索引的）索引链表是在普通的索引链表的基础上新增了一个表示当前横向链表层级的字段。因此，每个HeadIndex节点就需要用四个字段来表示：

·    level：当前索引链表的层级，从 1 开始计数

·    node：指向左下角的基础Node节点，这个Node节点只是起到一个标志性作用，因此没有KEY

·    down：指向下一层的头部索引节点

·    right：指向同一层的右侧的索引节点

可以参考`Java8`的`ConcurrentSkipListMap`源码。

## Redis中的有序集合

​      Redis使用跳跃表作为有序集合键的的底层实现，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时Redis就会使用跳跃表来作为有序集合键的底层实现。Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。

**Redis** **为什么要使用跳跃表而不是红黑树？**

​      其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。对于按照区间查找数据这个操作，跳表可以做到O(logn)的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。当然，Redis 之所以用跳表来实现有序集合，还有其他原因，比如，跳表更容易代码实现。虽然跳表的实现也不简单，但比起红黑树来说还是好懂、好写多了，而简单就意味着可读性好，不容易出错。还有，跳表更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。我们做业务开发的时候，直接拿来用就可以了，不用费劲自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果你想使用跳表，必须要自己实现。

